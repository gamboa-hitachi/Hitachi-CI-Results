2025-10-14 17:11:47.295 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:11:49.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:11:50.290 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:11:50.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:11:50.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:11:50.293 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:11:51.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:11:51.804 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:11:51.806 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:11:51.807 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:11:51.808 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:11:52.062 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:11:52.100 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.038s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:11:52.103 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=15910MB free_disk=172.57367324829102GB free_vcpus=8 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:11:52.104 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:11:52.105 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:11:53.165 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 0 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:11:53.166 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=512MB phys_disk=194GB used_disk=0GB total_vcpus=8 used_vcpus=0 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:11:52 up 1 day,  6:39,  4 users,  load average: 0.58, 1.19, 1.37\n'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:11:53.215 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:11:53.722 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:11:54.245 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:11:54.246 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.141s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:11:55.241 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:11:55.241 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_scheduler_instance_info [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:11:55.242 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:12:49.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:12:50.290 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:12:50.291 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:12:51.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:12:51.294 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:12:52.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:12:52.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:12:52.807 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:12:52.808 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:12:52.809 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:12:52.810 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:12:53.082 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:12:53.120 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.038s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:12:53.123 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=15935MB free_disk=172.5733184814453GB free_vcpus=8 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:12:53.124 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:12:53.125 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:12:54.185 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 0 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:12:54.186 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=512MB phys_disk=194GB used_disk=0GB total_vcpus=8 used_vcpus=0 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:12:53 up 1 day,  6:40,  4 users,  load average: 0.47, 1.06, 1.31\n'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:12:54.236 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:12:54.745 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:12:55.269 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:12:55.270 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.144s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:12:56.265 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:12:56.266 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:43.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._run_pending_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:43.293 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Cleaning up deleted instances [00;33m{{(pid=807113) _run_pending_deletes /opt/stack/nova/nova/compute/manager.py:11865}}[00m
2025-10-14 17:13:43.801 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] There are 0 instances to clean [00;33m{{(pid=807113) _run_pending_deletes /opt/stack/nova/nova/compute/manager.py:11874}}[00m
2025-10-14 17:13:49.801 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:50.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:50.292 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:13:51.293 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:53.285 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_scheduler_instance_info [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:53.290 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:53.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:53.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:53.804 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:13:53.805 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:13:53.806 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:13:53.807 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:13:54.068 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:13:54.106 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.038s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:13:54.109 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=15938MB free_disk=172.5721206665039GB free_vcpus=8 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:13:54.110 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:13:54.111 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:13:55.176 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 0 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:13:55.177 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=512MB phys_disk=194GB used_disk=0GB total_vcpus=8 used_vcpus=0 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:13:54 up 1 day,  6:41,  4 users,  load average: 0.46, 0.94, 1.25\n'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:13:55.226 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:13:55.735 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:13:56.257 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:13:56.258 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.146s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:13:56.259 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._cleanup_expired_console_auth_tokens [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:57.763 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:57.765 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:57.766 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._cleanup_incomplete_migrations [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:13:57.767 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Cleaning up deleted instances with incomplete migration  [00;33m{{(pid=807113) _cleanup_incomplete_migrations /opt/stack/nova/nova/compute/manager.py:11903}}[00m
2025-10-14 17:14:15.459 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_power_states [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:14:49.802 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:14:51.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:14:51.292 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:14:52.293 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:14:53.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:14:53.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:14:53.805 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:14:53.806 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:14:53.807 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:14:53.808 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:14:54.065 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:14:54.106 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.041s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:14:54.109 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=15820MB free_disk=172.57059860229492GB free_vcpus=8 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:14:54.111 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:14:54.113 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:14:55.225 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 0 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:14:55.226 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=512MB phys_disk=194GB used_disk=0GB total_vcpus=8 used_vcpus=0 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:14:54 up 1 day,  6:42,  5 users,  load average: 0.71, 0.91, 1.22\n'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:14:55.277 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Refreshing inventories for resource provider 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) _refresh_associations /opt/stack/nova/nova/scheduler/client/report.py:822}}[00m
2025-10-14 17:14:55.318 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Updating ProviderTree inventory for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 from _refresh_and_get_inventory using data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) _refresh_and_get_inventory /opt/stack/nova/nova/scheduler/client/report.py:786}}[00m
2025-10-14 17:14:55.319 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Updating inventory in ProviderTree for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 with inventory: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:176}}[00m
2025-10-14 17:14:55.349 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Refreshing aggregate associations for resource provider 074ba663-40c5-4090-8b4a-a216c63d8a77, aggregates: None [00;33m{{(pid=807113) _refresh_associations /opt/stack/nova/nova/scheduler/client/report.py:831}}[00m
2025-10-14 17:14:55.396 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Refreshing trait associations for resource provider 074ba663-40c5-4090-8b4a-a216c63d8a77, traits: HW_CPU_X86_SSE42,COMPUTE_STORAGE_BUS_SCSI,HW_CPU_X86_SSE,COMPUTE_NET_VIF_MODEL_VIRTIO,COMPUTE_NET_VIF_MODEL_LAN9118,COMPUTE_GRAPHICS_MODEL_VIRTIO,COMPUTE_TRUSTED_CERTS,COMPUTE_NET_VIF_MODEL_E1000,COMPUTE_IMAGE_TYPE_ISO,COMPUTE_NET_VIF_MODEL_SPAPR_VLAN,COMPUTE_IMAGE_TYPE_AMI,COMPUTE_STORAGE_BUS_SATA,HW_CPU_X86_SSSE3,COMPUTE_SOCKET_PCI_NUMA_AFFINITY,COMPUTE_VOLUME_MULTI_ATTACH,COMPUTE_ARCH_AARCH64,COMPUTE_VIOMMU_MODEL_AUTO,COMPUTE_ACCELERATORS,COMPUTE_GRAPHICS_MODEL_NONE,COMPUTE_STORAGE_BUS_IDE,HW_CPU_X86_SSE41,COMPUTE_GRAPHICS_MODEL_VGA,COMPUTE_IMAGE_TYPE_AKI,COMPUTE_NET_VIRTIO_PACKED,COMPUTE_SECURITY_UEFI_SECURE_BOOT,COMPUTE_ARCH_MIPSEL,COMPUTE_NET_VIF_MODEL_E1000E,COMPUTE_NET_ATTACH_INTERFACE_WITH_TAG,COMPUTE_GRAPHICS_MODEL_VMVGA,COMPUTE_ARCH_X86_64,COMPUTE_IMAGE_TYPE_ARI,COMPUTE_NET_VIF_MODEL_VMXNET3,COMPUTE_GRAPHICS_MODEL_QXL,COMPUTE_VIOMMU_MODEL_INTEL,COMPUTE_NET_ATTACH_INTERFACE,COMPUTE_RESCUE_BFV,COMPUTE_STORAGE_BUS_VIRTIO,COMPUTE_VOLUME_EXTEND,COMPUTE_NET_VIF_MODEL_NE2K_PCI,COMPUTE_IMAGE_TYPE_RAW,COMPUTE_STORAGE_BUS_FDC,COMPUTE_ARCH_PPC64LE,COMPUTE_VOLUME_ATTACH_WITH_TAG,COMPUTE_NODE,COMPUTE_ARCH_RISCV64,HW_CPU_X86_MMX,COMPUTE_IMAGE_TYPE_QCOW2,COMPUTE_NET_VIF_MODEL_RTL8139,COMPUTE_GRAPHICS_MODEL_CIRRUS,COMPUTE_NET_VIF_MODEL_PCNET,COMPUTE_GRAPHICS_MODEL_BOCHS,COMPUTE_DEVICE_TAGGING,HW_CPU_X86_SSE2,HW_ARCH_X86_64,COMPUTE_ARCH_S390X,COMPUTE_STORAGE_VIRTIO_FS,COMPUTE_STORAGE_BUS_USB,COMPUTE_VIOMMU_MODEL_SMMUV3 [00;33m{{(pid=807113) _refresh_associations /opt/stack/nova/nova/scheduler/client/report.py:843}}[00m
2025-10-14 17:14:55.435 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:14:55.943 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:14:56.464 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:14:56.465 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.352s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:14:57.467 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:14:57.468 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:14:57.468 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:15:49.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:15:53.293 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:15:53.294 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:15:53.294 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:15:53.295 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:15:53.806 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:15:53.807 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:15:53.807 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:15:53.808 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:15:54.079 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:15:54.105 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.026s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:15:54.107 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=15429MB free_disk=172.59542846679688GB free_vcpus=8 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:15:54.107 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:15:54.108 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:15:55.244 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 0 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:15:55.245 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=512MB phys_disk=194GB used_disk=0GB total_vcpus=8 used_vcpus=0 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:15:54 up 1 day,  6:43,  5 users,  load average: 4.50, 1.94, 1.56\n'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:15:55.294 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:15:55.803 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:15:56.327 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:15:56.327 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.220s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:15:57.326 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:15:57.327 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_scheduler_instance_info [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:15:57.328 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:15:57.329 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:15:57.330 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:16:49.294 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:16:53.294 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:16:54.290 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:16:54.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:16:54.293 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:16:54.294 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:16:54.812 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:16:54.813 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:16:54.813 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:16:54.814 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:16:55.108 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:16:55.143 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.036s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:16:55.145 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=15445MB free_disk=172.58824920654297GB free_vcpus=8 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:16:55.146 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:16:55.147 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:16:56.210 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 0 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:16:56.211 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=512MB phys_disk=194GB used_disk=0GB total_vcpus=8 used_vcpus=0 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:16:55 up 1 day,  6:44,  5 users,  load average: 3.97, 2.25, 1.69\n'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:16:56.252 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:16:56.761 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:16:57.289 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:16:57.290 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.144s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:16:59.286 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:16:59.287 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:16:59.288 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:17:13.578 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.build_and_run_instance.<locals>._locked_do_build_and_run_instance" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:17:13.578 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.build_and_run_instance.<locals>._locked_do_build_and_run_instance" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:17:14.083 807113 DEBUG nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Starting instance... [00;33m{{(pid=807113) _do_build_and_run_instance /opt/stack/nova/nova/compute/manager.py:2439}}[00m
2025-10-14 17:17:14.668 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.instance_claim" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:17:14.670 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.instance_claim" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:17:14.679 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Require both a host and instance NUMA topology to fit instance on host. [00;33m{{(pid=807113) numa_fit_instance_to_host /opt/stack/nova/nova/virt/hardware.py:2468}}[00m
2025-10-14 17:17:14.680 807113 INFO nova.compute.claims [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Claim successful on node devstack-u2204-93-55
2025-10-14 17:17:15.790 807113 DEBUG nova.compute.provider_tree [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:17:16.299 807113 DEBUG nova.scheduler.client.report [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:17:16.822 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.instance_claim" :: held 2.152s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:17:16.824 807113 DEBUG nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Start building networks asynchronously for instance. [00;33m{{(pid=807113) _build_resources /opt/stack/nova/nova/compute/manager.py:2836}}[00m
2025-10-14 17:17:17.345 807113 DEBUG nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Allocating IP information in the background. [00;33m{{(pid=807113) _allocate_network_async /opt/stack/nova/nova/compute/manager.py:1988}}[00m
2025-10-14 17:17:17.347 807113 DEBUG nova.network.neutron [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] allocate_for_instance() [00;33m{{(pid=807113) allocate_for_instance /opt/stack/nova/nova/network/neutron.py:1208}}[00m
2025-10-14 17:17:17.640 807113 DEBUG nova.policy [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Policy check for network:attach_external_network failed with credentials {'is_admin': False, 'user_id': '960a08fcc4d0429e9e879816a305186f', 'user_domain_id': 'default', 'system_scope': None, 'domain_id': None, 'project_id': '1eef17e93cf14f169df902f14b44a4e3', 'project_domain_id': 'default', 'roles': ['member', 'reader'], 'is_admin_project': True, 'service_user_id': None, 'service_user_domain_id': None, 'service_project_id': None, 'service_project_domain_id': None, 'service_roles': []} [00;33m{{(pid=807113) authorize /opt/stack/nova/nova/policy.py:192}}[00m
2025-10-14 17:17:17.847 807113 INFO nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2025-10-14 17:17:18.355 807113 DEBUG nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Start building block device mappings for instance. [00;33m{{(pid=807113) _build_resources /opt/stack/nova/nova/compute/manager.py:2871}}[00m
2025-10-14 17:17:18.529 807113 DEBUG nova.network.neutron [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Successfully created port: cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) _create_port_minimal /opt/stack/nova/nova/network/neutron.py:550}}[00m
2025-10-14 17:17:19.382 807113 DEBUG nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Start spawning the instance on the hypervisor. [00;33m{{(pid=807113) _build_and_run_instance /opt/stack/nova/nova/compute/manager.py:2645}}[00m
2025-10-14 17:17:19.386 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Creating instance directory [00;33m{{(pid=807113) _create_image /opt/stack/nova/nova/virt/libvirt/driver.py:5186}}[00m
2025-10-14 17:17:19.387 807113 INFO nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Creating image(s)
2025-10-14 17:17:19.389 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "/opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk.info" by "nova.virt.libvirt.imagebackend.Image.resolve_driver_format.<locals>.write_to_disk_info_file" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:17:19.390 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "/opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk.info" acquired by "nova.virt.libvirt.imagebackend.Image.resolve_driver_format.<locals>.write_to_disk_info_file" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:17:19.392 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "/opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk.info" "released" by "nova.virt.libvirt.imagebackend.Image.resolve_driver_format.<locals>.write_to_disk_info_file" :: held 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:17:19.393 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" by "nova.virt.libvirt.imagebackend.Image.cache.<locals>.fetch_func_sync" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:17:19.395 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" acquired by "nova.virt.libvirt.imagebackend.Image.cache.<locals>.fetch_func_sync" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:17:19.427 807113 DEBUG nova.network.neutron [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Successfully updated port: cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) _update_port /opt/stack/nova/nova/network/neutron.py:588}}[00m
2025-10-14 17:17:19.683 807113 DEBUG nova.compute.manager [req-078f002e-6614-4483-b729-01c1f1426440 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Received event network-changed-cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:17:19.684 807113 DEBUG nova.compute.manager [req-078f002e-6614-4483-b729-01c1f1426440 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Refreshing instance network info cache due to event network-changed-cb17c207-b6b1-4528-8c86-6ec60ca00990. [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11773}}[00m
2025-10-14 17:17:19.685 807113 DEBUG oslo_concurrency.lockutils [req-078f002e-6614-4483-b729-01c1f1426440 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:313}}[00m
2025-10-14 17:17:19.685 807113 DEBUG oslo_concurrency.lockutils [req-078f002e-6614-4483-b729-01c1f1426440 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquired lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:316}}[00m
2025-10-14 17:17:19.685 807113 DEBUG nova.network.neutron [req-078f002e-6614-4483-b729-01c1f1426440 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Refreshing network info cache for port cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) _get_instance_nw_info /opt/stack/nova/nova/network/neutron.py:2067}}[00m
2025-10-14 17:17:19.936 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:313}}[00m
2025-10-14 17:17:21.041 807113 DEBUG nova.network.neutron [req-078f002e-6614-4483-b729-01c1f1426440 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Instance cache missing network info. [00;33m{{(pid=807113) _get_preexisting_port_ids /opt/stack/nova/nova/network/neutron.py:3383}}[00m
2025-10-14 17:17:21.097 807113 DEBUG oslo_utils.imageutils.format_inspector [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vmdk does not match, excluding from consideration (Signature KDMV not found: b'\xebH\x90\x00') [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:17:21.107 807113 DEBUG oslo_utils.imageutils.format_inspector [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vhdx does not match, excluding from consideration (Region signature not found at 30000) [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:17:21.108 807113 DEBUG nova.virt.images [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Image fccdc018-118e-4071-9d16-6a4d7f6e5493 registered as raw, but detected as gpt [00;33m{{(pid=807113) do_image_deep_inspection /opt/stack/nova/nova/virt/images.py:194}}[00m
2025-10-14 17:17:21.109 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1.part --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:17:21.210 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1.part --force-share --output=json" returned: 0 in 0.101s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:17:21.214 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" "released" by "nova.virt.libvirt.imagebackend.Image.cache.<locals>.fetch_func_sync" :: held 1.819s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:17:21.216 807113 DEBUG oslo_utils.imageutils.format_inspector [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vmdk does not match, excluding from consideration (Signature KDMV not found: b'\xebH\x90\x00') [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:17:21.227 807113 DEBUG oslo_utils.imageutils.format_inspector [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vhdx does not match, excluding from consideration (Region signature not found at 30000) [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:17:21.230 807113 INFO oslo.privsep.daemon [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova-cpu.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpqdw05dbr/privsep.sock']
2025-10-14 17:17:21.297 807113 DEBUG nova.network.neutron [req-078f002e-6614-4483-b729-01c1f1426440 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updating instance_info_cache with network_info: [] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:17:21.808 807113 DEBUG oslo_concurrency.lockutils [req-078f002e-6614-4483-b729-01c1f1426440 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Releasing lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:334}}[00m
2025-10-14 17:17:21.811 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquired lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:316}}[00m
2025-10-14 17:17:21.812 807113 DEBUG nova.network.neutron [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Building network info cache for instance [00;33m{{(pid=807113) _get_instance_nw_info /opt/stack/nova/nova/network/neutron.py:2070}}[00m
2025-10-14 17:17:22.526 807113 DEBUG nova.network.neutron [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Instance cache missing network info. [00;33m{{(pid=807113) _get_preexisting_port_ids /opt/stack/nova/nova/network/neutron.py:3383}}[00m
2025-10-14 17:17:22.535 807113 INFO oslo.privsep.daemon [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Spawned new privsep daemon via rootwrap
2025-10-14 17:17:22.317 825640 INFO oslo.privsep.daemon [-] privsep daemon starting
2025-10-14 17:17:22.330 825640 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2025-10-14 17:17:22.336 825640 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2025-10-14 17:17:22.336 825640 INFO oslo.privsep.daemon [-] privsep daemon running as pid 825640
2025-10-14 17:17:22.651 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:17:22.754 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json" returned: 0 in 0.103s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:17:22.757 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" by "nova.virt.libvirt.imagebackend.Qcow2.create_image.<locals>.create_qcow2_image" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:17:22.759 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" acquired by "nova.virt.libvirt.imagebackend.Qcow2.create_image.<locals>.create_qcow2_image" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:17:22.761 807113 DEBUG oslo_utils.imageutils.format_inspector [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vmdk does not match, excluding from consideration (Signature KDMV not found: b'\xebH\x90\x00') [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:17:22.771 807113 DEBUG oslo_utils.imageutils.format_inspector [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vhdx does not match, excluding from consideration (Region signature not found at 30000) [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:17:22.772 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:17:22.875 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json" returned: 0 in 0.102s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:17:22.878 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): env LC_ALL=C LANG=C qemu-img create -f qcow2 -o backing_file=/opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1,backing_fmt=raw /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk 1073741824 [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:17:22.925 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "env LC_ALL=C LANG=C qemu-img create -f qcow2 -o backing_file=/opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1,backing_fmt=raw /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk 1073741824" returned: 0 in 0.048s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:17:22.929 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" "released" by "nova.virt.libvirt.imagebackend.Qcow2.create_image.<locals>.create_qcow2_image" :: held 0.170s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:17:22.931 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:17:23.008 807113 DEBUG nova.network.neutron [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updating instance_info_cache with network_info: [{"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:17:23.037 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json" returned: 0 in 0.106s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:17:23.039 807113 DEBUG nova.virt.disk.api [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Checking if we can resize image /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk. size=1073741824 [00;33m{{(pid=807113) can_resize_image /opt/stack/nova/nova/virt/disk/api.py:164}}[00m
2025-10-14 17:17:23.040 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:17:23.144 807113 DEBUG oslo_concurrency.processutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.104s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:17:23.148 807113 DEBUG nova.virt.disk.api [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Cannot resize image /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk to a smaller size. [00;33m{{(pid=807113) can_resize_image /opt/stack/nova/nova/virt/disk/api.py:170}}[00m
2025-10-14 17:17:23.150 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Created local disks [00;33m{{(pid=807113) _create_image /opt/stack/nova/nova/virt/libvirt/driver.py:5318}}[00m
2025-10-14 17:17:23.151 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Ensure instance console log exists: /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/console.log [00;33m{{(pid=807113) _ensure_console_log_for_instance /opt/stack/nova/nova/virt/libvirt/driver.py:5072}}[00m
2025-10-14 17:17:23.152 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "vgpu_resources" by "nova.virt.libvirt.driver.LibvirtDriver._allocate_mdevs" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:17:23.153 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "vgpu_resources" acquired by "nova.virt.libvirt.driver.LibvirtDriver._allocate_mdevs" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:17:23.154 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "vgpu_resources" "released" by "nova.virt.libvirt.driver.LibvirtDriver._allocate_mdevs" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:17:23.520 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Releasing lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:334}}[00m
2025-10-14 17:17:23.522 807113 DEBUG nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Instance network_info: |[{"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}]| [00;33m{{(pid=807113) _allocate_network_async /opt/stack/nova/nova/compute/manager.py:2003}}[00m
2025-10-14 17:17:23.532 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Start _get_guest_xml network_info=[{"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}] disk_info={'disk_bus': 'virtio', 'cdrom_bus': 'ide', 'mapping': {'root': {'bus': 'virtio', 'dev': 'vda', 'type': 'disk', 'boot_index': '1'}, 'disk': {'bus': 'virtio', 'dev': 'vda', 'type': 'disk', 'boot_index': '1'}}} image_meta=ImageMeta(checksum='1352196d1db841ad1931906db5e76ff6',container_format='bare',created_at=2025-10-15T00:04:23Z,direct_url=<?>,disk_format='raw',id=fccdc018-118e-4071-9d16-6a4d7f6e5493,min_disk=0,min_ram=0,name='cirros-0.6.1-x86_64-disk',owner='89c832aae7f04895a3e7cf9ee7f7bb2d',properties=ImageMetaProps,protected=<?>,size=117440512,status='active',tags=<?>,updated_at=2025-10-15T00:04:30Z,virtual_size=<?>,visibility=<?>) rescue=None block_device_info={'root_device_name': '/dev/vda', 'image': [{'encrypted': False, 'boot_index': 0, 'guest_format': None, 'encryption_secret_uuid': None, 'device_type': 'disk', 'disk_bus': 'virtio', 'encryption_format': None, 'device_name': '/dev/vda', 'size': 0, 'encryption_options': None, 'image_id': 'fccdc018-118e-4071-9d16-6a4d7f6e5493'}], 'ephemerals': [], 'block_device_mapping': [], 'swap': None}share_info=None [00;33m{{(pid=807113) _get_guest_xml /opt/stack/nova/nova/virt/libvirt/driver.py:8047}}[00m
2025-10-14 17:17:23.546 807113 DEBUG nova.virt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] InstanceDriverMetadata: InstanceDriverMetadata(root_type='image', root_id='fccdc018-118e-4071-9d16-6a4d7f6e5493', instance_meta=NovaInstanceMeta(name='tempest-VolumeMultiattachTests-server-17603601', uuid='1c5196e6-48bf-42c2-95c5-4db2adce84ba'), owner=OwnerMeta(userid='960a08fcc4d0429e9e879816a305186f', username='tempest-VolumeMultiattachTests-2017337252-project-member', projectid='1eef17e93cf14f169df902f14b44a4e3', projectname='tempest-VolumeMultiattachTests-2017337252'), image=ImageMeta(id='fccdc018-118e-4071-9d16-6a4d7f6e5493', name=None, properties=ImageMetaProps(hw_architecture=<?>,hw_auto_disk_config=<?>,hw_boot_menu=<?>,hw_cdrom_bus=<?>,hw_cpu_cores=<?>,hw_cpu_max_cores=<?>,hw_cpu_max_sockets=<?>,hw_cpu_max_threads=<?>,hw_cpu_policy=<?>,hw_cpu_realtime_mask=<?>,hw_cpu_sockets=<?>,hw_cpu_thread_policy=<?>,hw_cpu_threads=<?>,hw_device_id=<?>,hw_disk_bus=<?>,hw_disk_type=<?>,hw_emulation_architecture=<?>,hw_ephemeral_encryption=<?>,hw_ephemeral_encryption_format=<?>,hw_ephemeral_encryption_secret_uuid=<?>,hw_firmware_stateless=<?>,hw_firmware_type=<?>,hw_floppy_bus=<?>,hw_input_bus=<?>,hw_ipxe_boot=<?>,hw_locked_memory=<?>,hw_machine_type=<?>,hw_maxphysaddr_bits=<?>,hw_maxphysaddr_mode=<?>,hw_mem_encryption=<?>,hw_mem_page_size=<?>,hw_numa_cpus=<?>,hw_numa_mem=<?>,hw_numa_nodes=<?>,hw_pci_numa_affinity_policy=<?>,hw_pmu=<?>,hw_pointer_model=<?>,hw_qemu_guest_agent=<?>,hw_rescue_bus=<?>,hw_rescue_device=<?>,hw_rng_model='virtio',hw_scsi_model=<?>,hw_serial_port_count=<?>,hw_time_hpet=<?>,hw_tpm_model=<?>,hw_tpm_version=<?>,hw_video_model=<?>,hw_video_ram=<?>,hw_vif_model=<?>,hw_vif_multiqueue_enabled=<?>,hw_viommu_model=<?>,hw_virtio_packed_ring=<?>,hw_vm_mode=<?>,hw_watchdog_action=<?>,img_bdm_v2=<?>,img_bittorrent=<?>,img_block_device_mapping=<?>,img_cache_in_nova=<?>,img_compression_level=<?>,img_config_drive=<?>,img_hide_hypervisor_id=<?>,img_hv_requested_version=<?>,img_hv_type=<?>,img_linked_clone=<?>,img_mappings=<?>,img_owner_id=<?>,img_root_device_name=<?>,img_signature=<?>,img_signature_certificate_uuid=<?>,img_signature_hash_method=<?>,img_signature_key_type=<?>,img_use_agent=<?>,img_version=<?>,os_admin_user=<?>,os_command_line=<?>,os_distro=<?>,os_require_quiesce=<?>,os_secure_boot=<?>,os_skip_agent_inject_files_at_boot=<?>,os_skip_agent_inject_ssh=<?>,os_type=<?>,traits_required=<?>)), flavor=FlavorMeta(name='m1.nano', memory_mb=192, vcpus=1, root_gb=1, ephemeral_gb=0, extra_specs={'hw_rng:allowed': 'True'}, swap=0), network_info=[{"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}], nova_package='31.1.1', creation_time=1760487443.5458708) [00;33m{{(pid=807113) get_instance_driver_metadata /opt/stack/nova/nova/virt/driver.py:401}}[00m
2025-10-14 17:17:23.555 807113 DEBUG nova.virt.libvirt.host [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching host: 'devstack-u2204-93-55' for CPU controller through CGroups V1... [00;33m{{(pid=807113) _has_cgroupsv1_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1695}}[00m
2025-10-14 17:17:23.557 807113 DEBUG nova.virt.libvirt.host [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CPU controller missing on host. [00;33m{{(pid=807113) _has_cgroupsv1_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1705}}[00m
2025-10-14 17:17:23.561 807113 DEBUG nova.virt.libvirt.host [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching host: 'devstack-u2204-93-55' for CPU controller through CGroups V2... [00;33m{{(pid=807113) _has_cgroupsv2_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1714}}[00m
2025-10-14 17:17:23.562 807113 DEBUG nova.virt.libvirt.host [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CPU controller found on host. [00;33m{{(pid=807113) _has_cgroupsv2_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1721}}[00m
2025-10-14 17:17:23.566 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CPU mode 'custom' models 'Nehalem' was chosen, with extra flags: '' [00;33m{{(pid=807113) _get_guest_cpu_model_config /opt/stack/nova/nova/virt/libvirt/driver.py:5857}}[00m
2025-10-14 17:17:23.567 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Getting desirable topologies for flavor Flavor(created_at=2025-10-15T00:05:26Z,deleted=False,deleted_at=None,description=None,disabled=False,ephemeral_gb=0,extra_specs={hw_rng:allowed='True'},flavorid='42',id=11,is_public=True,memory_mb=192,name='m1.nano',projects=<?>,root_gb=1,rxtx_factor=1.0,swap=0,updated_at=None,vcpu_weight=0,vcpus=1) and image_meta ImageMeta(checksum='1352196d1db841ad1931906db5e76ff6',container_format='bare',created_at=2025-10-15T00:04:23Z,direct_url=<?>,disk_format='raw',id=fccdc018-118e-4071-9d16-6a4d7f6e5493,min_disk=0,min_ram=0,name='cirros-0.6.1-x86_64-disk',owner='89c832aae7f04895a3e7cf9ee7f7bb2d',properties=ImageMetaProps,protected=<?>,size=117440512,status='active',tags=<?>,updated_at=2025-10-15T00:04:30Z,virtual_size=<?>,visibility=<?>), allow threads: True [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:567}}[00m
2025-10-14 17:17:23.568 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Flavor limits 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:352}}[00m
2025-10-14 17:17:23.569 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Image limits 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:356}}[00m
2025-10-14 17:17:23.569 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Flavor pref 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:392}}[00m
2025-10-14 17:17:23.570 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Image pref 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:396}}[00m
2025-10-14 17:17:23.570 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Chose sockets=0, cores=0, threads=0; limits were sockets=65536, cores=65536, threads=65536 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:434}}[00m
2025-10-14 17:17:23.571 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Topology preferred VirtCPUTopology(cores=0,sockets=0,threads=0), maximum VirtCPUTopology(cores=65536,sockets=65536,threads=65536) [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:573}}[00m
2025-10-14 17:17:23.572 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Build topologies for 1 vcpu(s) 1:1:1 [00;33m{{(pid=807113) _get_possible_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:475}}[00m
2025-10-14 17:17:23.572 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Got 1 possible topologies [00;33m{{(pid=807113) _get_possible_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:505}}[00m
2025-10-14 17:17:23.572 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Possible topologies [VirtCPUTopology(cores=1,sockets=1,threads=1)] [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:579}}[00m
2025-10-14 17:17:23.573 807113 DEBUG nova.virt.hardware [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Sorted desired topologies [VirtCPUTopology(cores=1,sockets=1,threads=1)] [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:581}}[00m
2025-10-14 17:17:23.592 807113 DEBUG nova.privsep.utils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Path '/opt/stack/data/nova/instances' supports direct I/O [00;33m{{(pid=807113) supports_direct_io /opt/stack/nova/nova/privsep/utils.py:63}}[00m
2025-10-14 17:17:23.593 807113 DEBUG nova.virt.libvirt.vif [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] vif_type=ovs instance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone='nova',cell_name=None,cleaned=False,compute_id=1,config_drive='',created_at=2025-10-15T00:17:11Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,device_metadata=None,disable_terminate=False,display_description=None,display_name='tempest-VolumeMultiattachTests-server-17603601',ec2_ids=EC2Ids,ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,flavor=Flavor(11),hidden=False,host='devstack-u2204-93-55',hostname='tempest-volumemultiattachtests-server-17603601',id=1,image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',info_cache=InstanceInfoCache,instance_type_id=11,kernel_id='',key_data='ecdsa-sha2-nistp384 AAAAE2VjZHNhLXNoYTItbmlzdHAzODQAAAAIbmlzdHAzODQAAABhBA8Aiex4gcSHOLfHUTCeqhj7EyM75uU1yg5RlGdYgLuNs2zNO5yK6ijBQYa275YCZkO6CfvUFVYQ+Ps+520EW9lVVkJ9pJ8Md24/YbKYhDFiKsViWmJOf5Nn7uVTraEcEQ==',key_name='tempest-keypair-1058132398',keypairs=KeyPairList,launch_index=0,launched_at=None,launched_on='devstack-u2204-93-55',locked=False,locked_by=None,memory_mb=192,metadata={},migration_context=None,new_flavor=None,node='devstack-u2204-93-55',numa_topology=None,old_flavor=None,os_type=None,pci_devices=<?>,pci_requests=InstancePCIRequests,power_state=0,progress=0,project_id='1eef17e93cf14f169df902f14b44a4e3',ramdisk_id='',reservation_id='r-wrv46qma',resources=None,root_device_name='/dev/vda',root_gb=1,security_groups=SecurityGroupList,services=<?>,shutdown_terminate=False,system_metadata={boot_roles='member,reader',image_base_image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',image_container_format='bare',image_disk_format='raw',image_hw_machine_type='pc',image_hw_rng_model='virtio',image_min_disk='1',image_min_ram='0',image_owner_specified.openstack.md5='',image_owner_specified.openstack.object='images/cirros-0.6.1-x86_64-disk',image_owner_specified.openstack.sha256='',network_allocated='True',owner_project_name='tempest-VolumeMultiattachTests-2017337252',owner_user_name='tempest-VolumeMultiattachTests-2017337252-project-member'},tags=TagList,task_state='spawning',terminated_at=None,trusted_certs=None,updated_at=2025-10-15T00:17:18Z,user_data='IyEvYmluL3NoCmVjaG8gIlByaW50aW5nIGNpcnJvcyB1c2VyIGF1dGhvcml6ZWQga2V5cyIKY2F0IH5jaXJyb3MvLnNzaC9hdXRob3JpemVkX2tleXMgfHwgdHJ1ZQo=',user_id='960a08fcc4d0429e9e879816a305186f',uuid=1c5196e6-48bf-42c2-95c5-4db2adce84ba,vcpu_model=VirtCPUModel,vcpus=1,vm_mode=None,vm_state='building') vif={"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} virt_type=qemu [00;33m{{(pid=807113) get_config /opt/stack/nova/nova/virt/libvirt/vif.py:574}}[00m
2025-10-14 17:17:23.594 807113 DEBUG nova.network.os_vif_util [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converting VIF {"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:511}}[00m
2025-10-14 17:17:23.595 807113 DEBUG nova.network.os_vif_util [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converted object VIFOpenVSwitch(active=False,address=fa:16:3e:55:eb:ee,bridge_name='br-int',has_traffic_filtering=True,id=cb17c207-b6b1-4528-8c86-6ec60ca00990,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcb17c207-b6') [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:548}}[00m
2025-10-14 17:17:23.597 807113 DEBUG nova.objects.instance [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'pci_devices' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:17:24.104 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] End _get_guest_xml xml=<domain type="qemu">
  <uuid>1c5196e6-48bf-42c2-95c5-4db2adce84ba</uuid>
  <name>instance-00000001</name>
  <memory>196608</memory>
  <vcpu>1</vcpu>
  <metadata>
    <nova:instance xmlns:nova="http://openstack.org/xmlns/libvirt/nova/1.1">
      <nova:package version="31.1.1"/>
      <nova:name>tempest-VolumeMultiattachTests-server-17603601</nova:name>
      <nova:creationTime>2025-10-15 00:17:23</nova:creationTime>
      <nova:flavor name="m1.nano">
        <nova:memory>192</nova:memory>
        <nova:disk>1</nova:disk>
        <nova:swap>0</nova:swap>
        <nova:ephemeral>0</nova:ephemeral>
        <nova:vcpus>1</nova:vcpus>
      </nova:flavor>
      <nova:owner>
        <nova:user uuid="960a08fcc4d0429e9e879816a305186f">tempest-VolumeMultiattachTests-2017337252-project-member</nova:user>
        <nova:project uuid="1eef17e93cf14f169df902f14b44a4e3">tempest-VolumeMultiattachTests-2017337252</nova:project>
      </nova:owner>
      <nova:root type="image" uuid="fccdc018-118e-4071-9d16-6a4d7f6e5493"/>
      <nova:ports>
        <nova:port uuid="cb17c207-b6b1-4528-8c86-6ec60ca00990">
          <nova:ip type="fixed" address="10.1.0.9" ipVersion="4"/>
        </nova:port>
      </nova:ports>
    </nova:instance>
  </metadata>
  <sysinfo type="smbios">
    <system>
      <entry name="manufacturer">OpenStack Foundation</entry>
      <entry name="product">OpenStack Nova</entry>
      <entry name="version">31.1.1</entry>
      <entry name="serial">1c5196e6-48bf-42c2-95c5-4db2adce84ba</entry>
      <entry name="uuid">1c5196e6-48bf-42c2-95c5-4db2adce84ba</entry>
      <entry name="family">Virtual Machine</entry>
    </system>
  </sysinfo>
  <os>
    <type arch="x86_64" machine="pc">hvm</type>
    <boot dev="hd"/>
    <smbios mode="sysinfo"/>
  </os>
  <features>
    <acpi/>
    <vmcoreinfo/>
  </features>
  <clock offset="utc"/>
  <cpu mode="custom" match="exact">
    <model>Nehalem</model>
    <topology sockets="1" cores="1" threads="1"/>
  </cpu>
  <devices>
    <disk type="file" device="disk">
      <driver name="qemu" type="qcow2" cache="none"/>
      <source file="/opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk"/>
      <target dev="vda" bus="virtio"/>
    </disk>
    <interface type="ethernet">
      <mac address="fa:16:3e:55:eb:ee"/>
      <model type="virtio"/>
      <driver name="qemu"/>
      <mtu size="1450"/>
      <target dev="tapcb17c207-b6"/>
    </interface>
    <serial type="pty">
      <log file="/opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/console.log" append="off"/>
    </serial>
    <graphics type="vnc" autoport="yes" listen="0.0.0.0"/>
    <video>
      <model type="virtio"/>
    </video>
    <rng model="virtio">
      <backend model="random">/dev/urandom</backend>
    </rng>
    <controller type="usb" index="0" model="none"/>
    <memballoon model="virtio">
      <stats period="10"/>
    </memballoon>
  </devices>
</domain>
 [00;33m{{(pid=807113) _get_guest_xml /opt/stack/nova/nova/virt/libvirt/driver.py:8053}}[00m
2025-10-14 17:17:24.106 807113 DEBUG nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Preparing to wait for external event network-vif-plugged-cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) prepare_for_instance_event /opt/stack/nova/nova/compute/manager.py:285}}[00m
2025-10-14 17:17:24.106 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba-events" by "nova.compute.manager.InstanceEvents.prepare_for_instance_event.<locals>._create_or_get_event" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:17:24.107 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba-events" acquired by "nova.compute.manager.InstanceEvents.prepare_for_instance_event.<locals>._create_or_get_event" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:17:24.108 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba-events" "released" by "nova.compute.manager.InstanceEvents.prepare_for_instance_event.<locals>._create_or_get_event" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:17:24.110 807113 DEBUG nova.virt.libvirt.vif [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] vif_type=ovs instance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone='nova',cell_name=None,cleaned=False,compute_id=1,config_drive='',created_at=2025-10-15T00:17:11Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,device_metadata=None,disable_terminate=False,display_description=None,display_name='tempest-VolumeMultiattachTests-server-17603601',ec2_ids=EC2Ids,ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,flavor=Flavor(11),hidden=False,host='devstack-u2204-93-55',hostname='tempest-volumemultiattachtests-server-17603601',id=1,image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',info_cache=InstanceInfoCache,instance_type_id=11,kernel_id='',key_data='ecdsa-sha2-nistp384 AAAAE2VjZHNhLXNoYTItbmlzdHAzODQAAAAIbmlzdHAzODQAAABhBA8Aiex4gcSHOLfHUTCeqhj7EyM75uU1yg5RlGdYgLuNs2zNO5yK6ijBQYa275YCZkO6CfvUFVYQ+Ps+520EW9lVVkJ9pJ8Md24/YbKYhDFiKsViWmJOf5Nn7uVTraEcEQ==',key_name='tempest-keypair-1058132398',keypairs=KeyPairList,launch_index=0,launched_at=None,launched_on='devstack-u2204-93-55',locked=False,locked_by=None,memory_mb=192,metadata={},migration_context=None,new_flavor=None,node='devstack-u2204-93-55',numa_topology=None,old_flavor=None,os_type=None,pci_devices=PciDeviceList,pci_requests=InstancePCIRequests,power_state=0,progress=0,project_id='1eef17e93cf14f169df902f14b44a4e3',ramdisk_id='',reservation_id='r-wrv46qma',resources=None,root_device_name='/dev/vda',root_gb=1,security_groups=SecurityGroupList,services=<?>,shutdown_terminate=False,system_metadata={boot_roles='member,reader',image_base_image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',image_container_format='bare',image_disk_format='raw',image_hw_machine_type='pc',image_hw_rng_model='virtio',image_min_disk='1',image_min_ram='0',image_owner_specified.openstack.md5='',image_owner_specified.openstack.object='images/cirros-0.6.1-x86_64-disk',image_owner_specified.openstack.sha256='',network_allocated='True',owner_project_name='tempest-VolumeMultiattachTests-2017337252',owner_user_name='tempest-VolumeMultiattachTests-2017337252-project-member'},tags=TagList,task_state='spawning',terminated_at=None,trusted_certs=None,updated_at=2025-10-15T00:17:18Z,user_data='IyEvYmluL3NoCmVjaG8gIlByaW50aW5nIGNpcnJvcyB1c2VyIGF1dGhvcml6ZWQga2V5cyIKY2F0IH5jaXJyb3MvLnNzaC9hdXRob3JpemVkX2tleXMgfHwgdHJ1ZQo=',user_id='960a08fcc4d0429e9e879816a305186f',uuid=1c5196e6-48bf-42c2-95c5-4db2adce84ba,vcpu_model=VirtCPUModel,vcpus=1,vm_mode=None,vm_state='building') vif={"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) plug /opt/stack/nova/nova/virt/libvirt/vif.py:721}}[00m
2025-10-14 17:17:24.111 807113 DEBUG nova.network.os_vif_util [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converting VIF {"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:511}}[00m
2025-10-14 17:17:24.113 807113 DEBUG nova.network.os_vif_util [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converted object VIFOpenVSwitch(active=False,address=fa:16:3e:55:eb:ee,bridge_name='br-int',has_traffic_filtering=True,id=cb17c207-b6b1-4528-8c86-6ec60ca00990,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcb17c207-b6') [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:548}}[00m
2025-10-14 17:17:24.114 807113 DEBUG os_vif [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Plugging vif VIFOpenVSwitch(active=False,address=fa:16:3e:55:eb:ee,bridge_name='br-int',has_traffic_filtering=True,id=cb17c207-b6b1-4528-8c86-6ec60ca00990,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcb17c207-b6') [00;33m{{(pid=807113) plug /opt/stack/data/venv/lib/python3.10/site-packages/os_vif/__init__.py:76}}[00m
2025-10-14 17:17:24.193 807113 DEBUG ovsdbapp.backend.ovs_idl [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Created schema index Interface.name [00;33m{{(pid=807113) autocreate_indices /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/__init__.py:106}}[00m
2025-10-14 17:17:24.194 807113 DEBUG ovsdbapp.backend.ovs_idl [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Created schema index Port.name [00;33m{{(pid=807113) autocreate_indices /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/__init__.py:106}}[00m
2025-10-14 17:17:24.194 807113 DEBUG ovsdbapp.backend.ovs_idl [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Created schema index Bridge.name [00;33m{{(pid=807113) autocreate_indices /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/__init__.py:106}}[00m
2025-10-14 17:17:24.195 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] tcp:127.0.0.1:6640: entering CONNECTING [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:17:24.196 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [POLLOUT] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:24.196 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:17:24.197 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:24.200 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:24.238 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:24.281 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:24.282 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): AddBridgeCommand(_result=None, name=br-int, may_exist=True, datapath_type=system) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:17:24.282 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Transaction caused no change [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:129}}[00m
2025-10-14 17:17:24.284 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:24.284 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): DbCreateCommand(_result=None, table=QoS, columns={'type': 'linux-noop', 'external_ids': {'id': '955c956e-5371-5941-b62a-a05d71ca0dda', '_type': 'linux-noop'}}, row=False) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:17:24.286 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:24.292 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:17:24.295 807113 INFO oslo.privsep.daemon [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova-cpu.conf', '--privsep_context', 'vif_plug_ovs.privsep.vif_plug', '--privsep_sock_path', '/tmp/tmpwg5nlw3t/privsep.sock']
2025-10-14 17:17:25.585 807113 INFO oslo.privsep.daemon [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Spawned new privsep daemon via rootwrap
2025-10-14 17:17:25.362 825663 INFO oslo.privsep.daemon [-] privsep daemon starting
2025-10-14 17:17:25.374 825663 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2025-10-14 17:17:25.380 825663 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_OVERRIDE|CAP_NET_ADMIN/CAP_DAC_OVERRIDE|CAP_NET_ADMIN/none
2025-10-14 17:17:25.380 825663 INFO oslo.privsep.daemon [-] privsep daemon running as pid 825663
2025-10-14 17:17:25.979 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:25.980 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): AddPortCommand(_result=None, bridge=br-int, port=tapcb17c207-b6, may_exist=True, interface_attrs={}) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:17:25.982 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=1): DbSetCommand(_result=None, table=Port, record=tapcb17c207-b6, col_values=(('qos', UUID('2ea2153e-3fba-49d4-8769-e8394d3fe92b')),), if_exists=True) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:17:25.984 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=2): DbSetCommand(_result=None, table=Interface, record=tapcb17c207-b6, col_values=(('external_ids', {'iface-id': 'cb17c207-b6b1-4528-8c86-6ec60ca00990', 'iface-status': 'active', 'attached-mac': 'fa:16:3e:55:eb:ee', 'vm-uuid': '1c5196e6-48bf-42c2-95c5-4db2adce84ba'}),), if_exists=True) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:17:25.988 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:25.999 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:17:26.007 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:26.010 807113 INFO os_vif [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully plugged vif VIFOpenVSwitch(active=False,address=fa:16:3e:55:eb:ee,bridge_name='br-int',has_traffic_filtering=True,id=cb17c207-b6b1-4528-8c86-6ec60ca00990,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcb17c207-b6')
2025-10-14 17:17:26.101 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:26.117 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:26.122 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:26.138 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:26.392 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:26.712 807113 DEBUG nova.compute.manager [req-2a93955d-a7ed-43c6-be88-33d2ebe88c0d bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Received event network-vif-plugged-cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:17:26.714 807113 DEBUG oslo_concurrency.lockutils [req-2a93955d-a7ed-43c6-be88-33d2ebe88c0d bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba-events" by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:17:26.715 807113 DEBUG oslo_concurrency.lockutils [req-2a93955d-a7ed-43c6-be88-33d2ebe88c0d bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba-events" acquired by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:17:26.716 807113 DEBUG oslo_concurrency.lockutils [req-2a93955d-a7ed-43c6-be88-33d2ebe88c0d bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba-events" "released" by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:17:26.716 807113 DEBUG nova.compute.manager [req-2a93955d-a7ed-43c6-be88-33d2ebe88c0d bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Processing event network-vif-plugged-cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) _process_instance_event /opt/stack/nova/nova/compute/manager.py:11528}}[00m
2025-10-14 17:17:27.551 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vda, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:17:27.552 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No VIF found with MAC fa:16:3e:55:eb:ee, not building metadata [00;33m{{(pid=807113) _build_interface_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12794}}[00m
2025-10-14 17:17:28.772 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:28.788 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:30.823 807113 DEBUG nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Instance event wait completed in 0 seconds for network-vif-plugged [00;33m{{(pid=807113) wait_for_instance_event /opt/stack/nova/nova/compute/manager.py:579}}[00m
2025-10-14 17:17:30.833 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Guest created on hypervisor [00;33m{{(pid=807113) spawn /opt/stack/nova/nova/virt/libvirt/driver.py:4871}}[00m
2025-10-14 17:17:30.841 807113 INFO nova.virt.libvirt.driver [-] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Instance spawned successfully.
2025-10-14 17:17:30.842 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Attempting to register defaults for the following image properties: ['hw_cdrom_bus', 'hw_disk_bus', 'hw_input_bus', 'hw_pointer_model', 'hw_video_model', 'hw_vif_model'] [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1006}}[00m
2025-10-14 17:17:31.362 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Found default for hw_cdrom_bus of ide [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:17:31.364 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Found default for hw_disk_bus of virtio [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:17:31.366 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Found default for hw_input_bus of None [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:17:31.368 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Found default for hw_pointer_model of None [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:17:31.370 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Found default for hw_video_model of virtio [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:17:31.371 807113 DEBUG nova.virt.libvirt.driver [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Found default for hw_vif_model of virtio [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:17:31.395 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:31.887 807113 INFO nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Took 12.50 seconds to spawn the instance on the hypervisor.
2025-10-14 17:17:31.888 807113 DEBUG nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Checking state [00;33m{{(pid=807113) _get_power_state /opt/stack/nova/nova/compute/manager.py:1798}}[00m
2025-10-14 17:17:32.420 807113 INFO nova.compute.manager [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Took 17.82 seconds to build instance.
2025-10-14 17:17:32.926 807113 DEBUG oslo_concurrency.lockutils [req-bffd6d5b-4d8d-4e2a-aec3-4f4710ce6996 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.build_and_run_instance.<locals>._locked_do_build_and_run_instance" :: held 19.347s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:17:34.420 807113 DEBUG nova.compute.manager [req-97d449b8-91c9-4af7-889e-0241c851858a bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Received event network-changed-cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:17:34.421 807113 DEBUG nova.compute.manager [req-97d449b8-91c9-4af7-889e-0241c851858a bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Refreshing instance network info cache due to event network-changed-cb17c207-b6b1-4528-8c86-6ec60ca00990. [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11773}}[00m
2025-10-14 17:17:34.422 807113 DEBUG oslo_concurrency.lockutils [req-97d449b8-91c9-4af7-889e-0241c851858a bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:313}}[00m
2025-10-14 17:17:34.422 807113 DEBUG oslo_concurrency.lockutils [req-97d449b8-91c9-4af7-889e-0241c851858a bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquired lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:316}}[00m
2025-10-14 17:17:34.423 807113 DEBUG nova.network.neutron [req-97d449b8-91c9-4af7-889e-0241c851858a bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Refreshing network info cache for port cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) _get_instance_nw_info /opt/stack/nova/nova/network/neutron.py:2067}}[00m
2025-10-14 17:17:35.501 807113 DEBUG nova.network.neutron [req-97d449b8-91c9-4af7-889e-0241c851858a bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updated VIF entry in instance network info cache for port cb17c207-b6b1-4528-8c86-6ec60ca00990. [00;33m{{(pid=807113) _build_network_info_model /opt/stack/nova/nova/network/neutron.py:3542}}[00m
2025-10-14 17:17:35.502 807113 DEBUG nova.network.neutron [req-97d449b8-91c9-4af7-889e-0241c851858a bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updating instance_info_cache with network_info: [{"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": [{"address": "172.24.5.125", "type": "floating", "version": 4, "meta": {}}]}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": true, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:17:35.987 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:36.008 807113 DEBUG oslo_concurrency.lockutils [req-97d449b8-91c9-4af7-889e-0241c851858a bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Releasing lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:334}}[00m
2025-10-14 17:17:36.399 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:41.404 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:45.991 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:46.409 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:51.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:17:51.413 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:55.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:17:55.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:17:55.293 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:17:55.804 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:17:55.806 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:17:55.806 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:17:55.807 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:17:55.993 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:56.418 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:17:56.861 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:17:56.969 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.107s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:17:56.973 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:17:57.094 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.121s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:17:57.344 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:17:57.380 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.036s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:17:57.384 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=14950MB free_disk=172.33803176879883GB free_vcpus=7 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:17:57.385 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:17:57.387 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:17:58.463 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:17:58.464 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 1 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:17:58.465 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=704MB phys_disk=194GB used_disk=1GB total_vcpus=8 used_vcpus=1 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:17:57 up 1 day,  6:45,  5 users,  load average: 2.32, 2.12, 1.68\n', 'num_instances': '1', 'num_vm_active': '1', 'num_task_None': '1', 'num_os_type_None': '1', 'num_proj_1eef17e93cf14f169df902f14b44a4e3': '1', 'io_workload': '0'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:17:58.561 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:17:59.072 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:17:59.599 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:17:59.600 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.212s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:18:00.599 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:18:00.600 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_scheduler_instance_info [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:18:00.601 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:18:00.601 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:18:00.602 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:18:00.603 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:18:01.422 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:05.995 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:06.427 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:11.431 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:15.997 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:16.435 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:21.440 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:25.999 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:26.443 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:31.447 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4998-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:18:36.002 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:36.454 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:41.457 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:46.005 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:46.462 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:51.465 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:53.294 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:18:54.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._run_pending_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:18:54.293 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Cleaning up deleted instances [00;33m{{(pid=807113) _run_pending_deletes /opt/stack/nova/nova/compute/manager.py:11865}}[00m
2025-10-14 17:18:54.799 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] There are 0 instances to clean [00;33m{{(pid=807113) _run_pending_deletes /opt/stack/nova/nova/compute/manager.py:11874}}[00m
2025-10-14 17:18:55.800 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:18:55.801 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:18:55.802 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:18:56.008 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:56.320 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:18:56.321 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:18:56.322 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:18:56.323 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:18:56.468 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:18:57.381 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:18:57.487 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.106s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:18:57.491 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:18:57.593 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.102s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:18:57.852 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:18:57.889 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.037s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:18:57.892 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=14634MB free_disk=172.33396911621094GB free_vcpus=7 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:18:57.894 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:18:57.895 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:18:58.970 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:18:58.971 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 1 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:18:58.971 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=704MB phys_disk=194GB used_disk=1GB total_vcpus=8 used_vcpus=1 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:18:57 up 1 day,  6:46,  5 users,  load average: 1.89, 2.04, 1.68\n', 'num_instances': '1', 'num_vm_active': '1', 'num_task_None': '1', 'num_os_type_None': '1', 'num_proj_1eef17e93cf14f169df902f14b44a4e3': '1', 'io_workload': '0'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:18:59.058 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:18:59.565 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:19:00.090 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:19:00.092 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.197s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:19:01.475 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4997-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:01.477 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:01.478 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5004 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:19:01.478 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:19:01.479 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:01.480 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:19:01.581 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:01.582 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:01.583 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:01.583 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:01.584 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:19:04.491 807113 DEBUG oslo_concurrency.lockutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:19:04.493 807113 DEBUG oslo_concurrency.lockutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:19:05.004 807113 DEBUG nova.objects.instance [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:19:06.019 807113 DEBUG oslo_concurrency.lockutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" :: held 1.526s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:19:06.481 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:06.483 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:06.483 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:19:06.484 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:19:06.485 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:06.486 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:19:07.223 807113 DEBUG oslo_concurrency.lockutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:19:07.225 807113 DEBUG oslo_concurrency.lockutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:19:07.226 807113 INFO nova.compute.manager [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Attaching volume 6143228d-e127-4fba-8b40-e8d79c7b0c72 to /dev/vdb
2025-10-14 17:19:07.290 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._cleanup_expired_console_auth_tokens [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:07.344 807113 DEBUG os_brick.utils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> get_connector_properties: call "{'root_helper': 'sudo nova-rootwrap /etc/nova/rootwrap.conf', 'my_ip': '172.25.93.55', 'multipath': False, 'enforce_multipath': True, 'host': 'devstack-u2204-93-55', 'execute': None}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:19:07.346 807113 INFO oslo.privsep.daemon [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova-cpu.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmp7vwx6u_m/privsep.sock']
2025-10-14 17:19:08.563 807113 INFO oslo.privsep.daemon [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Spawned new privsep daemon via rootwrap
2025-10-14 17:19:08.343 826121 INFO oslo.privsep.daemon [-] privsep daemon starting
2025-10-14 17:19:08.357 826121 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2025-10-14 17:19:08.363 826121 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_SYS_ADMIN/CAP_SYS_ADMIN/none
2025-10-14 17:19:08.364 826121 INFO oslo.privsep.daemon [-] privsep daemon running as pid 826121
2025-10-14 17:19:08.571 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[c4fe0162-9450-4342-bb74-9d0a0b7c2e96]: (2,) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:08.737 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): cat /etc/iscsi/initiatorname.iscsi [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:08.750 826121 DEBUG oslo_concurrency.processutils [-] CMD "cat /etc/iscsi/initiatorname.iscsi" returned: 0 in 0.013s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:08.751 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[433b5454-4fa6-471f-a25b-39a6d521c007]: (4, ('InitiatorName=iqn.2016-04.com.open-iscsi:851997e07f81\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:08.755 807113 WARNING os_brick.initiator.connectors.nvmeof [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Could not find nvme_core/parameters/multipath: FileNotFoundError: [Errno 2] No such file or directory: '/sys/module/nvme_core/parameters/multipath'
2025-10-14 17:19:08.757 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): findmnt -v / -n -o SOURCE [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:08.774 826121 DEBUG oslo_concurrency.processutils [-] CMD "findmnt -v / -n -o SOURCE" returned: 0 in 0.017s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:08.775 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[2a591899-e8f5-4e43-bafc-fc358493e130]: (4, ('/dev/sda2\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:08.778 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): blkid /dev/sda2 -s UUID -o value [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:08.797 826121 DEBUG oslo_concurrency.processutils [-] CMD "blkid /dev/sda2 -s UUID -o value" returned: 0 in 0.019s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:08.798 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[92540771-c00f-4c8a-a5bb-2a4b1de472d1]: (4, ('849a1340-77d5-4de3-852c-cf0210ca78af\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:08.804 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[e3770007-5506-43d0-9f79-fd35b80744b9]: (4, '89b11b42-6ca2-76fb-88b9-4b0fae22b322') [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:08.805 807113 DEBUG oslo_concurrency.processutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): nvme version [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:08.836 807113 DEBUG oslo_concurrency.processutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] 'nvme version' failed. Not Retrying. [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:19:08.840 807113 DEBUG os_brick.initiator.connectors.nvmeof [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] nvme not present on system [00;33m{{(pid=807113) nvme_present /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/nvmeof.py:784}}[00m
2025-10-14 17:19:08.844 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): nvme show-hostnqn [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:08.856 826121 DEBUG oslo_concurrency.processutils [-] 'nvme show-hostnqn' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:19:08.857 826121 WARNING os_brick.privileged.nvmeof [-] Could not generate host nqn: [Errno 2] No such file or directory: 'nvme'
2025-10-14 17:19:08.858 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[1b526c87-3ce0-44b2-aa4f-ab03daadfc0b]: (4, '') [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:08.864 807113 DEBUG os_brick.initiator.connectors.lightos [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: [Errno 111] ECONNREFUSED [00;33m{{(pid=807113) find_dsc /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:135}}[00m
2025-10-14 17:19:08.869 807113 INFO os_brick.initiator.connectors.lightos [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Current host hostNQN  and IP(s) are ['172.25.93.55', 'fe80::387c:9d0a:2c22:5c64', '192.168.122.1', '172.24.5.1', 'fe80::7c4c:53ff:fed4:fe47', 'fe80::fc16:3eff:fe55:ebee'] 
2025-10-14 17:19:08.871 807113 DEBUG os_brick.initiator.connectors.lightos [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: did not find dsc, continuing anyway. [00;33m{{(pid=807113) get_connector_properties /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:112}}[00m
2025-10-14 17:19:08.872 807113 DEBUG os_brick.initiator.connectors.lightos [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: no hostnqn found. [00;33m{{(pid=807113) get_connector_properties /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:121}}[00m
2025-10-14 17:19:08.872 807113 DEBUG os_brick.utils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== get_connector_properties: return (1528ms) {'platform': 'x86_64', 'os_type': 'linux', 'ip': '172.25.93.55', 'host': 'devstack-u2204-93-55', 'multipath': False, 'enforce_multipath': True, 'initiator': 'iqn.2016-04.com.open-iscsi:851997e07f81', 'do_local_attach': False, 'uuid': '849a1340-77d5-4de3-852c-cf0210ca78af', 'system uuid': '89b11b42-6ca2-76fb-88b9-4b0fae22b322', 'nvme_native_multipath': False} [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:19:08.873 807113 DEBUG nova.virt.block_device [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updating existing volume attachment record: d1c7b206-230d-44e5-8da3-9c5cd7ee468c [00;33m{{(pid=807113) _volume_attach /opt/stack/nova/nova/virt/block_device.py:666}}[00m
2025-10-14 17:19:09.796 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._cleanup_incomplete_migrations [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:09.797 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Cleaning up deleted instances with incomplete migration  [00;33m{{(pid=807113) _cleanup_incomplete_migrations /opt/stack/nova/nova/compute/manager.py:11903}}[00m
2025-10-14 17:19:11.480 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:16.483 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:21.487 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:21.993 807113 DEBUG oslo_concurrency.lockutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "cache_volume_driver" by "nova.virt.libvirt.driver.LibvirtDriver._get_volume_driver.<locals>._cache_volume_driver" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:19:21.995 807113 DEBUG oslo_concurrency.lockutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "cache_volume_driver" acquired by "nova.virt.libvirt.driver.LibvirtDriver._get_volume_driver.<locals>._cache_volume_driver" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:19:22.001 807113 DEBUG os_brick.initiator.connector [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Factory for ISCSI on None [00;33m{{(pid=807113) factory /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connector.py:281}}[00m
2025-10-14 17:19:22.003 807113 DEBUG oslo_concurrency.lockutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "cache_volume_driver" "released" by "nova.virt.libvirt.driver.LibvirtDriver._get_volume_driver.<locals>._cache_volume_driver" :: held 0.008s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:19:22.003 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Calling os-brick to attach iSCSI Volume [00;33m{{(pid=807113) connect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:64}}[00m
2025-10-14 17:19:22.004 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> connect_volume: call "{'self': <os_brick.initiator.connectors.iscsi.ISCSIConnector object at 0x7a59504d4550>, 'connection_properties': {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 1, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True}}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:19:22.005 807113 DEBUG os_brick.initiator.connectors.base [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_volume" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:19:22.006 807113 DEBUG os_brick.initiator.connectors.base [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:19:22.007 807113 DEBUG os_brick.initiator.connectors.base [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connection properties {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 1, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True} [00;33m{{(pid=807113) check_multipath /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:133}}[00m
2025-10-14 17:19:22.009 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): multipathd show status [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:22.023 826121 DEBUG oslo_concurrency.processutils [-] 'multipathd show status' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:19:22.024 826121 DEBUG oslo.privsep.daemon [-] privsep: Exception during request[d2f90e82-191a-4abe-8e2e-29fcc249670c]: [Errno 2] No such file or directory: 'multipathd' [00;33m{{(pid=826121) _process_cmd /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:481}}[00m
Traceback (most recent call last):
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py", line 478, in _process_cmd
    ret = func(*f_args, **f_kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/priv_context.py", line 266, in _wrap
    return func(*args, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 198, in execute_root
    return custom_execute(*cmd, shell=False, run_as_root=False, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 146, in custom_execute
    return putils.execute(on_execute=on_execute,
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py", line 354, in execute
    obj = subprocess.Popen(cmd,
  File "/usr/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'multipathd'
2025-10-14 17:19:22.029 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[d2f90e82-191a-4abe-8e2e-29fcc249670c]: (5, 'builtins.FileNotFoundError', (2, 'No such file or directory')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:22.032 807113 DEBUG os_brick.initiator.connectors.base [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:19:22.033 807113 DEBUG os_brick.initiator.connectors.base [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:19:22.034 807113 INFO os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Trying to connect to iSCSI portal 172.25.59.221:3260
2025-10-14 17:19:22.036 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:22.056 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260" returned: 21 in 0.019s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:22.057 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[cf0ab372-d64a-4d1f-89c7-6e66d3133a73]: (4, ('', 'iscsiadm: No records found\n')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:22.058 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm (): stdout= stderr=iscsiadm: No records found
 [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:19:22.061 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --interface default --op new [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:22.082 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --interface default --op new" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:22.083 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[ed162cbb-1e62-4942-ab8d-ef944a7d60ff]: (4, ('New iSCSI node [tcp:[hw=,ip=,net_if=,iscsi_if=default] 172.25.59.221,3260,-1 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target] added\n', 'iscsiadm: config file line 337 do not has value\niscsiadm: config file line 337 do not has value\niscsiadm: config file line 337 do not has value\niscsiadm: config file line 337 do not has value\n')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:22.085 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--interface', 'default', '--op', 'new'): stdout=New iSCSI node [tcp:[hw=,ip=,net_if=,iscsi_if=default] 172.25.59.221,3260,-1 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target] added
 stderr=iscsiadm: config file line 337 do not has value
iscsiadm: config file line 337 do not has value
iscsiadm: config file line 337 do not has value
iscsiadm: config file line 337 do not has value
 [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:19:22.086 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Retrying to connect to iSCSI portal 172.25.59.221:3260 [00;33m{{(pid=807113) _connect_to_iscsi_portal_unsafe /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1131}}[00m
2025-10-14 17:19:22.087 807113 DEBUG os_brick.utils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Finished call to 'os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe' after 0.053(s), this was the 1st time calling it. [00;33m{{(pid=807113) log_it /opt/stack/data/venv/lib/python3.10/site-packages/tenacity/after.py:44}}[00m
2025-10-14 17:19:22.089 807113 DEBUG os_brick.utils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Retrying os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe in 1.0 seconds as it raised BrickException: An unknown exception occurred.. [00;33m{{(pid=807113) log_it /opt/stack/data/venv/lib/python3.10/site-packages/tenacity/before_sleep.py:65}}[00m
2025-10-14 17:19:23.091 807113 INFO os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Trying to connect to iSCSI portal 172.25.59.221:3260
2025-10-14 17:19:23.093 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:23.114 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:23.115 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[51bf08d6-3271-47b2-b0e4-aa1c910bb695]: (4, ('# BEGIN RECORD 2.1.5\nnode.name = iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\nnode.tpgt = -1\nnode.startup = manual\nnode.leading_login = No\niface.iscsi_ifacename = default\niface.net_ifacename = <empty>\niface.ipaddress = <empty>\niface.prefix_len = 0\niface.hwaddress = <empty>\niface.transport_name = tcp\niface.initiatorname = <empty>\niface.state = <empty>\niface.vlan_id = 0\niface.vlan_priority = 0\niface.vlan_state = <empty>\niface.iface_num = 0\niface.mtu = 0\niface.port = 0\niface.bootproto = <empty>\niface.subnet_mask = <empty>\niface.gateway = <empty>\niface.dhcp_alt_client_id_state = <empty>\niface.dhcp_alt_client_id = <empty>\niface.dhcp_dns = <empty>\niface.dhcp_learn_iqn = <empty>\niface.dhcp_req_vendor_id_state = <empty>\niface.dhcp_vendor_id_state = <empty>\niface.dhcp_vendor_id = <empty>\niface.dhcp_slp_da = <empty>\niface.fragmentation = <empty>\niface.gratuitous_arp = <empty>\niface.incoming_forwarding = <empty>\niface.tos_state = <empty>\niface.tos = 0\niface.ttl = 0\niface.delayed_ack = <empty>\niface.tcp_nagle = <empty>\niface.tcp_wsf_state = <empty>\niface.tcp_wsf = 0\niface.tcp_timer_scale = 0\niface.tcp_timestamp = <empty>\niface.redirect = <empty>\niface.def_task_mgmt_timeout = 0\niface.header_digest = <empty>\niface.data_digest = <empty>\niface.immediate_data = <empty>\niface.initial_r2t = <empty>\niface.data_seq_inorder = <empty>\niface.data_pdu_inorder = <empty>\niface.erl = 0\niface.max_receive_data_len = 0\niface.first_burst_len = 0\niface.max_outstanding_r2t = 0\niface.max_burst_len = 0\niface.chap_auth = <empty>\niface.bidi_chap = <empty>\niface.strict_login_compliance = <empty>\niface.discovery_auth = <empty>\niface.discovery_logout = <empty>\nnode.discovery_address = <empty>\nnode.discovery_port = 0\nnode.discovery_type = static\nnode.session.initial_cmdsn = 0\nnode.session.initial_login_retry_max = 8\nnode.session.xmit_thread_priority = -20\nnode.session.cmds_max = 128\nnode.session.queue_depth = 32\nnode.session.nr_sessions = 1\nnode.session.auth.authmethod = None\nnode.session.auth.username = <empty>\nnode.session.auth.password = <empty>\nnode.session.auth.username_in = <empty>\nnode.session.auth.password_in = <empty>\nnode.session.auth.chap_algs = SHA3-256,SHA256\nnode.session.timeo.replacement_timeout = 120\nnode.session.err_timeo.abort_timeout = 15\nnode.session.err_timeo.lu_reset_timeout = 30\nnode.session.err_timeo.tgt_reset_timeout = 30\nnode.session.err_timeo.host_reset_timeout = 60\nnode.session.iscsi.FastAbort = Yes\nnode.session.iscsi.InitialR2T = No\nnode.session.iscsi.ImmediateData = Yes\nnode.session.iscsi.FirstBurstLength = 262144\nnode.session.iscsi.MaxBurstLength = 16776192\nnode.session.iscsi.DefaultTime2Retain = 0\nnode.session.iscsi.DefaultTime2Wait = 2\nnode.session.iscsi.MaxConnections = 1\nnode.session.iscsi.MaxOutstandingR2T = 1\nnode.session.iscsi.ERL = 0\nnode.session.scan = auto\nnode.session.reopen_max = 0\nnode.conn[0].address = 172.25.59.221\nnode.conn[0].port = 3260\nnode.conn[0].startup = manual\nnode.conn[0].tcp.window_size = 524288\nnode.conn[0].tcp.type_of_service = 0\nnode.conn[0].timeo.logout_timeout = 15\nnode.conn[0].timeo.login_timeout = 15\nnode.conn[0].timeo.auth_timeout = 45\nnode.conn[0].timeo.noop_out_interval = 5\nnode.conn[0].timeo.noop_out_timeout = 5\nnode.conn[0].iscsi.MaxXmitDataSegmentLength = 0\nnode.conn[0].iscsi.MaxRecvDataSegmentLength = 262144\nnode.conn[0].iscsi.HeaderDigest = None\nnode.conn[0].iscsi.DataDigest = None\nnode.conn[0].iscsi.IFMarker = No\nnode.conn[0].iscsi.OFMarker = No\n# END RECORD\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:23.120 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm (): stdout=# BEGIN RECORD 2.1.5
node.name = iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target
node.tpgt = -1
node.startup = manual
node.leading_login = No
iface.iscsi_ifacename = default
iface.net_ifacename = <empty>
iface.ipaddress = <empty>
iface.prefix_len = 0
iface.hwaddress = <empty>
iface.transport_name = tcp
iface.initiatorname = <empty>
iface.state = <empty>
iface.vlan_id = 0
iface.vlan_priority = 0
iface.vlan_state = <empty>
iface.iface_num = 0
iface.mtu = 0
iface.port = 0
iface.bootproto = <empty>
iface.subnet_mask = <empty>
iface.gateway = <empty>
iface.dhcp_alt_client_id_state = <empty>
iface.dhcp_alt_client_id = <empty>
iface.dhcp_dns = <empty>
iface.dhcp_learn_iqn = <empty>
iface.dhcp_req_vendor_id_state = <empty>
iface.dhcp_vendor_id_state = <empty>
iface.dhcp_vendor_id = <empty>
iface.dhcp_slp_da = <empty>
iface.fragmentation = <empty>
iface.gratuitous_arp = <empty>
iface.incoming_forwarding = <empty>
iface.tos_state = <empty>
iface.tos = 0
iface.ttl = 0
iface.delayed_ack = <empty>
iface.tcp_nagle = <empty>
iface.tcp_wsf_state = <empty>
iface.tcp_wsf = 0
iface.tcp_timer_scale = 0
iface.tcp_timestamp = <empty>
iface.redirect = <empty>
iface.def_task_mgmt_timeout = 0
iface.header_digest = <empty>
iface.data_digest = <empty>
iface.immediate_data = <empty>
iface.initial_r2t = <empty>
iface.data_seq_inorder = <empty>
iface.data_pdu_inorder = <empty>
iface.erl = 0
iface.max_receive_data_len = 0
iface.first_burst_len = 0
iface.max_outstanding_r2t = 0
iface.max_burst_len = 0
iface.chap_auth = <empty>
iface.bidi_chap = <empty>
iface.strict_login_compliance = <empty>
iface.discovery_auth = <empty>
iface.discovery_logout = <empty>
node.discovery_address = <empty>
node.discovery_port = 0
node.discovery_type = static
node.session.initial_cmdsn = 0
node.session.initial_login_retry_max = 8
node.session.xmit_thread_priority = -20
node.session.cmds_max = 128
node.session.queue_depth = 32
node.session.nr_sessions = 1
node.session.auth.authmethod = None
node.session.auth.username = <empty>
node.session.auth.password = ***
node.session.auth.username_in = <empty>
node.session.auth.password_in = <empty>
node.session.auth.chap_algs = SHA3-256,SHA256
node.session.timeo.replacement_timeout = 120
node.session.err_timeo.abort_timeout = 15
node.session.err_timeo.lu_reset_timeout = 30
node.session.err_timeo.tgt_reset_timeout = 30
node.session.err_timeo.host_reset_timeout = 60
node.session.iscsi.FastAbort = Yes
node.session.iscsi.InitialR2T = No
node.session.iscsi.ImmediateData = Yes
node.session.iscsi.FirstBurstLength = 262144
node.session.iscsi.MaxBurstLength = 16776192
node.session.iscsi.DefaultTime2Retain = 0
node.session.iscsi.DefaultTime2Wait = 2
node.session.iscsi.MaxConnections = 1
node.session.iscsi.MaxOutstandingR2T = 1
node.session.iscsi.ERL = 0
node.session.scan = auto
node.session.reopen_max = 0
node.conn[0].address = 172.25.59.221
node.conn[0].port = 3260
node.conn[0].startup = manual
node.conn[0].tcp.window_size = 524288
node.conn[0].tcp.type_of_service = 0
node.conn[0].timeo.logout_timeout = 15
node.conn[0].timeo.login_timeout = 15
node.conn[0].timeo.auth_timeout = 45
node.conn[0].timeo.noop_out_interval = 5
node.conn[0].timeo.noop_out_timeout = 5
node.conn[0].iscsi.MaxXmitDataSegmentLength = 0
node.conn[0].iscsi.MaxRecvDataSegmentLength = 262144
node.conn[0].iscsi.HeaderDigest = None
node.conn[0].iscsi.DataDigest = None
node.conn[0].iscsi.IFMarker = No
node.conn[0].iscsi.OFMarker = No
# END RECORD
 stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:19:23.122 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.session.scan -v manual [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:23.145 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.session.scan -v manual" returned: 0 in 0.023s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:23.147 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[addb5767-3a16-47d2-bce9-d4fab0daccce]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:23.148 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'update', '-n', 'node.session.scan', '-v', 'manual'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:19:23.151 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:23.171 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 21 in 0.020s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:23.172 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[aab06267-0a4b-40b5-bdf5-a1b79bf3a1f3]: (4, ('', 'iscsiadm: No active sessions.\n')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:23.174 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout= stderr=iscsiadm: No active sessions.
 [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:19:23.175 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout= stderr=iscsiadm: No active sessions.
 [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:19:23.175 807113 WARNING os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm stderr output when getting sessions: iscsiadm: No active sessions.

2025-10-14 17:19:23.177 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --login [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:24.227 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --login" returned: 0 in 1.049s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:24.228 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[7546760c-0d49-441b-993c-bb3e8ac4f2e7]: (4, ('Logging in to [iface: default, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260]\nLogin to [iface: default, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260] successful.\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:24.229 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--login',): stdout=Logging in to [iface: default, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260]
Login to [iface: default, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260] successful.
 stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:19:24.231 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.startup -v automatic [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:24.250 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.startup -v automatic" returned: 0 in 0.019s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:24.251 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[01a45bda-23c3-4933-a089-1bf4caa51f8d]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:24.252 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'update', '-n', 'node.startup', '-v', 'automatic'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:19:24.254 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:24.275 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:24.277 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[c3665428-6538-4d21-ac92-6c783d1f247c]: (4, ('tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:24.278 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:19:24.279 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:19:24.280 807113 DEBUG os_brick.initiator.connectors.base [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" :: held 2.247s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:19:24.281 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connected to 172.25.59.221:3260 [00;33m{{(pid=807113) _connect_vol /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:659}}[00m
2025-10-14 17:19:24.283 807113 DEBUG os_brick.initiator.linuxscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] HCTL ('33', '-', '-', 1) found on session 17 with lun 1 [00;33m{{(pid=807113) get_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:788}}[00m
2025-10-14 17:19:24.284 807113 DEBUG os_brick.initiator.linuxscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Scanning host 33 c: -, t: -, l: 1) [00;33m{{(pid=807113) scan_iscsi /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:814}}[00m
2025-10-14 17:19:24.286 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): tee -a /sys/class/scsi_host/host33/scan [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:24.320 826121 DEBUG oslo_concurrency.processutils [-] CMD "tee -a /sys/class/scsi_host/host33/scan" returned: 0 in 0.034s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:24.321 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[f6579db9-4ec0-4097-a255-788c972b463f]: (4, ('- - 1', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:24.326 807113 DEBUG os_brick.initiator.linuxscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching for a device in session 17 and hctl ['33', '*', '*', 1] yield: sdb [00;33m{{(pid=807113) device_name_by_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:808}}[00m
2025-10-14 17:19:24.327 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connected to sdb using {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 1, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True} [00;33m{{(pid=807113) _connect_vol /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:687}}[00m
2025-10-14 17:19:25.331 807113 DEBUG os_brick.initiator.connectors.base [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" :: held 3.324s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:19:25.332 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== connect_volume: return (3326ms) {'type': 'block', 'scsi_wwn': '360060e8008757e000050757e000055f2', 'path': '/dev/sdb'} [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:19:25.333 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Attached iSCSI volume {'type': 'block', 'scsi_wwn': '360060e8008757e000050757e000055f2', 'path': '/dev/sdb'} [00;33m{{(pid=807113) connect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:66}}[00m
2025-10-14 17:19:25.342 807113 DEBUG nova.objects.instance [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:19:25.856 807113 DEBUG nova.virt.libvirt.guest [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] attach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-6143228d-e127-4fba-8b40-e8d79c7b0c72"/>
  <source dev="/dev/sdb"/>
  <target dev="vdb" bus="virtio"/>
  <serial>6143228d-e127-4fba-8b40-e8d79c7b0c72</serial>
</disk>
 [00;33m{{(pid=807113) attach_device /opt/stack/nova/nova/virt/libvirt/guest.py:336}}[00m
2025-10-14 17:19:26.491 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:27.755 807113 DEBUG nova.virt.libvirt.driver [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vda, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:19:27.756 807113 DEBUG nova.virt.libvirt.driver [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vdb, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:19:27.757 807113 DEBUG nova.virt.libvirt.driver [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No VIF found with MAC fa:16:3e:55:eb:ee, not building metadata [00;33m{{(pid=807113) _build_interface_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12794}}[00m
2025-10-14 17:19:31.494 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:36.497 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:48.476 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:48.481 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:48.482 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering BACKOFF [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:19:49.483 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:49.485 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering CONNECTING [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:19:49.486 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLOUT] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:49.487 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:19:49.489 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:49.494 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:49.556 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:50.584 807113 DEBUG oslo_concurrency.lockutils [req-c5b7d14e-9e89-4635-a938-8e611d1242e0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" :: held 43.359s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:19:50.927 807113 DEBUG oslo_concurrency.lockutils [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:19:50.928 807113 DEBUG oslo_concurrency.lockutils [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:19:51.438 807113 DEBUG nova.objects.instance [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:19:52.454 807113 DEBUG oslo_concurrency.lockutils [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" :: held 1.526s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:19:53.638 807113 DEBUG oslo_concurrency.lockutils [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:19:53.640 807113 DEBUG oslo_concurrency.lockutils [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:19:53.640 807113 INFO nova.compute.manager [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Attaching volume 73706d59-5ba8-4c8e-8953-1fad2944615a to /dev/vdc
2025-10-14 17:19:53.720 807113 DEBUG os_brick.utils [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> get_connector_properties: call "{'root_helper': 'sudo nova-rootwrap /etc/nova/rootwrap.conf', 'my_ip': '172.25.93.55', 'multipath': False, 'enforce_multipath': True, 'host': 'devstack-u2204-93-55', 'execute': None}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:19:53.722 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): cat /etc/iscsi/initiatorname.iscsi [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:53.737 826121 DEBUG oslo_concurrency.processutils [-] CMD "cat /etc/iscsi/initiatorname.iscsi" returned: 0 in 0.015s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:53.737 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[1f34f9be-e370-4579-a8ae-630df47a1a92]: (4, ('InitiatorName=iqn.2016-04.com.open-iscsi:851997e07f81\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:53.741 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): findmnt -v / -n -o SOURCE [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:53.758 826121 DEBUG oslo_concurrency.processutils [-] CMD "findmnt -v / -n -o SOURCE" returned: 0 in 0.017s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:53.759 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[8b994e2a-5c35-4ecd-9275-13ba4cb875c6]: (4, ('/dev/sda2\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:53.761 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): blkid /dev/sda2 -s UUID -o value [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:53.783 826121 DEBUG oslo_concurrency.processutils [-] CMD "blkid /dev/sda2 -s UUID -o value" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:53.784 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[3e934c7f-9328-4489-8720-e69bd2d7b7a5]: (4, ('849a1340-77d5-4de3-852c-cf0210ca78af\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:53.787 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[dbe9b4f8-ae80-431f-8238-8ac4a0da95c0]: (4, '89b11b42-6ca2-76fb-88b9-4b0fae22b322') [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:53.789 807113 DEBUG oslo_concurrency.processutils [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): nvme version [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:53.823 807113 DEBUG oslo_concurrency.processutils [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] 'nvme version' failed. Not Retrying. [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:19:53.827 807113 DEBUG os_brick.initiator.connectors.nvmeof [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] nvme not present on system [00;33m{{(pid=807113) nvme_present /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/nvmeof.py:784}}[00m
2025-10-14 17:19:53.831 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): nvme show-hostnqn [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:53.845 826121 DEBUG oslo_concurrency.processutils [-] 'nvme show-hostnqn' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:19:53.846 826121 WARNING os_brick.privileged.nvmeof [-] Could not generate host nqn: [Errno 2] No such file or directory: 'nvme'
2025-10-14 17:19:53.847 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[7f5cc317-ed00-49a8-9d06-c27eae646f2d]: (4, '') [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:19:53.853 807113 DEBUG os_brick.initiator.connectors.lightos [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: [Errno 111] ECONNREFUSED [00;33m{{(pid=807113) find_dsc /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:135}}[00m
2025-10-14 17:19:53.855 807113 INFO os_brick.initiator.connectors.lightos [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Current host hostNQN  and IP(s) are ['172.25.93.55', 'fe80::387c:9d0a:2c22:5c64', '192.168.122.1', '172.24.5.1', 'fe80::7c4c:53ff:fed4:fe47', 'fe80::fc16:3eff:fe55:ebee'] 
2025-10-14 17:19:53.856 807113 DEBUG os_brick.initiator.connectors.lightos [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: did not find dsc, continuing anyway. [00;33m{{(pid=807113) get_connector_properties /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:112}}[00m
2025-10-14 17:19:53.857 807113 DEBUG os_brick.initiator.connectors.lightos [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: no hostnqn found. [00;33m{{(pid=807113) get_connector_properties /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:121}}[00m
2025-10-14 17:19:53.858 807113 DEBUG os_brick.utils [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== get_connector_properties: return (136ms) {'platform': 'x86_64', 'os_type': 'linux', 'ip': '172.25.93.55', 'host': 'devstack-u2204-93-55', 'multipath': False, 'enforce_multipath': True, 'initiator': 'iqn.2016-04.com.open-iscsi:851997e07f81', 'do_local_attach': False, 'uuid': '849a1340-77d5-4de3-852c-cf0210ca78af', 'system uuid': '89b11b42-6ca2-76fb-88b9-4b0fae22b322', 'nvme_native_multipath': False} [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:19:53.859 807113 DEBUG nova.virt.block_device [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updating existing volume attachment record: 296e119e-9eb8-46bc-86fd-b5923b1cbd7e [00;33m{{(pid=807113) _volume_attach /opt/stack/nova/nova/virt/block_device.py:666}}[00m
2025-10-14 17:19:54.621 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4972-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:54.623 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:54.624 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5004 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:19:54.625 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:19:54.626 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:54.627 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:19:54.800 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:56.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:57.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:57.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:57.293 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:19:57.294 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:19:57.810 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:19:57.812 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:19:57.813 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:19:57.814 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:19:58.875 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:58.974 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.099s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:58.978 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:59.061 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.083s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:59.064 807113 DEBUG nova.virt.libvirt.driver [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] skipping disk /dev/sdb (vdb) as it is a volume [00;33m{{(pid=807113) _get_instance_disk_info_from_config /opt/stack/nova/nova/virt/libvirt/driver.py:11941}}[00m
2025-10-14 17:19:59.292 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:19:59.328 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.035s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:19:59.330 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=14571MB free_disk=172.3321647644043GB free_vcpus=7 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:19:59.331 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:19:59.333 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:19:59.628 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:59.632 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:19:59.632 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5005 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:19:59.633 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:19:59.634 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:19:59.636 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:20:00.590 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:20:00.591 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 1 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:20:00.592 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=704MB phys_disk=194GB used_disk=1GB total_vcpus=8 used_vcpus=1 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:19:59 up 1 day,  6:47,  5 users,  load average: 8.87, 3.76, 2.28\n', 'num_instances': '1', 'num_vm_active': '1', 'num_task_None': '1', 'num_os_type_None': '1', 'num_proj_1eef17e93cf14f169df902f14b44a4e3': '1', 'io_workload': '0'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:20:00.635 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Refreshing inventories for resource provider 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) _refresh_associations /opt/stack/nova/nova/scheduler/client/report.py:822}}[00m
2025-10-14 17:20:00.674 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Updating ProviderTree inventory for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 from _refresh_and_get_inventory using data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) _refresh_and_get_inventory /opt/stack/nova/nova/scheduler/client/report.py:786}}[00m
2025-10-14 17:20:00.675 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Updating inventory in ProviderTree for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 with inventory: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:176}}[00m
2025-10-14 17:20:00.707 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Refreshing aggregate associations for resource provider 074ba663-40c5-4090-8b4a-a216c63d8a77, aggregates: None [00;33m{{(pid=807113) _refresh_associations /opt/stack/nova/nova/scheduler/client/report.py:831}}[00m
2025-10-14 17:20:00.760 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Refreshing trait associations for resource provider 074ba663-40c5-4090-8b4a-a216c63d8a77, traits: HW_CPU_X86_SSE42,COMPUTE_STORAGE_BUS_SCSI,HW_CPU_X86_SSE,COMPUTE_NET_VIF_MODEL_VIRTIO,COMPUTE_NET_VIF_MODEL_LAN9118,COMPUTE_GRAPHICS_MODEL_VIRTIO,COMPUTE_TRUSTED_CERTS,COMPUTE_NET_VIF_MODEL_E1000,COMPUTE_IMAGE_TYPE_ISO,COMPUTE_NET_VIF_MODEL_SPAPR_VLAN,COMPUTE_IMAGE_TYPE_AMI,COMPUTE_STORAGE_BUS_SATA,HW_CPU_X86_SSSE3,COMPUTE_SOCKET_PCI_NUMA_AFFINITY,COMPUTE_VOLUME_MULTI_ATTACH,COMPUTE_ARCH_AARCH64,COMPUTE_VIOMMU_MODEL_AUTO,COMPUTE_ACCELERATORS,COMPUTE_GRAPHICS_MODEL_NONE,COMPUTE_STORAGE_BUS_IDE,HW_CPU_X86_SSE41,COMPUTE_GRAPHICS_MODEL_VGA,COMPUTE_IMAGE_TYPE_AKI,COMPUTE_NET_VIRTIO_PACKED,COMPUTE_SECURITY_UEFI_SECURE_BOOT,COMPUTE_ARCH_MIPSEL,COMPUTE_NET_VIF_MODEL_E1000E,COMPUTE_NET_ATTACH_INTERFACE_WITH_TAG,COMPUTE_GRAPHICS_MODEL_VMVGA,COMPUTE_ARCH_X86_64,COMPUTE_IMAGE_TYPE_ARI,COMPUTE_NET_VIF_MODEL_VMXNET3,COMPUTE_GRAPHICS_MODEL_QXL,COMPUTE_VIOMMU_MODEL_INTEL,COMPUTE_NET_ATTACH_INTERFACE,COMPUTE_RESCUE_BFV,COMPUTE_STORAGE_BUS_VIRTIO,COMPUTE_VOLUME_EXTEND,COMPUTE_NET_VIF_MODEL_NE2K_PCI,COMPUTE_IMAGE_TYPE_RAW,COMPUTE_STORAGE_BUS_FDC,COMPUTE_ARCH_PPC64LE,COMPUTE_VOLUME_ATTACH_WITH_TAG,COMPUTE_NODE,COMPUTE_ARCH_RISCV64,HW_CPU_X86_MMX,COMPUTE_IMAGE_TYPE_QCOW2,COMPUTE_NET_VIF_MODEL_RTL8139,COMPUTE_GRAPHICS_MODEL_CIRRUS,COMPUTE_NET_VIF_MODEL_PCNET,COMPUTE_GRAPHICS_MODEL_BOCHS,COMPUTE_DEVICE_TAGGING,HW_CPU_X86_SSE2,HW_ARCH_X86_64,COMPUTE_ARCH_S390X,COMPUTE_STORAGE_VIRTIO_FS,COMPUTE_STORAGE_BUS_USB,COMPUTE_VIOMMU_MODEL_SMMUV3 [00;33m{{(pid=807113) _refresh_associations /opt/stack/nova/nova/scheduler/client/report.py:843}}[00m
2025-10-14 17:20:00.841 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:20:01.349 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:20:01.874 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:20:01.875 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.542s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:01.999 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Calling os-brick to attach iSCSI Volume [00;33m{{(pid=807113) connect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:64}}[00m
2025-10-14 17:20:02.001 807113 DEBUG os_brick.initiator.connectors.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> connect_volume: call "{'self': <os_brick.initiator.connectors.iscsi.ISCSIConnector object at 0x7a59504d4550>, 'connection_properties': {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 0, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True}}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:20:02.002 807113 DEBUG os_brick.initiator.connectors.base [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_volume" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:20:02.004 807113 DEBUG os_brick.initiator.connectors.base [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:20:02.005 807113 DEBUG os_brick.initiator.connectors.base [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connection properties {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 0, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True} [00;33m{{(pid=807113) check_multipath /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:133}}[00m
2025-10-14 17:20:02.007 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): multipathd show status [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:02.021 826121 DEBUG oslo_concurrency.processutils [-] 'multipathd show status' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:20:02.022 826121 DEBUG oslo.privsep.daemon [-] privsep: Exception during request[9c48a355-64e1-41a5-ab3a-167c25573adb]: [Errno 2] No such file or directory: 'multipathd' [00;33m{{(pid=826121) _process_cmd /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:481}}[00m
Traceback (most recent call last):
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py", line 478, in _process_cmd
    ret = func(*f_args, **f_kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/priv_context.py", line 266, in _wrap
    return func(*args, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 198, in execute_root
    return custom_execute(*cmd, shell=False, run_as_root=False, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 146, in custom_execute
    return putils.execute(on_execute=on_execute,
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py", line 354, in execute
    obj = subprocess.Popen(cmd,
  File "/usr/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'multipathd'
2025-10-14 17:20:02.024 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[9c48a355-64e1-41a5-ab3a-167c25573adb]: (5, 'builtins.FileNotFoundError', (2, 'No such file or directory')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:02.026 807113 DEBUG os_brick.initiator.connectors.base [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:20:02.028 807113 DEBUG os_brick.initiator.connectors.base [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:20:02.029 807113 INFO os_brick.initiator.connectors.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Trying to connect to iSCSI portal 172.25.59.221:3260
2025-10-14 17:20:02.031 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:02.051 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:02.053 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[6df3b29d-733a-46f8-b79a-3b7e93ec69b8]: (4, ('# BEGIN RECORD 2.1.5\nnode.name = iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\nnode.tpgt = -1\nnode.startup = automatic\nnode.leading_login = No\niface.iscsi_ifacename = default\niface.net_ifacename = <empty>\niface.ipaddress = <empty>\niface.prefix_len = 0\niface.hwaddress = <empty>\niface.transport_name = tcp\niface.initiatorname = <empty>\niface.state = <empty>\niface.vlan_id = 0\niface.vlan_priority = 0\niface.vlan_state = <empty>\niface.iface_num = 0\niface.mtu = 0\niface.port = 0\niface.bootproto = <empty>\niface.subnet_mask = <empty>\niface.gateway = <empty>\niface.dhcp_alt_client_id_state = <empty>\niface.dhcp_alt_client_id = <empty>\niface.dhcp_dns = <empty>\niface.dhcp_learn_iqn = <empty>\niface.dhcp_req_vendor_id_state = <empty>\niface.dhcp_vendor_id_state = <empty>\niface.dhcp_vendor_id = <empty>\niface.dhcp_slp_da = <empty>\niface.fragmentation = <empty>\niface.gratuitous_arp = <empty>\niface.incoming_forwarding = <empty>\niface.tos_state = <empty>\niface.tos = 0\niface.ttl = 0\niface.delayed_ack = <empty>\niface.tcp_nagle = <empty>\niface.tcp_wsf_state = <empty>\niface.tcp_wsf = 0\niface.tcp_timer_scale = 0\niface.tcp_timestamp = <empty>\niface.redirect = <empty>\niface.def_task_mgmt_timeout = 0\niface.header_digest = <empty>\niface.data_digest = <empty>\niface.immediate_data = <empty>\niface.initial_r2t = <empty>\niface.data_seq_inorder = <empty>\niface.data_pdu_inorder = <empty>\niface.erl = 0\niface.max_receive_data_len = 0\niface.first_burst_len = 0\niface.max_outstanding_r2t = 0\niface.max_burst_len = 0\niface.chap_auth = <empty>\niface.bidi_chap = <empty>\niface.strict_login_compliance = <empty>\niface.discovery_auth = <empty>\niface.discovery_logout = <empty>\nnode.discovery_address = <empty>\nnode.discovery_port = 0\nnode.discovery_type = static\nnode.session.initial_cmdsn = 0\nnode.session.initial_login_retry_max = 8\nnode.session.xmit_thread_priority = -20\nnode.session.cmds_max = 128\nnode.session.queue_depth = 32\nnode.session.nr_sessions = 1\nnode.session.auth.authmethod = None\nnode.session.auth.username = <empty>\nnode.session.auth.password = <empty>\nnode.session.auth.username_in = <empty>\nnode.session.auth.password_in = <empty>\nnode.session.auth.chap_algs = SHA3-256,SHA256\nnode.session.timeo.replacement_timeout = 120\nnode.session.err_timeo.abort_timeout = 15\nnode.session.err_timeo.lu_reset_timeout = 30\nnode.session.err_timeo.tgt_reset_timeout = 30\nnode.session.err_timeo.host_reset_timeout = 60\nnode.session.iscsi.FastAbort = Yes\nnode.session.iscsi.InitialR2T = No\nnode.session.iscsi.ImmediateData = Yes\nnode.session.iscsi.FirstBurstLength = 262144\nnode.session.iscsi.MaxBurstLength = 16776192\nnode.session.iscsi.DefaultTime2Retain = 0\nnode.session.iscsi.DefaultTime2Wait = 2\nnode.session.iscsi.MaxConnections = 1\nnode.session.iscsi.MaxOutstandingR2T = 1\nnode.session.iscsi.ERL = 0\nnode.session.scan = manual\nnode.session.reopen_max = 0\nnode.conn[0].address = 172.25.59.221\nnode.conn[0].port = 3260\nnode.conn[0].startup = manual\nnode.conn[0].tcp.window_size = 524288\nnode.conn[0].tcp.type_of_service = 0\nnode.conn[0].timeo.logout_timeout = 15\nnode.conn[0].timeo.login_timeout = 15\nnode.conn[0].timeo.auth_timeout = 45\nnode.conn[0].timeo.noop_out_interval = 5\nnode.conn[0].timeo.noop_out_timeout = 5\nnode.conn[0].iscsi.MaxXmitDataSegmentLength = 0\nnode.conn[0].iscsi.MaxRecvDataSegmentLength = 262144\nnode.conn[0].iscsi.HeaderDigest = None\nnode.conn[0].iscsi.DataDigest = None\nnode.conn[0].iscsi.IFMarker = No\nnode.conn[0].iscsi.OFMarker = No\n# END RECORD\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:02.057 807113 DEBUG os_brick.initiator.connectors.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm (): stdout=# BEGIN RECORD 2.1.5
node.name = iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target
node.tpgt = -1
node.startup = automatic
node.leading_login = No
iface.iscsi_ifacename = default
iface.net_ifacename = <empty>
iface.ipaddress = <empty>
iface.prefix_len = 0
iface.hwaddress = <empty>
iface.transport_name = tcp
iface.initiatorname = <empty>
iface.state = <empty>
iface.vlan_id = 0
iface.vlan_priority = 0
iface.vlan_state = <empty>
iface.iface_num = 0
iface.mtu = 0
iface.port = 0
iface.bootproto = <empty>
iface.subnet_mask = <empty>
iface.gateway = <empty>
iface.dhcp_alt_client_id_state = <empty>
iface.dhcp_alt_client_id = <empty>
iface.dhcp_dns = <empty>
iface.dhcp_learn_iqn = <empty>
iface.dhcp_req_vendor_id_state = <empty>
iface.dhcp_vendor_id_state = <empty>
iface.dhcp_vendor_id = <empty>
iface.dhcp_slp_da = <empty>
iface.fragmentation = <empty>
iface.gratuitous_arp = <empty>
iface.incoming_forwarding = <empty>
iface.tos_state = <empty>
iface.tos = 0
iface.ttl = 0
iface.delayed_ack = <empty>
iface.tcp_nagle = <empty>
iface.tcp_wsf_state = <empty>
iface.tcp_wsf = 0
iface.tcp_timer_scale = 0
iface.tcp_timestamp = <empty>
iface.redirect = <empty>
iface.def_task_mgmt_timeout = 0
iface.header_digest = <empty>
iface.data_digest = <empty>
iface.immediate_data = <empty>
iface.initial_r2t = <empty>
iface.data_seq_inorder = <empty>
iface.data_pdu_inorder = <empty>
iface.erl = 0
iface.max_receive_data_len = 0
iface.first_burst_len = 0
iface.max_outstanding_r2t = 0
iface.max_burst_len = 0
iface.chap_auth = <empty>
iface.bidi_chap = <empty>
iface.strict_login_compliance = <empty>
iface.discovery_auth = <empty>
iface.discovery_logout = <empty>
node.discovery_address = <empty>
node.discovery_port = 0
node.discovery_type = static
node.session.initial_cmdsn = 0
node.session.initial_login_retry_max = 8
node.session.xmit_thread_priority = -20
node.session.cmds_max = 128
node.session.queue_depth = 32
node.session.nr_sessions = 1
node.session.auth.authmethod = None
node.session.auth.username = <empty>
node.session.auth.password = ***
node.session.auth.username_in = <empty>
node.session.auth.password_in = <empty>
node.session.auth.chap_algs = SHA3-256,SHA256
node.session.timeo.replacement_timeout = 120
node.session.err_timeo.abort_timeout = 15
node.session.err_timeo.lu_reset_timeout = 30
node.session.err_timeo.tgt_reset_timeout = 30
node.session.err_timeo.host_reset_timeout = 60
node.session.iscsi.FastAbort = Yes
node.session.iscsi.InitialR2T = No
node.session.iscsi.ImmediateData = Yes
node.session.iscsi.FirstBurstLength = 262144
node.session.iscsi.MaxBurstLength = 16776192
node.session.iscsi.DefaultTime2Retain = 0
node.session.iscsi.DefaultTime2Wait = 2
node.session.iscsi.MaxConnections = 1
node.session.iscsi.MaxOutstandingR2T = 1
node.session.iscsi.ERL = 0
node.session.scan = manual
node.session.reopen_max = 0
node.conn[0].address = 172.25.59.221
node.conn[0].port = 3260
node.conn[0].startup = manual
node.conn[0].tcp.window_size = 524288
node.conn[0].tcp.type_of_service = 0
node.conn[0].timeo.logout_timeout = 15
node.conn[0].timeo.login_timeout = 15
node.conn[0].timeo.auth_timeout = 45
node.conn[0].timeo.noop_out_interval = 5
node.conn[0].timeo.noop_out_timeout = 5
node.conn[0].iscsi.MaxXmitDataSegmentLength = 0
node.conn[0].iscsi.MaxRecvDataSegmentLength = 262144
node.conn[0].iscsi.HeaderDigest = None
node.conn[0].iscsi.DataDigest = None
node.conn[0].iscsi.IFMarker = No
node.conn[0].iscsi.OFMarker = No
# END RECORD
 stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:20:02.059 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.session.scan -v manual [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:02.082 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.session.scan -v manual" returned: 0 in 0.023s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:02.083 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[e9ae8a54-e92c-41f6-bab9-ba8677f11d55]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:02.085 807113 DEBUG os_brick.initiator.connectors.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'update', '-n', 'node.session.scan', '-v', 'manual'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:20:02.087 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:02.110 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 0 in 0.023s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:02.111 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[421e33d6-091b-409b-89ed-4abccfe03266]: (4, ('tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:02.113 807113 DEBUG os_brick.initiator.connectors.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:20:02.114 807113 DEBUG os_brick.initiator.connectors.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:20:02.115 807113 DEBUG os_brick.initiator.connectors.base [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" :: held 0.087s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:20:02.116 807113 DEBUG os_brick.initiator.connectors.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connected to 172.25.59.221:3260 [00;33m{{(pid=807113) _connect_vol /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:659}}[00m
2025-10-14 17:20:02.117 807113 DEBUG os_brick.initiator.linuxscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] HCTL ('33', '0', '0', 0) found on session 17 with lun 0 [00;33m{{(pid=807113) get_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:788}}[00m
2025-10-14 17:20:02.118 807113 DEBUG os_brick.initiator.linuxscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Scanning host 33 c: 0, t: 0, l: 0) [00;33m{{(pid=807113) scan_iscsi /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:814}}[00m
2025-10-14 17:20:02.120 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): tee -a /sys/class/scsi_host/host33/scan [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:02.167 826121 DEBUG oslo_concurrency.processutils [-] CMD "tee -a /sys/class/scsi_host/host33/scan" returned: 0 in 0.047s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:02.168 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[1492d1bc-b632-4376-a704-332108ee1faa]: (4, ('0 0 0', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:02.170 807113 DEBUG os_brick.initiator.linuxscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching for a device in session 17 and hctl ('33', '0', '0', 0) yield: None [00;33m{{(pid=807113) device_name_by_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:808}}[00m
2025-10-14 17:20:03.173 807113 DEBUG os_brick.initiator.linuxscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching for a device in session 17 and hctl ('33', '0', '0', 0) yield: sdc [00;33m{{(pid=807113) device_name_by_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:808}}[00m
2025-10-14 17:20:03.174 807113 DEBUG os_brick.initiator.connectors.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connected to sdc using {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 0, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True} [00;33m{{(pid=807113) _connect_vol /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:687}}[00m
2025-10-14 17:20:03.176 807113 DEBUG os_brick.initiator.connectors.base [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" :: held 1.172s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:20:03.177 807113 DEBUG os_brick.initiator.connectors.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== connect_volume: return (1174ms) {'type': 'block', 'scsi_wwn': '360060e8008757e000050757e000055f4', 'path': '/dev/sdc'} [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:20:03.178 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Attached iSCSI volume {'type': 'block', 'scsi_wwn': '360060e8008757e000050757e000055f4', 'path': '/dev/sdc'} [00;33m{{(pid=807113) connect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:66}}[00m
2025-10-14 17:20:03.186 807113 DEBUG nova.objects.instance [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:20:03.698 807113 DEBUG nova.virt.libvirt.guest [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] attach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-73706d59-5ba8-4c8e-8953-1fad2944615a"/>
  <source dev="/dev/sdc"/>
  <target dev="vdc" bus="virtio"/>
  <serial>73706d59-5ba8-4c8e-8953-1fad2944615a</serial>
</disk>
 [00;33m{{(pid=807113) attach_device /opt/stack/nova/nova/virt/libvirt/guest.py:336}}[00m
2025-10-14 17:20:03.869 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:20:03.870 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_scheduler_instance_info [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:20:03.871 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:20:03.872 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:20:04.636 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:20:04.638 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:20:04.639 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:20:04.639 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:20:04.641 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:04.642 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:20:05.600 807113 DEBUG nova.virt.libvirt.driver [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vda, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:20:05.601 807113 DEBUG nova.virt.libvirt.driver [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vdb, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:20:05.601 807113 DEBUG nova.virt.libvirt.driver [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vdc, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:20:05.602 807113 DEBUG nova.virt.libvirt.driver [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No VIF found with MAC fa:16:3e:55:eb:ee, not building metadata [00;33m{{(pid=807113) _build_interface_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12794}}[00m
2025-10-14 17:20:06.514 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:07.200 807113 DEBUG oslo_concurrency.lockutils [req-1517dfc1-f4bc-448c-b495-020e3519d473 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" :: held 13.561s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:08.333 807113 DEBUG oslo_concurrency.lockutils [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:08.335 807113 DEBUG oslo_concurrency.lockutils [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:20:08.847 807113 DEBUG nova.objects.instance [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:20:09.864 807113 DEBUG oslo_concurrency.lockutils [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" :: held 1.529s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:11.016 807113 DEBUG oslo_concurrency.lockutils [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:11.018 807113 DEBUG oslo_concurrency.lockutils [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:20:11.019 807113 INFO nova.compute.manager [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Attaching volume 25868f8c-06ce-4319-9d90-346bddc4bf70 to /dev/vdd
2025-10-14 17:20:11.117 807113 DEBUG os_brick.utils [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> get_connector_properties: call "{'root_helper': 'sudo nova-rootwrap /etc/nova/rootwrap.conf', 'my_ip': '172.25.93.55', 'multipath': False, 'enforce_multipath': True, 'host': 'devstack-u2204-93-55', 'execute': None}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:20:11.119 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): cat /etc/iscsi/initiatorname.iscsi [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:11.137 826121 DEBUG oslo_concurrency.processutils [-] CMD "cat /etc/iscsi/initiatorname.iscsi" returned: 0 in 0.017s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:11.138 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[c3a8234b-9e7f-4ba5-9a79-a6b6b98176cf]: (4, ('InitiatorName=iqn.2016-04.com.open-iscsi:851997e07f81\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:11.143 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): findmnt -v / -n -o SOURCE [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:11.160 826121 DEBUG oslo_concurrency.processutils [-] CMD "findmnt -v / -n -o SOURCE" returned: 0 in 0.017s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:11.162 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[f0dd462e-3649-449d-a70d-6d829ea13584]: (4, ('/dev/sda2\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:11.165 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): blkid /dev/sda2 -s UUID -o value [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:11.180 826121 DEBUG oslo_concurrency.processutils [-] CMD "blkid /dev/sda2 -s UUID -o value" returned: 0 in 0.014s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:11.180 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[4be69876-dfe9-4792-889c-75969d1fe8c9]: (4, ('849a1340-77d5-4de3-852c-cf0210ca78af\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:11.183 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[9a524c1f-d429-4375-b718-fec10a717799]: (4, '89b11b42-6ca2-76fb-88b9-4b0fae22b322') [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:11.185 807113 DEBUG oslo_concurrency.processutils [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): nvme version [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:11.209 807113 DEBUG oslo_concurrency.processutils [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] 'nvme version' failed. Not Retrying. [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:20:11.211 807113 DEBUG os_brick.initiator.connectors.nvmeof [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] nvme not present on system [00;33m{{(pid=807113) nvme_present /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/nvmeof.py:784}}[00m
2025-10-14 17:20:11.213 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): nvme show-hostnqn [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:11.223 826121 DEBUG oslo_concurrency.processutils [-] 'nvme show-hostnqn' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:20:11.223 826121 WARNING os_brick.privileged.nvmeof [-] Could not generate host nqn: [Errno 2] No such file or directory: 'nvme'
2025-10-14 17:20:11.224 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[3dd32046-ed31-469f-9afc-ce80b85ca3ac]: (4, '') [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:11.228 807113 DEBUG os_brick.initiator.connectors.lightos [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: [Errno 111] ECONNREFUSED [00;33m{{(pid=807113) find_dsc /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:135}}[00m
2025-10-14 17:20:11.230 807113 INFO os_brick.initiator.connectors.lightos [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Current host hostNQN  and IP(s) are ['172.25.93.55', 'fe80::387c:9d0a:2c22:5c64', '192.168.122.1', '172.24.5.1', 'fe80::7c4c:53ff:fed4:fe47', 'fe80::fc16:3eff:fe55:ebee'] 
2025-10-14 17:20:11.231 807113 DEBUG os_brick.initiator.connectors.lightos [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: did not find dsc, continuing anyway. [00;33m{{(pid=807113) get_connector_properties /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:112}}[00m
2025-10-14 17:20:11.231 807113 DEBUG os_brick.initiator.connectors.lightos [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: no hostnqn found. [00;33m{{(pid=807113) get_connector_properties /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:121}}[00m
2025-10-14 17:20:11.232 807113 DEBUG os_brick.utils [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== get_connector_properties: return (113ms) {'platform': 'x86_64', 'os_type': 'linux', 'ip': '172.25.93.55', 'host': 'devstack-u2204-93-55', 'multipath': False, 'enforce_multipath': True, 'initiator': 'iqn.2016-04.com.open-iscsi:851997e07f81', 'do_local_attach': False, 'uuid': '849a1340-77d5-4de3-852c-cf0210ca78af', 'system uuid': '89b11b42-6ca2-76fb-88b9-4b0fae22b322', 'nvme_native_multipath': False} [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:20:11.233 807113 DEBUG nova.virt.block_device [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updating existing volume attachment record: 74a794fc-dfbe-4a80-8280-d822ce4f01e7 [00;33m{{(pid=807113) _volume_attach /opt/stack/nova/nova/virt/block_device.py:666}}[00m
2025-10-14 17:20:11.519 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:14.642 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:16.524 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:19.844 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Calling os-brick to attach iSCSI Volume [00;33m{{(pid=807113) connect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:64}}[00m
2025-10-14 17:20:19.845 807113 DEBUG os_brick.initiator.connectors.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> connect_volume: call "{'self': <os_brick.initiator.connectors.iscsi.ISCSIConnector object at 0x7a59504d4550>, 'connection_properties': {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 2, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True}}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:20:19.846 807113 DEBUG os_brick.initiator.connectors.base [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_volume" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:20:19.848 807113 DEBUG os_brick.initiator.connectors.base [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:20:19.849 807113 DEBUG os_brick.initiator.connectors.base [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connection properties {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 2, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True} [00;33m{{(pid=807113) check_multipath /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:133}}[00m
2025-10-14 17:20:19.851 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): multipathd show status [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:19.865 826121 DEBUG oslo_concurrency.processutils [-] 'multipathd show status' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:20:19.866 826121 DEBUG oslo.privsep.daemon [-] privsep: Exception during request[06a5f7df-b0d0-4fac-bb00-32cd5a2154ea]: [Errno 2] No such file or directory: 'multipathd' [00;33m{{(pid=826121) _process_cmd /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:481}}[00m
Traceback (most recent call last):
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py", line 478, in _process_cmd
    ret = func(*f_args, **f_kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/priv_context.py", line 266, in _wrap
    return func(*args, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 198, in execute_root
    return custom_execute(*cmd, shell=False, run_as_root=False, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 146, in custom_execute
    return putils.execute(on_execute=on_execute,
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py", line 354, in execute
    obj = subprocess.Popen(cmd,
  File "/usr/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'multipathd'
2025-10-14 17:20:19.868 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[06a5f7df-b0d0-4fac-bb00-32cd5a2154ea]: (5, 'builtins.FileNotFoundError', (2, 'No such file or directory')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:19.870 807113 DEBUG os_brick.initiator.connectors.base [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:20:19.872 807113 DEBUG os_brick.initiator.connectors.base [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:20:19.873 807113 INFO os_brick.initiator.connectors.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Trying to connect to iSCSI portal 172.25.59.221:3260
2025-10-14 17:20:19.875 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:19.893 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260" returned: 0 in 0.018s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:19.894 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[1c7665f3-14e5-40ca-95bc-5c09916d8e16]: (4, ('# BEGIN RECORD 2.1.5\nnode.name = iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\nnode.tpgt = -1\nnode.startup = automatic\nnode.leading_login = No\niface.iscsi_ifacename = default\niface.net_ifacename = <empty>\niface.ipaddress = <empty>\niface.prefix_len = 0\niface.hwaddress = <empty>\niface.transport_name = tcp\niface.initiatorname = <empty>\niface.state = <empty>\niface.vlan_id = 0\niface.vlan_priority = 0\niface.vlan_state = <empty>\niface.iface_num = 0\niface.mtu = 0\niface.port = 0\niface.bootproto = <empty>\niface.subnet_mask = <empty>\niface.gateway = <empty>\niface.dhcp_alt_client_id_state = <empty>\niface.dhcp_alt_client_id = <empty>\niface.dhcp_dns = <empty>\niface.dhcp_learn_iqn = <empty>\niface.dhcp_req_vendor_id_state = <empty>\niface.dhcp_vendor_id_state = <empty>\niface.dhcp_vendor_id = <empty>\niface.dhcp_slp_da = <empty>\niface.fragmentation = <empty>\niface.gratuitous_arp = <empty>\niface.incoming_forwarding = <empty>\niface.tos_state = <empty>\niface.tos = 0\niface.ttl = 0\niface.delayed_ack = <empty>\niface.tcp_nagle = <empty>\niface.tcp_wsf_state = <empty>\niface.tcp_wsf = 0\niface.tcp_timer_scale = 0\niface.tcp_timestamp = <empty>\niface.redirect = <empty>\niface.def_task_mgmt_timeout = 0\niface.header_digest = <empty>\niface.data_digest = <empty>\niface.immediate_data = <empty>\niface.initial_r2t = <empty>\niface.data_seq_inorder = <empty>\niface.data_pdu_inorder = <empty>\niface.erl = 0\niface.max_receive_data_len = 0\niface.first_burst_len = 0\niface.max_outstanding_r2t = 0\niface.max_burst_len = 0\niface.chap_auth = <empty>\niface.bidi_chap = <empty>\niface.strict_login_compliance = <empty>\niface.discovery_auth = <empty>\niface.discovery_logout = <empty>\nnode.discovery_address = <empty>\nnode.discovery_port = 0\nnode.discovery_type = static\nnode.session.initial_cmdsn = 0\nnode.session.initial_login_retry_max = 8\nnode.session.xmit_thread_priority = -20\nnode.session.cmds_max = 128\nnode.session.queue_depth = 32\nnode.session.nr_sessions = 1\nnode.session.auth.authmethod = None\nnode.session.auth.username = <empty>\nnode.session.auth.password = <empty>\nnode.session.auth.username_in = <empty>\nnode.session.auth.password_in = <empty>\nnode.session.auth.chap_algs = SHA3-256,SHA256\nnode.session.timeo.replacement_timeout = 120\nnode.session.err_timeo.abort_timeout = 15\nnode.session.err_timeo.lu_reset_timeout = 30\nnode.session.err_timeo.tgt_reset_timeout = 30\nnode.session.err_timeo.host_reset_timeout = 60\nnode.session.iscsi.FastAbort = Yes\nnode.session.iscsi.InitialR2T = No\nnode.session.iscsi.ImmediateData = Yes\nnode.session.iscsi.FirstBurstLength = 262144\nnode.session.iscsi.MaxBurstLength = 16776192\nnode.session.iscsi.DefaultTime2Retain = 0\nnode.session.iscsi.DefaultTime2Wait = 2\nnode.session.iscsi.MaxConnections = 1\nnode.session.iscsi.MaxOutstandingR2T = 1\nnode.session.iscsi.ERL = 0\nnode.session.scan = manual\nnode.session.reopen_max = 0\nnode.conn[0].address = 172.25.59.221\nnode.conn[0].port = 3260\nnode.conn[0].startup = manual\nnode.conn[0].tcp.window_size = 524288\nnode.conn[0].tcp.type_of_service = 0\nnode.conn[0].timeo.logout_timeout = 15\nnode.conn[0].timeo.login_timeout = 15\nnode.conn[0].timeo.auth_timeout = 45\nnode.conn[0].timeo.noop_out_interval = 5\nnode.conn[0].timeo.noop_out_timeout = 5\nnode.conn[0].iscsi.MaxXmitDataSegmentLength = 0\nnode.conn[0].iscsi.MaxRecvDataSegmentLength = 262144\nnode.conn[0].iscsi.HeaderDigest = None\nnode.conn[0].iscsi.DataDigest = None\nnode.conn[0].iscsi.IFMarker = No\nnode.conn[0].iscsi.OFMarker = No\n# END RECORD\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:19.898 807113 DEBUG os_brick.initiator.connectors.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm (): stdout=# BEGIN RECORD 2.1.5
node.name = iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target
node.tpgt = -1
node.startup = automatic
node.leading_login = No
iface.iscsi_ifacename = default
iface.net_ifacename = <empty>
iface.ipaddress = <empty>
iface.prefix_len = 0
iface.hwaddress = <empty>
iface.transport_name = tcp
iface.initiatorname = <empty>
iface.state = <empty>
iface.vlan_id = 0
iface.vlan_priority = 0
iface.vlan_state = <empty>
iface.iface_num = 0
iface.mtu = 0
iface.port = 0
iface.bootproto = <empty>
iface.subnet_mask = <empty>
iface.gateway = <empty>
iface.dhcp_alt_client_id_state = <empty>
iface.dhcp_alt_client_id = <empty>
iface.dhcp_dns = <empty>
iface.dhcp_learn_iqn = <empty>
iface.dhcp_req_vendor_id_state = <empty>
iface.dhcp_vendor_id_state = <empty>
iface.dhcp_vendor_id = <empty>
iface.dhcp_slp_da = <empty>
iface.fragmentation = <empty>
iface.gratuitous_arp = <empty>
iface.incoming_forwarding = <empty>
iface.tos_state = <empty>
iface.tos = 0
iface.ttl = 0
iface.delayed_ack = <empty>
iface.tcp_nagle = <empty>
iface.tcp_wsf_state = <empty>
iface.tcp_wsf = 0
iface.tcp_timer_scale = 0
iface.tcp_timestamp = <empty>
iface.redirect = <empty>
iface.def_task_mgmt_timeout = 0
iface.header_digest = <empty>
iface.data_digest = <empty>
iface.immediate_data = <empty>
iface.initial_r2t = <empty>
iface.data_seq_inorder = <empty>
iface.data_pdu_inorder = <empty>
iface.erl = 0
iface.max_receive_data_len = 0
iface.first_burst_len = 0
iface.max_outstanding_r2t = 0
iface.max_burst_len = 0
iface.chap_auth = <empty>
iface.bidi_chap = <empty>
iface.strict_login_compliance = <empty>
iface.discovery_auth = <empty>
iface.discovery_logout = <empty>
node.discovery_address = <empty>
node.discovery_port = 0
node.discovery_type = static
node.session.initial_cmdsn = 0
node.session.initial_login_retry_max = 8
node.session.xmit_thread_priority = -20
node.session.cmds_max = 128
node.session.queue_depth = 32
node.session.nr_sessions = 1
node.session.auth.authmethod = None
node.session.auth.username = <empty>
node.session.auth.password = ***
node.session.auth.username_in = <empty>
node.session.auth.password_in = <empty>
node.session.auth.chap_algs = SHA3-256,SHA256
node.session.timeo.replacement_timeout = 120
node.session.err_timeo.abort_timeout = 15
node.session.err_timeo.lu_reset_timeout = 30
node.session.err_timeo.tgt_reset_timeout = 30
node.session.err_timeo.host_reset_timeout = 60
node.session.iscsi.FastAbort = Yes
node.session.iscsi.InitialR2T = No
node.session.iscsi.ImmediateData = Yes
node.session.iscsi.FirstBurstLength = 262144
node.session.iscsi.MaxBurstLength = 16776192
node.session.iscsi.DefaultTime2Retain = 0
node.session.iscsi.DefaultTime2Wait = 2
node.session.iscsi.MaxConnections = 1
node.session.iscsi.MaxOutstandingR2T = 1
node.session.iscsi.ERL = 0
node.session.scan = manual
node.session.reopen_max = 0
node.conn[0].address = 172.25.59.221
node.conn[0].port = 3260
node.conn[0].startup = manual
node.conn[0].tcp.window_size = 524288
node.conn[0].tcp.type_of_service = 0
node.conn[0].timeo.logout_timeout = 15
node.conn[0].timeo.login_timeout = 15
node.conn[0].timeo.auth_timeout = 45
node.conn[0].timeo.noop_out_interval = 5
node.conn[0].timeo.noop_out_timeout = 5
node.conn[0].iscsi.MaxXmitDataSegmentLength = 0
node.conn[0].iscsi.MaxRecvDataSegmentLength = 262144
node.conn[0].iscsi.HeaderDigest = None
node.conn[0].iscsi.DataDigest = None
node.conn[0].iscsi.IFMarker = No
node.conn[0].iscsi.OFMarker = No
# END RECORD
 stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:20:19.900 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.session.scan -v manual [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:19.914 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.session.scan -v manual" returned: 0 in 0.014s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:19.916 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[46bf6895-e583-4d7c-852c-bcc4a37f01e5]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:19.917 807113 DEBUG os_brick.initiator.connectors.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'update', '-n', 'node.session.scan', '-v', 'manual'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:20:19.919 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:19.933 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 0 in 0.014s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:19.934 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[af2dfb9e-a758-4ae1-b5de-087437512a56]: (4, ('tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:19.936 807113 DEBUG os_brick.initiator.connectors.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:20:19.937 807113 DEBUG os_brick.initiator.connectors.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:20:19.938 807113 DEBUG os_brick.initiator.connectors.base [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" :: held 0.066s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:20:19.939 807113 DEBUG os_brick.initiator.connectors.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connected to 172.25.59.221:3260 [00;33m{{(pid=807113) _connect_vol /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:659}}[00m
2025-10-14 17:20:19.940 807113 DEBUG os_brick.initiator.linuxscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] HCTL ('33', '0', '0', 2) found on session 17 with lun 2 [00;33m{{(pid=807113) get_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:788}}[00m
2025-10-14 17:20:19.941 807113 DEBUG os_brick.initiator.linuxscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Scanning host 33 c: 0, t: 0, l: 2) [00;33m{{(pid=807113) scan_iscsi /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:814}}[00m
2025-10-14 17:20:19.943 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): tee -a /sys/class/scsi_host/host33/scan [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:19.982 826121 DEBUG oslo_concurrency.processutils [-] CMD "tee -a /sys/class/scsi_host/host33/scan" returned: 0 in 0.040s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:19.984 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[0752ab99-5bbe-4bed-b9bf-2c87f45afeaa]: (4, ('0 0 2', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:20:19.985 807113 DEBUG os_brick.initiator.linuxscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching for a device in session 17 and hctl ('33', '0', '0', 2) yield: None [00;33m{{(pid=807113) device_name_by_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:808}}[00m
2025-10-14 17:20:20.987 807113 DEBUG os_brick.initiator.linuxscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching for a device in session 17 and hctl ('33', '0', '0', 2) yield: sdd [00;33m{{(pid=807113) device_name_by_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:808}}[00m
2025-10-14 17:20:20.988 807113 DEBUG os_brick.initiator.connectors.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connected to sdd using {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 2, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True} [00;33m{{(pid=807113) _connect_vol /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:687}}[00m
2025-10-14 17:20:20.990 807113 DEBUG os_brick.initiator.connectors.base [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" :: held 1.142s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:20:20.991 807113 DEBUG os_brick.initiator.connectors.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== connect_volume: return (1144ms) {'type': 'block', 'scsi_wwn': '360060e8008757e000050757e000055f3', 'path': '/dev/sdd'} [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:20:20.992 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Attached iSCSI volume {'type': 'block', 'scsi_wwn': '360060e8008757e000050757e000055f3', 'path': '/dev/sdd'} [00;33m{{(pid=807113) connect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:66}}[00m
2025-10-14 17:20:21.003 807113 DEBUG nova.objects.instance [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:20:21.520 807113 DEBUG nova.virt.libvirt.guest [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] attach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-25868f8c-06ce-4319-9d90-346bddc4bf70"/>
  <source dev="/dev/sdd"/>
  <target dev="vdd" bus="virtio"/>
  <serial>25868f8c-06ce-4319-9d90-346bddc4bf70</serial>
  <shareable/>
</disk>
 [00;33m{{(pid=807113) attach_device /opt/stack/nova/nova/virt/libvirt/guest.py:336}}[00m
2025-10-14 17:20:21.529 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:23.463 807113 DEBUG nova.virt.libvirt.driver [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vda, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:20:23.464 807113 DEBUG nova.virt.libvirt.driver [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vdb, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:20:23.465 807113 DEBUG nova.virt.libvirt.driver [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vdc, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:20:23.465 807113 DEBUG nova.virt.libvirt.driver [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vdd, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:20:23.466 807113 DEBUG nova.virt.libvirt.driver [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No VIF found with MAC fa:16:3e:55:eb:ee, not building metadata [00;33m{{(pid=807113) _build_interface_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12794}}[00m
2025-10-14 17:20:24.645 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:25.104 807113 DEBUG oslo_concurrency.lockutils [req-76993f1b-1c27-4726-970b-3abfc0b9f5a7 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" :: held 14.086s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:26.534 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:29.294 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "457ce939-5f92-4f51-b71e-041cccbfa57f" by "nova.compute.manager.ComputeManager.build_and_run_instance.<locals>._locked_do_build_and_run_instance" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:29.295 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f" acquired by "nova.compute.manager.ComputeManager.build_and_run_instance.<locals>._locked_do_build_and_run_instance" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:20:29.803 807113 DEBUG nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Starting instance... [00;33m{{(pid=807113) _do_build_and_run_instance /opt/stack/nova/nova/compute/manager.py:2439}}[00m
2025-10-14 17:20:30.361 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.instance_claim" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:30.363 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.instance_claim" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:20:30.375 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Require both a host and instance NUMA topology to fit instance on host. [00;33m{{(pid=807113) numa_fit_instance_to_host /opt/stack/nova/nova/virt/hardware.py:2468}}[00m
2025-10-14 17:20:30.377 807113 INFO nova.compute.claims [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Claim successful on node devstack-u2204-93-55
2025-10-14 17:20:31.529 807113 DEBUG nova.compute.provider_tree [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:20:31.539 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:32.038 807113 DEBUG nova.scheduler.client.report [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:20:32.560 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.instance_claim" :: held 2.197s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:32.562 807113 DEBUG nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Start building networks asynchronously for instance. [00;33m{{(pid=807113) _build_resources /opt/stack/nova/nova/compute/manager.py:2836}}[00m
2025-10-14 17:20:33.081 807113 DEBUG nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Allocating IP information in the background. [00;33m{{(pid=807113) _allocate_network_async /opt/stack/nova/nova/compute/manager.py:1988}}[00m
2025-10-14 17:20:33.082 807113 DEBUG nova.network.neutron [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] allocate_for_instance() [00;33m{{(pid=807113) allocate_for_instance /opt/stack/nova/nova/network/neutron.py:1208}}[00m
2025-10-14 17:20:33.183 807113 DEBUG nova.policy [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Policy check for network:attach_external_network failed with credentials {'is_admin': False, 'user_id': '960a08fcc4d0429e9e879816a305186f', 'user_domain_id': 'default', 'system_scope': None, 'domain_id': None, 'project_id': '1eef17e93cf14f169df902f14b44a4e3', 'project_domain_id': 'default', 'roles': ['member', 'reader'], 'is_admin_project': True, 'service_user_id': None, 'service_user_domain_id': None, 'service_project_id': None, 'service_project_domain_id': None, 'service_roles': []} [00;33m{{(pid=807113) authorize /opt/stack/nova/nova/policy.py:192}}[00m
2025-10-14 17:20:33.589 807113 INFO nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2025-10-14 17:20:34.042 807113 DEBUG nova.network.neutron [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Successfully created port: cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) _create_port_minimal /opt/stack/nova/nova/network/neutron.py:550}}[00m
2025-10-14 17:20:34.099 807113 DEBUG nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Start building block device mappings for instance. [00;33m{{(pid=807113) _build_resources /opt/stack/nova/nova/compute/manager.py:2871}}[00m
2025-10-14 17:20:34.649 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:34.913 807113 DEBUG nova.network.neutron [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Successfully updated port: cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) _update_port /opt/stack/nova/nova/network/neutron.py:588}}[00m
2025-10-14 17:20:34.963 807113 DEBUG nova.compute.manager [req-c4281deb-c904-4c8f-8788-eabaeef0a353 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Received event network-changed-cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:20:34.964 807113 DEBUG nova.compute.manager [req-c4281deb-c904-4c8f-8788-eabaeef0a353 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Refreshing instance network info cache due to event network-changed-cee44034-dbe7-4086-a701-cbdee9e5a9ab. [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11773}}[00m
2025-10-14 17:20:34.965 807113 DEBUG oslo_concurrency.lockutils [req-c4281deb-c904-4c8f-8788-eabaeef0a353 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "refresh_cache-457ce939-5f92-4f51-b71e-041cccbfa57f" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:313}}[00m
2025-10-14 17:20:34.966 807113 DEBUG oslo_concurrency.lockutils [req-c4281deb-c904-4c8f-8788-eabaeef0a353 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquired lock "refresh_cache-457ce939-5f92-4f51-b71e-041cccbfa57f" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:316}}[00m
2025-10-14 17:20:34.967 807113 DEBUG nova.network.neutron [req-c4281deb-c904-4c8f-8788-eabaeef0a353 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Refreshing network info cache for port cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) _get_instance_nw_info /opt/stack/nova/nova/network/neutron.py:2067}}[00m
2025-10-14 17:20:35.124 807113 DEBUG nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Start spawning the instance on the hypervisor. [00;33m{{(pid=807113) _build_and_run_instance /opt/stack/nova/nova/compute/manager.py:2645}}[00m
2025-10-14 17:20:35.128 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Creating instance directory [00;33m{{(pid=807113) _create_image /opt/stack/nova/nova/virt/libvirt/driver.py:5186}}[00m
2025-10-14 17:20:35.129 807113 INFO nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Creating image(s)
2025-10-14 17:20:35.131 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "/opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk.info" by "nova.virt.libvirt.imagebackend.Image.resolve_driver_format.<locals>.write_to_disk_info_file" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:35.132 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "/opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk.info" acquired by "nova.virt.libvirt.imagebackend.Image.resolve_driver_format.<locals>.write_to_disk_info_file" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:20:35.134 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "/opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk.info" "released" by "nova.virt.libvirt.imagebackend.Image.resolve_driver_format.<locals>.write_to_disk_info_file" :: held 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:35.137 807113 DEBUG oslo_utils.imageutils.format_inspector [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vmdk does not match, excluding from consideration (Signature KDMV not found: b'\xebH\x90\x00') [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:20:35.148 807113 DEBUG oslo_utils.imageutils.format_inspector [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vhdx does not match, excluding from consideration (Region signature not found at 30000) [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:20:35.152 807113 DEBUG oslo_concurrency.processutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:35.266 807113 DEBUG oslo_concurrency.processutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json" returned: 0 in 0.114s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:35.268 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" by "nova.virt.libvirt.imagebackend.Qcow2.create_image.<locals>.create_qcow2_image" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:35.269 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" acquired by "nova.virt.libvirt.imagebackend.Qcow2.create_image.<locals>.create_qcow2_image" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:20:35.271 807113 DEBUG oslo_utils.imageutils.format_inspector [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vmdk does not match, excluding from consideration (Signature KDMV not found: b'\xebH\x90\x00') [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:20:35.282 807113 DEBUG oslo_utils.imageutils.format_inspector [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vhdx does not match, excluding from consideration (Region signature not found at 30000) [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:20:35.283 807113 DEBUG oslo_concurrency.processutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:35.386 807113 DEBUG oslo_concurrency.processutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json" returned: 0 in 0.104s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:35.390 807113 DEBUG oslo_concurrency.processutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): env LC_ALL=C LANG=C qemu-img create -f qcow2 -o backing_file=/opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1,backing_fmt=raw /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk 1073741824 [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:35.423 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "refresh_cache-457ce939-5f92-4f51-b71e-041cccbfa57f" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:313}}[00m
2025-10-14 17:20:35.447 807113 DEBUG oslo_concurrency.processutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "env LC_ALL=C LANG=C qemu-img create -f qcow2 -o backing_file=/opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1,backing_fmt=raw /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk 1073741824" returned: 0 in 0.057s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:35.449 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" "released" by "nova.virt.libvirt.imagebackend.Qcow2.create_image.<locals>.create_qcow2_image" :: held 0.180s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:35.450 807113 DEBUG oslo_concurrency.processutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:35.559 807113 DEBUG oslo_concurrency.processutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json" returned: 0 in 0.108s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:35.562 807113 DEBUG nova.virt.disk.api [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Checking if we can resize image /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk. size=1073741824 [00;33m{{(pid=807113) can_resize_image /opt/stack/nova/nova/virt/disk/api.py:164}}[00m
2025-10-14 17:20:35.563 807113 DEBUG oslo_concurrency.processutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:35.591 807113 DEBUG nova.network.neutron [req-c4281deb-c904-4c8f-8788-eabaeef0a353 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Instance cache missing network info. [00;33m{{(pid=807113) _get_preexisting_port_ids /opt/stack/nova/nova/network/neutron.py:3383}}[00m
2025-10-14 17:20:35.671 807113 DEBUG oslo_concurrency.processutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk --force-share --output=json" returned: 0 in 0.108s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:35.673 807113 DEBUG nova.virt.disk.api [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Cannot resize image /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk to a smaller size. [00;33m{{(pid=807113) can_resize_image /opt/stack/nova/nova/virt/disk/api.py:170}}[00m
2025-10-14 17:20:35.674 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Created local disks [00;33m{{(pid=807113) _create_image /opt/stack/nova/nova/virt/libvirt/driver.py:5318}}[00m
2025-10-14 17:20:35.675 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Ensure instance console log exists: /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/console.log [00;33m{{(pid=807113) _ensure_console_log_for_instance /opt/stack/nova/nova/virt/libvirt/driver.py:5072}}[00m
2025-10-14 17:20:35.675 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "vgpu_resources" by "nova.virt.libvirt.driver.LibvirtDriver._allocate_mdevs" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:35.676 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "vgpu_resources" acquired by "nova.virt.libvirt.driver.LibvirtDriver._allocate_mdevs" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:20:35.677 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "vgpu_resources" "released" by "nova.virt.libvirt.driver.LibvirtDriver._allocate_mdevs" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:35.799 807113 DEBUG nova.network.neutron [req-c4281deb-c904-4c8f-8788-eabaeef0a353 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Updating instance_info_cache with network_info: [] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:20:36.309 807113 DEBUG oslo_concurrency.lockutils [req-c4281deb-c904-4c8f-8788-eabaeef0a353 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Releasing lock "refresh_cache-457ce939-5f92-4f51-b71e-041cccbfa57f" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:334}}[00m
2025-10-14 17:20:36.311 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquired lock "refresh_cache-457ce939-5f92-4f51-b71e-041cccbfa57f" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:316}}[00m
2025-10-14 17:20:36.312 807113 DEBUG nova.network.neutron [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Building network info cache for instance [00;33m{{(pid=807113) _get_instance_nw_info /opt/stack/nova/nova/network/neutron.py:2070}}[00m
2025-10-14 17:20:36.871 807113 DEBUG nova.network.neutron [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Instance cache missing network info. [00;33m{{(pid=807113) _get_preexisting_port_ids /opt/stack/nova/nova/network/neutron.py:3383}}[00m
2025-10-14 17:20:37.231 807113 DEBUG nova.network.neutron [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Updating instance_info_cache with network_info: [{"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:20:37.737 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Releasing lock "refresh_cache-457ce939-5f92-4f51-b71e-041cccbfa57f" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:334}}[00m
2025-10-14 17:20:37.738 807113 DEBUG nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Instance network_info: |[{"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}]| [00;33m{{(pid=807113) _allocate_network_async /opt/stack/nova/nova/compute/manager.py:2003}}[00m
2025-10-14 17:20:37.747 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Start _get_guest_xml network_info=[{"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}] disk_info={'disk_bus': 'virtio', 'cdrom_bus': 'ide', 'mapping': {'root': {'bus': 'virtio', 'dev': 'vda', 'type': 'disk', 'boot_index': '1'}, 'disk': {'bus': 'virtio', 'dev': 'vda', 'type': 'disk', 'boot_index': '1'}}} image_meta=ImageMeta(checksum='1352196d1db841ad1931906db5e76ff6',container_format='bare',created_at=2025-10-15T00:04:23Z,direct_url=<?>,disk_format='raw',id=fccdc018-118e-4071-9d16-6a4d7f6e5493,min_disk=0,min_ram=0,name='cirros-0.6.1-x86_64-disk',owner='89c832aae7f04895a3e7cf9ee7f7bb2d',properties=ImageMetaProps,protected=<?>,size=117440512,status='active',tags=<?>,updated_at=2025-10-15T00:04:30Z,virtual_size=<?>,visibility=<?>) rescue=None block_device_info={'root_device_name': '/dev/vda', 'image': [{'encrypted': False, 'boot_index': 0, 'guest_format': None, 'encryption_secret_uuid': None, 'device_type': 'disk', 'disk_bus': 'virtio', 'encryption_format': None, 'device_name': '/dev/vda', 'size': 0, 'encryption_options': None, 'image_id': 'fccdc018-118e-4071-9d16-6a4d7f6e5493'}], 'ephemerals': [], 'block_device_mapping': [], 'swap': None}share_info=None [00;33m{{(pid=807113) _get_guest_xml /opt/stack/nova/nova/virt/libvirt/driver.py:8047}}[00m
2025-10-14 17:20:37.759 807113 DEBUG nova.virt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] InstanceDriverMetadata: InstanceDriverMetadata(root_type='image', root_id='fccdc018-118e-4071-9d16-6a4d7f6e5493', instance_meta=NovaInstanceMeta(name='tempest-VolumeMultiattachTests-server-28408194', uuid='457ce939-5f92-4f51-b71e-041cccbfa57f'), owner=OwnerMeta(userid='960a08fcc4d0429e9e879816a305186f', username='tempest-VolumeMultiattachTests-2017337252-project-member', projectid='1eef17e93cf14f169df902f14b44a4e3', projectname='tempest-VolumeMultiattachTests-2017337252'), image=ImageMeta(id='fccdc018-118e-4071-9d16-6a4d7f6e5493', name=None, properties=ImageMetaProps(hw_architecture=<?>,hw_auto_disk_config=<?>,hw_boot_menu=<?>,hw_cdrom_bus=<?>,hw_cpu_cores=<?>,hw_cpu_max_cores=<?>,hw_cpu_max_sockets=<?>,hw_cpu_max_threads=<?>,hw_cpu_policy=<?>,hw_cpu_realtime_mask=<?>,hw_cpu_sockets=<?>,hw_cpu_thread_policy=<?>,hw_cpu_threads=<?>,hw_device_id=<?>,hw_disk_bus=<?>,hw_disk_type=<?>,hw_emulation_architecture=<?>,hw_ephemeral_encryption=<?>,hw_ephemeral_encryption_format=<?>,hw_ephemeral_encryption_secret_uuid=<?>,hw_firmware_stateless=<?>,hw_firmware_type=<?>,hw_floppy_bus=<?>,hw_input_bus=<?>,hw_ipxe_boot=<?>,hw_locked_memory=<?>,hw_machine_type=<?>,hw_maxphysaddr_bits=<?>,hw_maxphysaddr_mode=<?>,hw_mem_encryption=<?>,hw_mem_page_size=<?>,hw_numa_cpus=<?>,hw_numa_mem=<?>,hw_numa_nodes=<?>,hw_pci_numa_affinity_policy=<?>,hw_pmu=<?>,hw_pointer_model=<?>,hw_qemu_guest_agent=<?>,hw_rescue_bus=<?>,hw_rescue_device=<?>,hw_rng_model='virtio',hw_scsi_model=<?>,hw_serial_port_count=<?>,hw_time_hpet=<?>,hw_tpm_model=<?>,hw_tpm_version=<?>,hw_video_model=<?>,hw_video_ram=<?>,hw_vif_model=<?>,hw_vif_multiqueue_enabled=<?>,hw_viommu_model=<?>,hw_virtio_packed_ring=<?>,hw_vm_mode=<?>,hw_watchdog_action=<?>,img_bdm_v2=<?>,img_bittorrent=<?>,img_block_device_mapping=<?>,img_cache_in_nova=<?>,img_compression_level=<?>,img_config_drive=<?>,img_hide_hypervisor_id=<?>,img_hv_requested_version=<?>,img_hv_type=<?>,img_linked_clone=<?>,img_mappings=<?>,img_owner_id=<?>,img_root_device_name=<?>,img_signature=<?>,img_signature_certificate_uuid=<?>,img_signature_hash_method=<?>,img_signature_key_type=<?>,img_use_agent=<?>,img_version=<?>,os_admin_user=<?>,os_command_line=<?>,os_distro=<?>,os_require_quiesce=<?>,os_secure_boot=<?>,os_skip_agent_inject_files_at_boot=<?>,os_skip_agent_inject_ssh=<?>,os_type=<?>,traits_required=<?>)), flavor=FlavorMeta(name='m1.nano', memory_mb=192, vcpus=1, root_gb=1, ephemeral_gb=0, extra_specs={'hw_rng:allowed': 'True'}, swap=0), network_info=[{"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}], nova_package='31.1.1', creation_time=1760487637.759589) [00;33m{{(pid=807113) get_instance_driver_metadata /opt/stack/nova/nova/virt/driver.py:401}}[00m
2025-10-14 17:20:37.765 807113 DEBUG nova.virt.libvirt.host [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching host: 'devstack-u2204-93-55' for CPU controller through CGroups V1... [00;33m{{(pid=807113) _has_cgroupsv1_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1695}}[00m
2025-10-14 17:20:37.766 807113 DEBUG nova.virt.libvirt.host [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CPU controller missing on host. [00;33m{{(pid=807113) _has_cgroupsv1_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1705}}[00m
2025-10-14 17:20:37.772 807113 DEBUG nova.virt.libvirt.host [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching host: 'devstack-u2204-93-55' for CPU controller through CGroups V2... [00;33m{{(pid=807113) _has_cgroupsv2_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1714}}[00m
2025-10-14 17:20:37.773 807113 DEBUG nova.virt.libvirt.host [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CPU controller found on host. [00;33m{{(pid=807113) _has_cgroupsv2_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1721}}[00m
2025-10-14 17:20:37.776 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CPU mode 'custom' models 'Nehalem' was chosen, with extra flags: '' [00;33m{{(pid=807113) _get_guest_cpu_model_config /opt/stack/nova/nova/virt/libvirt/driver.py:5857}}[00m
2025-10-14 17:20:37.777 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Getting desirable topologies for flavor Flavor(created_at=2025-10-15T00:05:26Z,deleted=False,deleted_at=None,description=None,disabled=False,ephemeral_gb=0,extra_specs={hw_rng:allowed='True'},flavorid='42',id=11,is_public=True,memory_mb=192,name='m1.nano',projects=<?>,root_gb=1,rxtx_factor=1.0,swap=0,updated_at=None,vcpu_weight=0,vcpus=1) and image_meta ImageMeta(checksum='1352196d1db841ad1931906db5e76ff6',container_format='bare',created_at=2025-10-15T00:04:23Z,direct_url=<?>,disk_format='raw',id=fccdc018-118e-4071-9d16-6a4d7f6e5493,min_disk=0,min_ram=0,name='cirros-0.6.1-x86_64-disk',owner='89c832aae7f04895a3e7cf9ee7f7bb2d',properties=ImageMetaProps,protected=<?>,size=117440512,status='active',tags=<?>,updated_at=2025-10-15T00:04:30Z,virtual_size=<?>,visibility=<?>), allow threads: True [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:567}}[00m
2025-10-14 17:20:37.778 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Flavor limits 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:352}}[00m
2025-10-14 17:20:37.779 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Image limits 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:356}}[00m
2025-10-14 17:20:37.780 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Flavor pref 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:392}}[00m
2025-10-14 17:20:37.781 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Image pref 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:396}}[00m
2025-10-14 17:20:37.781 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Chose sockets=0, cores=0, threads=0; limits were sockets=65536, cores=65536, threads=65536 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:434}}[00m
2025-10-14 17:20:37.782 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Topology preferred VirtCPUTopology(cores=0,sockets=0,threads=0), maximum VirtCPUTopology(cores=65536,sockets=65536,threads=65536) [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:573}}[00m
2025-10-14 17:20:37.783 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Build topologies for 1 vcpu(s) 1:1:1 [00;33m{{(pid=807113) _get_possible_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:475}}[00m
2025-10-14 17:20:37.783 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Got 1 possible topologies [00;33m{{(pid=807113) _get_possible_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:505}}[00m
2025-10-14 17:20:37.784 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Possible topologies [VirtCPUTopology(cores=1,sockets=1,threads=1)] [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:579}}[00m
2025-10-14 17:20:37.785 807113 DEBUG nova.virt.hardware [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Sorted desired topologies [VirtCPUTopology(cores=1,sockets=1,threads=1)] [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:581}}[00m
2025-10-14 17:20:37.807 807113 DEBUG nova.virt.libvirt.vif [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] vif_type=ovs instance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone='nova',cell_name=None,cleaned=False,compute_id=1,config_drive='',created_at=2025-10-15T00:20:28Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,device_metadata=None,disable_terminate=False,display_description=None,display_name='tempest-VolumeMultiattachTests-server-28408194',ec2_ids=EC2Ids,ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,flavor=Flavor(11),hidden=False,host='devstack-u2204-93-55',hostname='tempest-volumemultiattachtests-server-28408194',id=2,image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',info_cache=InstanceInfoCache,instance_type_id=11,kernel_id='',key_data='ecdsa-sha2-nistp384 AAAAE2VjZHNhLXNoYTItbmlzdHAzODQAAAAIbmlzdHAzODQAAABhBA8Aiex4gcSHOLfHUTCeqhj7EyM75uU1yg5RlGdYgLuNs2zNO5yK6ijBQYa275YCZkO6CfvUFVYQ+Ps+520EW9lVVkJ9pJ8Md24/YbKYhDFiKsViWmJOf5Nn7uVTraEcEQ==',key_name='tempest-keypair-1058132398',keypairs=KeyPairList,launch_index=0,launched_at=None,launched_on='devstack-u2204-93-55',locked=False,locked_by=None,memory_mb=192,metadata={},migration_context=None,new_flavor=None,node='devstack-u2204-93-55',numa_topology=None,old_flavor=None,os_type=None,pci_devices=<?>,pci_requests=InstancePCIRequests,power_state=0,progress=0,project_id='1eef17e93cf14f169df902f14b44a4e3',ramdisk_id='',reservation_id='r-vp5b6c6n',resources=None,root_device_name='/dev/vda',root_gb=1,security_groups=SecurityGroupList,services=<?>,shutdown_terminate=False,system_metadata={boot_roles='member,reader',image_base_image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',image_container_format='bare',image_disk_format='raw',image_hw_machine_type='pc',image_hw_rng_model='virtio',image_min_disk='1',image_min_ram='0',image_owner_specified.openstack.md5='',image_owner_specified.openstack.object='images/cirros-0.6.1-x86_64-disk',image_owner_specified.openstack.sha256='',network_allocated='True',owner_project_name='tempest-VolumeMultiattachTests-2017337252',owner_user_name='tempest-VolumeMultiattachTests-2017337252-project-member'},tags=TagList,task_state='spawning',terminated_at=None,trusted_certs=None,updated_at=2025-10-15T00:20:34Z,user_data='IyEvYmluL3NoCmVjaG8gIlByaW50aW5nIGNpcnJvcyB1c2VyIGF1dGhvcml6ZWQga2V5cyIKY2F0IH5jaXJyb3MvLnNzaC9hdXRob3JpemVkX2tleXMgfHwgdHJ1ZQo=',user_id='960a08fcc4d0429e9e879816a305186f',uuid=457ce939-5f92-4f51-b71e-041cccbfa57f,vcpu_model=VirtCPUModel,vcpus=1,vm_mode=None,vm_state='building') vif={"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} virt_type=qemu [00;33m{{(pid=807113) get_config /opt/stack/nova/nova/virt/libvirt/vif.py:574}}[00m
2025-10-14 17:20:37.807 807113 DEBUG nova.network.os_vif_util [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converting VIF {"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:511}}[00m
2025-10-14 17:20:37.809 807113 DEBUG nova.network.os_vif_util [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converted object VIFOpenVSwitch(active=False,address=fa:16:3e:93:af:48,bridge_name='br-int',has_traffic_filtering=True,id=cee44034-dbe7-4086-a701-cbdee9e5a9ab,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcee44034-db') [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:548}}[00m
2025-10-14 17:20:37.810 807113 DEBUG nova.objects.instance [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'pci_devices' on Instance uuid 457ce939-5f92-4f51-b71e-041cccbfa57f [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:20:38.317 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] End _get_guest_xml xml=<domain type="qemu">
  <uuid>457ce939-5f92-4f51-b71e-041cccbfa57f</uuid>
  <name>instance-00000002</name>
  <memory>196608</memory>
  <vcpu>1</vcpu>
  <metadata>
    <nova:instance xmlns:nova="http://openstack.org/xmlns/libvirt/nova/1.1">
      <nova:package version="31.1.1"/>
      <nova:name>tempest-VolumeMultiattachTests-server-28408194</nova:name>
      <nova:creationTime>2025-10-15 00:20:37</nova:creationTime>
      <nova:flavor name="m1.nano">
        <nova:memory>192</nova:memory>
        <nova:disk>1</nova:disk>
        <nova:swap>0</nova:swap>
        <nova:ephemeral>0</nova:ephemeral>
        <nova:vcpus>1</nova:vcpus>
      </nova:flavor>
      <nova:owner>
        <nova:user uuid="960a08fcc4d0429e9e879816a305186f">tempest-VolumeMultiattachTests-2017337252-project-member</nova:user>
        <nova:project uuid="1eef17e93cf14f169df902f14b44a4e3">tempest-VolumeMultiattachTests-2017337252</nova:project>
      </nova:owner>
      <nova:root type="image" uuid="fccdc018-118e-4071-9d16-6a4d7f6e5493"/>
      <nova:ports>
        <nova:port uuid="cee44034-dbe7-4086-a701-cbdee9e5a9ab">
          <nova:ip type="fixed" address="10.1.0.4" ipVersion="4"/>
        </nova:port>
      </nova:ports>
    </nova:instance>
  </metadata>
  <sysinfo type="smbios">
    <system>
      <entry name="manufacturer">OpenStack Foundation</entry>
      <entry name="product">OpenStack Nova</entry>
      <entry name="version">31.1.1</entry>
      <entry name="serial">457ce939-5f92-4f51-b71e-041cccbfa57f</entry>
      <entry name="uuid">457ce939-5f92-4f51-b71e-041cccbfa57f</entry>
      <entry name="family">Virtual Machine</entry>
    </system>
  </sysinfo>
  <os>
    <type arch="x86_64" machine="pc">hvm</type>
    <boot dev="hd"/>
    <smbios mode="sysinfo"/>
  </os>
  <features>
    <acpi/>
    <vmcoreinfo/>
  </features>
  <clock offset="utc"/>
  <cpu mode="custom" match="exact">
    <model>Nehalem</model>
    <topology sockets="1" cores="1" threads="1"/>
  </cpu>
  <devices>
    <disk type="file" device="disk">
      <driver name="qemu" type="qcow2" cache="none"/>
      <source file="/opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk"/>
      <target dev="vda" bus="virtio"/>
    </disk>
    <interface type="ethernet">
      <mac address="fa:16:3e:93:af:48"/>
      <model type="virtio"/>
      <driver name="qemu"/>
      <mtu size="1450"/>
      <target dev="tapcee44034-db"/>
    </interface>
    <serial type="pty">
      <log file="/opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/console.log" append="off"/>
    </serial>
    <graphics type="vnc" autoport="yes" listen="0.0.0.0"/>
    <video>
      <model type="virtio"/>
    </video>
    <rng model="virtio">
      <backend model="random">/dev/urandom</backend>
    </rng>
    <controller type="usb" index="0" model="none"/>
    <memballoon model="virtio">
      <stats period="10"/>
    </memballoon>
  </devices>
</domain>
 [00;33m{{(pid=807113) _get_guest_xml /opt/stack/nova/nova/virt/libvirt/driver.py:8053}}[00m
2025-10-14 17:20:38.318 807113 DEBUG nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Preparing to wait for external event network-vif-plugged-cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) prepare_for_instance_event /opt/stack/nova/nova/compute/manager.py:285}}[00m
2025-10-14 17:20:38.319 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" by "nova.compute.manager.InstanceEvents.prepare_for_instance_event.<locals>._create_or_get_event" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:38.320 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" acquired by "nova.compute.manager.InstanceEvents.prepare_for_instance_event.<locals>._create_or_get_event" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:20:38.321 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" "released" by "nova.compute.manager.InstanceEvents.prepare_for_instance_event.<locals>._create_or_get_event" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:38.324 807113 DEBUG nova.virt.libvirt.vif [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] vif_type=ovs instance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone='nova',cell_name=None,cleaned=False,compute_id=1,config_drive='',created_at=2025-10-15T00:20:28Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,device_metadata=None,disable_terminate=False,display_description=None,display_name='tempest-VolumeMultiattachTests-server-28408194',ec2_ids=EC2Ids,ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,flavor=Flavor(11),hidden=False,host='devstack-u2204-93-55',hostname='tempest-volumemultiattachtests-server-28408194',id=2,image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',info_cache=InstanceInfoCache,instance_type_id=11,kernel_id='',key_data='ecdsa-sha2-nistp384 AAAAE2VjZHNhLXNoYTItbmlzdHAzODQAAAAIbmlzdHAzODQAAABhBA8Aiex4gcSHOLfHUTCeqhj7EyM75uU1yg5RlGdYgLuNs2zNO5yK6ijBQYa275YCZkO6CfvUFVYQ+Ps+520EW9lVVkJ9pJ8Md24/YbKYhDFiKsViWmJOf5Nn7uVTraEcEQ==',key_name='tempest-keypair-1058132398',keypairs=KeyPairList,launch_index=0,launched_at=None,launched_on='devstack-u2204-93-55',locked=False,locked_by=None,memory_mb=192,metadata={},migration_context=None,new_flavor=None,node='devstack-u2204-93-55',numa_topology=None,old_flavor=None,os_type=None,pci_devices=PciDeviceList,pci_requests=InstancePCIRequests,power_state=0,progress=0,project_id='1eef17e93cf14f169df902f14b44a4e3',ramdisk_id='',reservation_id='r-vp5b6c6n',resources=None,root_device_name='/dev/vda',root_gb=1,security_groups=SecurityGroupList,services=<?>,shutdown_terminate=False,system_metadata={boot_roles='member,reader',image_base_image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',image_container_format='bare',image_disk_format='raw',image_hw_machine_type='pc',image_hw_rng_model='virtio',image_min_disk='1',image_min_ram='0',image_owner_specified.openstack.md5='',image_owner_specified.openstack.object='images/cirros-0.6.1-x86_64-disk',image_owner_specified.openstack.sha256='',network_allocated='True',owner_project_name='tempest-VolumeMultiattachTests-2017337252',owner_user_name='tempest-VolumeMultiattachTests-2017337252-project-member'},tags=TagList,task_state='spawning',terminated_at=None,trusted_certs=None,updated_at=2025-10-15T00:20:34Z,user_data='IyEvYmluL3NoCmVjaG8gIlByaW50aW5nIGNpcnJvcyB1c2VyIGF1dGhvcml6ZWQga2V5cyIKY2F0IH5jaXJyb3MvLnNzaC9hdXRob3JpemVkX2tleXMgfHwgdHJ1ZQo=',user_id='960a08fcc4d0429e9e879816a305186f',uuid=457ce939-5f92-4f51-b71e-041cccbfa57f,vcpu_model=VirtCPUModel,vcpus=1,vm_mode=None,vm_state='building') vif={"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) plug /opt/stack/nova/nova/virt/libvirt/vif.py:721}}[00m
2025-10-14 17:20:38.325 807113 DEBUG nova.network.os_vif_util [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converting VIF {"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:511}}[00m
2025-10-14 17:20:38.327 807113 DEBUG nova.network.os_vif_util [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converted object VIFOpenVSwitch(active=False,address=fa:16:3e:93:af:48,bridge_name='br-int',has_traffic_filtering=True,id=cee44034-dbe7-4086-a701-cbdee9e5a9ab,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcee44034-db') [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:548}}[00m
2025-10-14 17:20:38.328 807113 DEBUG os_vif [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Plugging vif VIFOpenVSwitch(active=False,address=fa:16:3e:93:af:48,bridge_name='br-int',has_traffic_filtering=True,id=cee44034-dbe7-4086-a701-cbdee9e5a9ab,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcee44034-db') [00;33m{{(pid=807113) plug /opt/stack/data/venv/lib/python3.10/site-packages/os_vif/__init__.py:76}}[00m
2025-10-14 17:20:38.330 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:38.332 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): AddBridgeCommand(_result=None, name=br-int, may_exist=True, datapath_type=system) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:20:38.333 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Transaction caused no change [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:129}}[00m
2025-10-14 17:20:38.336 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:38.336 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): DbCreateCommand(_result=None, table=QoS, columns={'type': 'linux-noop', 'external_ids': {'id': 'ba9d087e-0b4a-5912-b2a1-3295b6e5dd0a', '_type': 'linux-noop'}}, row=False) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:20:38.339 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:38.344 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:20:38.350 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:38.350 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): AddPortCommand(_result=None, bridge=br-int, port=tapcee44034-db, may_exist=True, interface_attrs={}) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:20:38.351 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=1): DbSetCommand(_result=None, table=Port, record=tapcee44034-db, col_values=(('qos', UUID('8a2c6ba4-61cf-46cd-8378-6e857e6b6d0c')),), if_exists=True) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:20:38.352 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=2): DbSetCommand(_result=None, table=Interface, record=tapcee44034-db, col_values=(('external_ids', {'iface-id': 'cee44034-dbe7-4086-a701-cbdee9e5a9ab', 'iface-status': 'active', 'attached-mac': 'fa:16:3e:93:af:48', 'vm-uuid': '457ce939-5f92-4f51-b71e-041cccbfa57f'}),), if_exists=True) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:20:38.354 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:38.361 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:20:38.372 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:38.375 807113 INFO os_vif [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully plugged vif VIFOpenVSwitch(active=False,address=fa:16:3e:93:af:48,bridge_name='br-int',has_traffic_filtering=True,id=cee44034-dbe7-4086-a701-cbdee9e5a9ab,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcee44034-db')
2025-10-14 17:20:38.585 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:38.599 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:38.607 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:38.622 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:38.908 807113 DEBUG nova.compute.manager [req-0782ca7c-054d-4a54-9e80-03ad98168b9d bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Received event network-vif-plugged-cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:20:38.909 807113 DEBUG oslo_concurrency.lockutils [req-0782ca7c-054d-4a54-9e80-03ad98168b9d bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:38.910 807113 DEBUG oslo_concurrency.lockutils [req-0782ca7c-054d-4a54-9e80-03ad98168b9d bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" acquired by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:20:38.910 807113 DEBUG oslo_concurrency.lockutils [req-0782ca7c-054d-4a54-9e80-03ad98168b9d bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" "released" by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:38.911 807113 DEBUG nova.compute.manager [req-0782ca7c-054d-4a54-9e80-03ad98168b9d bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Processing event network-vif-plugged-cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) _process_instance_event /opt/stack/nova/nova/compute/manager.py:11528}}[00m
2025-10-14 17:20:39.926 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vda, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:20:39.927 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No VIF found with MAC fa:16:3e:93:af:48, not building metadata [00;33m{{(pid=807113) _build_interface_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12794}}[00m
2025-10-14 17:20:41.166 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:41.178 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:43.151 807113 DEBUG nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Instance event wait completed in 0 seconds for network-vif-plugged [00;33m{{(pid=807113) wait_for_instance_event /opt/stack/nova/nova/compute/manager.py:579}}[00m
2025-10-14 17:20:43.160 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Guest created on hypervisor [00;33m{{(pid=807113) spawn /opt/stack/nova/nova/virt/libvirt/driver.py:4871}}[00m
2025-10-14 17:20:43.167 807113 INFO nova.virt.libvirt.driver [-] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Instance spawned successfully.
2025-10-14 17:20:43.168 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Attempting to register defaults for the following image properties: ['hw_cdrom_bus', 'hw_disk_bus', 'hw_input_bus', 'hw_pointer_model', 'hw_video_model', 'hw_vif_model'] [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1006}}[00m
2025-10-14 17:20:43.682 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Found default for hw_cdrom_bus of ide [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:20:43.684 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Found default for hw_disk_bus of virtio [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:20:43.686 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Found default for hw_input_bus of None [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:20:43.687 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Found default for hw_pointer_model of None [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:20:43.689 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Found default for hw_video_model of virtio [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:20:43.690 807113 DEBUG nova.virt.libvirt.driver [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Found default for hw_vif_model of virtio [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:20:44.204 807113 INFO nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Took 9.08 seconds to spawn the instance on the hypervisor.
2025-10-14 17:20:44.205 807113 DEBUG nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Checking state [00;33m{{(pid=807113) _get_power_state /opt/stack/nova/nova/compute/manager.py:1798}}[00m
2025-10-14 17:20:44.734 807113 INFO nova.compute.manager [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Took 14.42 seconds to build instance.
2025-10-14 17:20:45.240 807113 DEBUG oslo_concurrency.lockutils [req-ed42618d-4a70-4555-b54c-741b8c700b46 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f" "released" by "nova.compute.manager.ComputeManager.build_and_run_instance.<locals>._locked_do_build_and_run_instance" :: held 15.945s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:46.183 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:20:46.185 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:20:46.185 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:20:46.186 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:20:46.187 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:46.188 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:20:46.548 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:47.486 807113 DEBUG nova.compute.manager [req-38710c73-913f-471b-a9c6-59cf4f4f20fd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Received event network-changed-cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:20:47.487 807113 DEBUG nova.compute.manager [req-38710c73-913f-471b-a9c6-59cf4f4f20fd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Refreshing instance network info cache due to event network-changed-cb17c207-b6b1-4528-8c86-6ec60ca00990. [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11773}}[00m
2025-10-14 17:20:47.488 807113 DEBUG oslo_concurrency.lockutils [req-38710c73-913f-471b-a9c6-59cf4f4f20fd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:313}}[00m
2025-10-14 17:20:47.488 807113 DEBUG oslo_concurrency.lockutils [req-38710c73-913f-471b-a9c6-59cf4f4f20fd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquired lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:316}}[00m
2025-10-14 17:20:47.489 807113 DEBUG nova.network.neutron [req-38710c73-913f-471b-a9c6-59cf4f4f20fd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Refreshing network info cache for port cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) _get_instance_nw_info /opt/stack/nova/nova/network/neutron.py:2067}}[00m
2025-10-14 17:20:48.469 807113 DEBUG nova.network.neutron [req-38710c73-913f-471b-a9c6-59cf4f4f20fd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updated VIF entry in instance network info cache for port cb17c207-b6b1-4528-8c86-6ec60ca00990. [00;33m{{(pid=807113) _build_network_info_model /opt/stack/nova/nova/network/neutron.py:3542}}[00m
2025-10-14 17:20:48.470 807113 DEBUG nova.network.neutron [req-38710c73-913f-471b-a9c6-59cf4f4f20fd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updating instance_info_cache with network_info: [{"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": true, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:20:48.977 807113 DEBUG oslo_concurrency.lockutils [req-38710c73-913f-471b-a9c6-59cf4f4f20fd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Releasing lock "refresh_cache-1c5196e6-48bf-42c2-95c5-4db2adce84ba" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:334}}[00m
2025-10-14 17:20:49.551 807113 DEBUG nova.compute.manager [req-6552c97b-e0eb-40d6-bd1e-7175b81f7373 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Received event network-changed-cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:20:49.552 807113 DEBUG nova.compute.manager [req-6552c97b-e0eb-40d6-bd1e-7175b81f7373 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Refreshing instance network info cache due to event network-changed-cee44034-dbe7-4086-a701-cbdee9e5a9ab. [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11773}}[00m
2025-10-14 17:20:49.552 807113 DEBUG oslo_concurrency.lockutils [req-6552c97b-e0eb-40d6-bd1e-7175b81f7373 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "refresh_cache-457ce939-5f92-4f51-b71e-041cccbfa57f" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:313}}[00m
2025-10-14 17:20:49.553 807113 DEBUG oslo_concurrency.lockutils [req-6552c97b-e0eb-40d6-bd1e-7175b81f7373 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquired lock "refresh_cache-457ce939-5f92-4f51-b71e-041cccbfa57f" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:316}}[00m
2025-10-14 17:20:49.553 807113 DEBUG nova.network.neutron [req-6552c97b-e0eb-40d6-bd1e-7175b81f7373 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Refreshing network info cache for port cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) _get_instance_nw_info /opt/stack/nova/nova/network/neutron.py:2067}}[00m
2025-10-14 17:20:50.650 807113 DEBUG nova.network.neutron [req-6552c97b-e0eb-40d6-bd1e-7175b81f7373 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Updated VIF entry in instance network info cache for port cee44034-dbe7-4086-a701-cbdee9e5a9ab. [00;33m{{(pid=807113) _build_network_info_model /opt/stack/nova/nova/network/neutron.py:3542}}[00m
2025-10-14 17:20:50.652 807113 DEBUG nova.network.neutron [req-6552c97b-e0eb-40d6-bd1e-7175b81f7373 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Updating instance_info_cache with network_info: [{"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": [{"address": "172.24.5.125", "type": "floating", "version": 4, "meta": {}}]}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": true, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:20:51.159 807113 DEBUG oslo_concurrency.lockutils [req-6552c97b-e0eb-40d6-bd1e-7175b81f7373 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Releasing lock "refresh_cache-457ce939-5f92-4f51-b71e-041cccbfa57f" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:334}}[00m
2025-10-14 17:20:51.551 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:20:51.553 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:20:51.553 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:20:51.554 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:20:51.564 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:20:54.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:20:56.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:20:56.558 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:20:57.290 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:20:57.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:20:57.293 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:20:57.294 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:20:57.807 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:57.808 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:20:57.809 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:20:57.809 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:20:58.870 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:58.968 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.098s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:58.972 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:59.080 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.108s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:59.084 807113 DEBUG nova.virt.libvirt.driver [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] skipping disk /dev/sdb (vdb) as it is a volume [00;33m{{(pid=807113) _get_instance_disk_info_from_config /opt/stack/nova/nova/virt/libvirt/driver.py:11941}}[00m
2025-10-14 17:20:59.085 807113 DEBUG nova.virt.libvirt.driver [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] skipping disk /dev/sdc (vdc) as it is a volume [00;33m{{(pid=807113) _get_instance_disk_info_from_config /opt/stack/nova/nova/virt/libvirt/driver.py:11941}}[00m
2025-10-14 17:20:59.085 807113 DEBUG nova.virt.libvirt.driver [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] skipping disk /dev/sdd (vdd) as it is a volume [00;33m{{(pid=807113) _get_instance_disk_info_from_config /opt/stack/nova/nova/virt/libvirt/driver.py:11941}}[00m
2025-10-14 17:20:59.097 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:59.201 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk --force-share --output=json" returned: 0 in 0.104s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:59.204 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:59.320 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk --force-share --output=json" returned: 0 in 0.116s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:59.654 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:20:59.691 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.037s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:20:59.695 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=14157MB free_disk=172.32880401611328GB free_vcpus=6 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:20:59.696 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:20:59.697 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:21:00.775 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:21:00.776 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 457ce939-5f92-4f51-b71e-041cccbfa57f actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:21:00.776 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 2 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:21:00.777 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=896MB phys_disk=194GB used_disk=2GB total_vcpus=8 used_vcpus=2 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:20:59 up 1 day,  6:48,  5 users,  load average: 4.38, 3.35, 2.23\n', 'num_instances': '2', 'num_vm_active': '2', 'num_task_None': '2', 'num_os_type_None': '2', 'num_proj_1eef17e93cf14f169df902f14b44a4e3': '2', 'io_workload': '0'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:21:00.884 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:21:01.391 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:21:01.556 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:01.562 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:01.913 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:21:01.914 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.217s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:21:05.909 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:21:05.910 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:21:05.911 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:21:06.567 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:11.563 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:11.574 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:16.577 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:21.567 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:21.582 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:26.587 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:31.570 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:31.591 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:36.594 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:41.573 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:41.599 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:46.603 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:51.576 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:51.609 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:56.293 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:21:56.615 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:21:58.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:21:58.293 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:21:58.806 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:21:58.807 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:21:58.808 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:21:58.809 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:21:59.879 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:21:59.985 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.106s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:21:59.987 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:00.096 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.109s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:00.099 807113 DEBUG nova.virt.libvirt.driver [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] skipping disk /dev/sdb (vdb) as it is a volume [00;33m{{(pid=807113) _get_instance_disk_info_from_config /opt/stack/nova/nova/virt/libvirt/driver.py:11941}}[00m
2025-10-14 17:22:00.100 807113 DEBUG nova.virt.libvirt.driver [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] skipping disk /dev/sdc (vdc) as it is a volume [00;33m{{(pid=807113) _get_instance_disk_info_from_config /opt/stack/nova/nova/virt/libvirt/driver.py:11941}}[00m
2025-10-14 17:22:00.100 807113 DEBUG nova.virt.libvirt.driver [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] skipping disk /dev/sdd (vdd) as it is a volume [00;33m{{(pid=807113) _get_instance_disk_info_from_config /opt/stack/nova/nova/virt/libvirt/driver.py:11941}}[00m
2025-10-14 17:22:00.112 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:00.217 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk --force-share --output=json" returned: 0 in 0.105s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:00.221 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:00.322 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f/disk --force-share --output=json" returned: 0 in 0.101s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:00.379 807113 DEBUG oslo_concurrency.lockutils [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "457ce939-5f92-4f51-b71e-041cccbfa57f" by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:22:00.381 807113 DEBUG oslo_concurrency.lockutils [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f" acquired by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:22:00.616 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:00.657 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.041s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:00.660 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=13849MB free_disk=172.30008697509766GB free_vcpus=6 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:22:00.661 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:22:00.662 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:22:00.893 807113 DEBUG nova.objects.instance [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 457ce939-5f92-4f51-b71e-041cccbfa57f [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:22:01.580 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:01.620 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:01.737 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:22:01.738 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 457ce939-5f92-4f51-b71e-041cccbfa57f actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:22:01.739 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 2 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:22:01.740 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=896MB phys_disk=194GB used_disk=2GB total_vcpus=8 used_vcpus=2 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:22:00 up 1 day,  6:49,  5 users,  load average: 2.77, 3.05, 2.19\n', 'num_instances': '2', 'num_vm_active': '2', 'num_task_None': '2', 'num_os_type_None': '2', 'num_proj_1eef17e93cf14f169df902f14b44a4e3': '2', 'io_workload': '0'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:22:01.866 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:22:01.908 807113 DEBUG oslo_concurrency.lockutils [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f" "released" by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" :: held 1.527s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:22:02.374 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:22:02.901 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:22:02.902 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.240s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:22:03.086 807113 DEBUG oslo_concurrency.lockutils [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "457ce939-5f92-4f51-b71e-041cccbfa57f" by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:22:03.087 807113 DEBUG oslo_concurrency.lockutils [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f" acquired by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:22:03.089 807113 INFO nova.compute.manager [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Attaching volume 25868f8c-06ce-4319-9d90-346bddc4bf70 to /dev/vdb
2025-10-14 17:22:03.178 807113 DEBUG os_brick.utils [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> get_connector_properties: call "{'root_helper': 'sudo nova-rootwrap /etc/nova/rootwrap.conf', 'my_ip': '172.25.93.55', 'multipath': False, 'enforce_multipath': True, 'host': 'devstack-u2204-93-55', 'execute': None}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:22:03.181 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): cat /etc/iscsi/initiatorname.iscsi [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:03.197 826121 DEBUG oslo_concurrency.processutils [-] CMD "cat /etc/iscsi/initiatorname.iscsi" returned: 0 in 0.016s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:03.198 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[75f6cc94-e506-4d9a-9d38-b03539a49eef]: (4, ('InitiatorName=iqn.2016-04.com.open-iscsi:851997e07f81\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:22:03.202 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): findmnt -v / -n -o SOURCE [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:03.219 826121 DEBUG oslo_concurrency.processutils [-] CMD "findmnt -v / -n -o SOURCE" returned: 0 in 0.017s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:03.221 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[86a113bf-7cae-4954-81ee-dddcf4cfbe8e]: (4, ('/dev/sda2\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:22:03.223 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): blkid /dev/sda2 -s UUID -o value [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:03.240 826121 DEBUG oslo_concurrency.processutils [-] CMD "blkid /dev/sda2 -s UUID -o value" returned: 0 in 0.017s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:03.241 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[79bb079c-577b-4d4a-8d84-d1627544fcbc]: (4, ('849a1340-77d5-4de3-852c-cf0210ca78af\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:22:03.244 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[5bf6c3ab-4c9e-4c5d-9244-fb00fc27d480]: (4, '89b11b42-6ca2-76fb-88b9-4b0fae22b322') [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:22:03.245 807113 DEBUG oslo_concurrency.processutils [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): nvme version [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:03.277 807113 DEBUG oslo_concurrency.processutils [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] 'nvme version' failed. Not Retrying. [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:22:03.280 807113 DEBUG os_brick.initiator.connectors.nvmeof [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] nvme not present on system [00;33m{{(pid=807113) nvme_present /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/nvmeof.py:784}}[00m
2025-10-14 17:22:03.283 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): nvme show-hostnqn [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:03.293 826121 DEBUG oslo_concurrency.processutils [-] 'nvme show-hostnqn' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:22:03.294 826121 WARNING os_brick.privileged.nvmeof [-] Could not generate host nqn: [Errno 2] No such file or directory: 'nvme'
2025-10-14 17:22:03.294 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[a4a32ad2-566a-4917-adf2-d52dadf45eed]: (4, '') [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:22:03.300 807113 DEBUG os_brick.initiator.connectors.lightos [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: [Errno 111] ECONNREFUSED [00;33m{{(pid=807113) find_dsc /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:135}}[00m
2025-10-14 17:22:03.302 807113 INFO os_brick.initiator.connectors.lightos [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Current host hostNQN  and IP(s) are ['172.25.93.55', 'fe80::387c:9d0a:2c22:5c64', '192.168.122.1', '172.24.5.1', 'fe80::7c4c:53ff:fed4:fe47', 'fe80::fc16:3eff:fe55:ebee', 'fe80::fc16:3eff:fe93:af48'] 
2025-10-14 17:22:03.303 807113 DEBUG os_brick.initiator.connectors.lightos [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: did not find dsc, continuing anyway. [00;33m{{(pid=807113) get_connector_properties /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:112}}[00m
2025-10-14 17:22:03.304 807113 DEBUG os_brick.initiator.connectors.lightos [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: no hostnqn found. [00;33m{{(pid=807113) get_connector_properties /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:121}}[00m
2025-10-14 17:22:03.305 807113 DEBUG os_brick.utils [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== get_connector_properties: return (125ms) {'platform': 'x86_64', 'os_type': 'linux', 'ip': '172.25.93.55', 'host': 'devstack-u2204-93-55', 'multipath': False, 'enforce_multipath': True, 'initiator': 'iqn.2016-04.com.open-iscsi:851997e07f81', 'do_local_attach': False, 'uuid': '849a1340-77d5-4de3-852c-cf0210ca78af', 'system uuid': '89b11b42-6ca2-76fb-88b9-4b0fae22b322', 'nvme_native_multipath': False} [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:22:03.306 807113 DEBUG nova.virt.block_device [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Updating existing volume attachment record: e7cb0e67-0833-4c38-af4e-ccb0531f353b [00;33m{{(pid=807113) _volume_attach /opt/stack/nova/nova/virt/block_device.py:666}}[00m
2025-10-14 17:22:03.901 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:22:03.903 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_scheduler_instance_info [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:22:03.904 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:22:03.905 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:22:03.905 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:22:03.906 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:22:03.907 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:22:06.625 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:11.583 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:11.629 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:12.924 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Calling os-brick to attach iSCSI Volume [00;33m{{(pid=807113) connect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:64}}[00m
2025-10-14 17:22:12.925 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> connect_volume: call "{'self': <os_brick.initiator.connectors.iscsi.ISCSIConnector object at 0x7a59504d4550>, 'connection_properties': {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 2, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True}}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:22:12.926 807113 DEBUG os_brick.initiator.connectors.base [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_volume" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:22:12.929 807113 DEBUG os_brick.initiator.connectors.base [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:22:12.929 807113 DEBUG os_brick.initiator.connectors.base [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connection properties {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 2, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True} [00;33m{{(pid=807113) check_multipath /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:133}}[00m
2025-10-14 17:22:12.931 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): multipathd show status [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:12.946 826121 DEBUG oslo_concurrency.processutils [-] 'multipathd show status' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:22:12.947 826121 DEBUG oslo.privsep.daemon [-] privsep: Exception during request[e4b15ca7-04ec-47a8-9a08-6481236a2279]: [Errno 2] No such file or directory: 'multipathd' [00;33m{{(pid=826121) _process_cmd /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:481}}[00m
Traceback (most recent call last):
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py", line 478, in _process_cmd
    ret = func(*f_args, **f_kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/priv_context.py", line 266, in _wrap
    return func(*args, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 198, in execute_root
    return custom_execute(*cmd, shell=False, run_as_root=False, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 146, in custom_execute
    return putils.execute(on_execute=on_execute,
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py", line 354, in execute
    obj = subprocess.Popen(cmd,
  File "/usr/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'multipathd'
2025-10-14 17:22:12.949 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[e4b15ca7-04ec-47a8-9a08-6481236a2279]: (5, 'builtins.FileNotFoundError', (2, 'No such file or directory')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:22:12.951 807113 DEBUG os_brick.initiator.connectors.base [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:22:12.953 807113 DEBUG os_brick.initiator.connectors.base [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:22:12.954 807113 INFO os_brick.initiator.connectors.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Trying to connect to iSCSI portal 172.25.59.221:3260
2025-10-14 17:22:12.956 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:12.980 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260" returned: 0 in 0.024s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:12.981 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[97601195-76f7-4e82-9e1f-5b81a181c3b1]: (4, ('# BEGIN RECORD 2.1.5\nnode.name = iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\nnode.tpgt = -1\nnode.startup = automatic\nnode.leading_login = No\niface.iscsi_ifacename = default\niface.net_ifacename = <empty>\niface.ipaddress = <empty>\niface.prefix_len = 0\niface.hwaddress = <empty>\niface.transport_name = tcp\niface.initiatorname = <empty>\niface.state = <empty>\niface.vlan_id = 0\niface.vlan_priority = 0\niface.vlan_state = <empty>\niface.iface_num = 0\niface.mtu = 0\niface.port = 0\niface.bootproto = <empty>\niface.subnet_mask = <empty>\niface.gateway = <empty>\niface.dhcp_alt_client_id_state = <empty>\niface.dhcp_alt_client_id = <empty>\niface.dhcp_dns = <empty>\niface.dhcp_learn_iqn = <empty>\niface.dhcp_req_vendor_id_state = <empty>\niface.dhcp_vendor_id_state = <empty>\niface.dhcp_vendor_id = <empty>\niface.dhcp_slp_da = <empty>\niface.fragmentation = <empty>\niface.gratuitous_arp = <empty>\niface.incoming_forwarding = <empty>\niface.tos_state = <empty>\niface.tos = 0\niface.ttl = 0\niface.delayed_ack = <empty>\niface.tcp_nagle = <empty>\niface.tcp_wsf_state = <empty>\niface.tcp_wsf = 0\niface.tcp_timer_scale = 0\niface.tcp_timestamp = <empty>\niface.redirect = <empty>\niface.def_task_mgmt_timeout = 0\niface.header_digest = <empty>\niface.data_digest = <empty>\niface.immediate_data = <empty>\niface.initial_r2t = <empty>\niface.data_seq_inorder = <empty>\niface.data_pdu_inorder = <empty>\niface.erl = 0\niface.max_receive_data_len = 0\niface.first_burst_len = 0\niface.max_outstanding_r2t = 0\niface.max_burst_len = 0\niface.chap_auth = <empty>\niface.bidi_chap = <empty>\niface.strict_login_compliance = <empty>\niface.discovery_auth = <empty>\niface.discovery_logout = <empty>\nnode.discovery_address = <empty>\nnode.discovery_port = 0\nnode.discovery_type = static\nnode.session.initial_cmdsn = 0\nnode.session.initial_login_retry_max = 8\nnode.session.xmit_thread_priority = -20\nnode.session.cmds_max = 128\nnode.session.queue_depth = 32\nnode.session.nr_sessions = 1\nnode.session.auth.authmethod = None\nnode.session.auth.username = <empty>\nnode.session.auth.password = <empty>\nnode.session.auth.username_in = <empty>\nnode.session.auth.password_in = <empty>\nnode.session.auth.chap_algs = SHA3-256,SHA256\nnode.session.timeo.replacement_timeout = 120\nnode.session.err_timeo.abort_timeout = 15\nnode.session.err_timeo.lu_reset_timeout = 30\nnode.session.err_timeo.tgt_reset_timeout = 30\nnode.session.err_timeo.host_reset_timeout = 60\nnode.session.iscsi.FastAbort = Yes\nnode.session.iscsi.InitialR2T = No\nnode.session.iscsi.ImmediateData = Yes\nnode.session.iscsi.FirstBurstLength = 262144\nnode.session.iscsi.MaxBurstLength = 16776192\nnode.session.iscsi.DefaultTime2Retain = 0\nnode.session.iscsi.DefaultTime2Wait = 2\nnode.session.iscsi.MaxConnections = 1\nnode.session.iscsi.MaxOutstandingR2T = 1\nnode.session.iscsi.ERL = 0\nnode.session.scan = manual\nnode.session.reopen_max = 0\nnode.conn[0].address = 172.25.59.221\nnode.conn[0].port = 3260\nnode.conn[0].startup = manual\nnode.conn[0].tcp.window_size = 524288\nnode.conn[0].tcp.type_of_service = 0\nnode.conn[0].timeo.logout_timeout = 15\nnode.conn[0].timeo.login_timeout = 15\nnode.conn[0].timeo.auth_timeout = 45\nnode.conn[0].timeo.noop_out_interval = 5\nnode.conn[0].timeo.noop_out_timeout = 5\nnode.conn[0].iscsi.MaxXmitDataSegmentLength = 0\nnode.conn[0].iscsi.MaxRecvDataSegmentLength = 262144\nnode.conn[0].iscsi.HeaderDigest = None\nnode.conn[0].iscsi.DataDigest = None\nnode.conn[0].iscsi.IFMarker = No\nnode.conn[0].iscsi.OFMarker = No\n# END RECORD\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:22:12.985 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm (): stdout=# BEGIN RECORD 2.1.5
node.name = iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target
node.tpgt = -1
node.startup = automatic
node.leading_login = No
iface.iscsi_ifacename = default
iface.net_ifacename = <empty>
iface.ipaddress = <empty>
iface.prefix_len = 0
iface.hwaddress = <empty>
iface.transport_name = tcp
iface.initiatorname = <empty>
iface.state = <empty>
iface.vlan_id = 0
iface.vlan_priority = 0
iface.vlan_state = <empty>
iface.iface_num = 0
iface.mtu = 0
iface.port = 0
iface.bootproto = <empty>
iface.subnet_mask = <empty>
iface.gateway = <empty>
iface.dhcp_alt_client_id_state = <empty>
iface.dhcp_alt_client_id = <empty>
iface.dhcp_dns = <empty>
iface.dhcp_learn_iqn = <empty>
iface.dhcp_req_vendor_id_state = <empty>
iface.dhcp_vendor_id_state = <empty>
iface.dhcp_vendor_id = <empty>
iface.dhcp_slp_da = <empty>
iface.fragmentation = <empty>
iface.gratuitous_arp = <empty>
iface.incoming_forwarding = <empty>
iface.tos_state = <empty>
iface.tos = 0
iface.ttl = 0
iface.delayed_ack = <empty>
iface.tcp_nagle = <empty>
iface.tcp_wsf_state = <empty>
iface.tcp_wsf = 0
iface.tcp_timer_scale = 0
iface.tcp_timestamp = <empty>
iface.redirect = <empty>
iface.def_task_mgmt_timeout = 0
iface.header_digest = <empty>
iface.data_digest = <empty>
iface.immediate_data = <empty>
iface.initial_r2t = <empty>
iface.data_seq_inorder = <empty>
iface.data_pdu_inorder = <empty>
iface.erl = 0
iface.max_receive_data_len = 0
iface.first_burst_len = 0
iface.max_outstanding_r2t = 0
iface.max_burst_len = 0
iface.chap_auth = <empty>
iface.bidi_chap = <empty>
iface.strict_login_compliance = <empty>
iface.discovery_auth = <empty>
iface.discovery_logout = <empty>
node.discovery_address = <empty>
node.discovery_port = 0
node.discovery_type = static
node.session.initial_cmdsn = 0
node.session.initial_login_retry_max = 8
node.session.xmit_thread_priority = -20
node.session.cmds_max = 128
node.session.queue_depth = 32
node.session.nr_sessions = 1
node.session.auth.authmethod = None
node.session.auth.username = <empty>
node.session.auth.password = ***
node.session.auth.username_in = <empty>
node.session.auth.password_in = <empty>
node.session.auth.chap_algs = SHA3-256,SHA256
node.session.timeo.replacement_timeout = 120
node.session.err_timeo.abort_timeout = 15
node.session.err_timeo.lu_reset_timeout = 30
node.session.err_timeo.tgt_reset_timeout = 30
node.session.err_timeo.host_reset_timeout = 60
node.session.iscsi.FastAbort = Yes
node.session.iscsi.InitialR2T = No
node.session.iscsi.ImmediateData = Yes
node.session.iscsi.FirstBurstLength = 262144
node.session.iscsi.MaxBurstLength = 16776192
node.session.iscsi.DefaultTime2Retain = 0
node.session.iscsi.DefaultTime2Wait = 2
node.session.iscsi.MaxConnections = 1
node.session.iscsi.MaxOutstandingR2T = 1
node.session.iscsi.ERL = 0
node.session.scan = manual
node.session.reopen_max = 0
node.conn[0].address = 172.25.59.221
node.conn[0].port = 3260
node.conn[0].startup = manual
node.conn[0].tcp.window_size = 524288
node.conn[0].tcp.type_of_service = 0
node.conn[0].timeo.logout_timeout = 15
node.conn[0].timeo.login_timeout = 15
node.conn[0].timeo.auth_timeout = 45
node.conn[0].timeo.noop_out_interval = 5
node.conn[0].timeo.noop_out_timeout = 5
node.conn[0].iscsi.MaxXmitDataSegmentLength = 0
node.conn[0].iscsi.MaxRecvDataSegmentLength = 262144
node.conn[0].iscsi.HeaderDigest = None
node.conn[0].iscsi.DataDigest = None
node.conn[0].iscsi.IFMarker = No
node.conn[0].iscsi.OFMarker = No
# END RECORD
 stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:22:12.986 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.session.scan -v manual [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:13.009 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.session.scan -v manual" returned: 0 in 0.023s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:13.011 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[8bd21ca7-d4b7-4f64-8271-519a8535be4a]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:22:13.012 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'update', '-n', 'node.session.scan', '-v', 'manual'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:22:13.014 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:13.035 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:13.036 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[658820c7-6841-443c-9cbb-3bb280eccd59]: (4, ('tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:22:13.038 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:22:13.039 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:22:13.040 807113 DEBUG os_brick.initiator.connectors.base [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" :: held 0.087s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:22:13.041 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connected to 172.25.59.221:3260 [00;33m{{(pid=807113) _connect_vol /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:659}}[00m
2025-10-14 17:22:13.042 807113 DEBUG os_brick.initiator.linuxscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] HCTL ('33', '0', '0', 2) found on session 17 with lun 2 [00;33m{{(pid=807113) get_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:788}}[00m
2025-10-14 17:22:13.043 807113 DEBUG os_brick.initiator.linuxscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Scanning host 33 c: 0, t: 0, l: 2) [00;33m{{(pid=807113) scan_iscsi /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:814}}[00m
2025-10-14 17:22:13.045 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): tee -a /sys/class/scsi_host/host33/scan [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:22:13.059 826121 DEBUG oslo_concurrency.processutils [-] CMD "tee -a /sys/class/scsi_host/host33/scan" returned: 0 in 0.014s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:22:13.060 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[b2260f1f-dc13-491c-a9ae-c52e14d8f675]: (4, ('0 0 2', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:22:13.062 807113 DEBUG os_brick.initiator.linuxscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching for a device in session 17 and hctl ('33', '0', '0', 2) yield: sdd [00;33m{{(pid=807113) device_name_by_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:808}}[00m
2025-10-14 17:22:13.063 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connected to sdd using {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 2, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True} [00;33m{{(pid=807113) _connect_vol /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:687}}[00m
2025-10-14 17:22:13.065 807113 DEBUG os_brick.initiator.connectors.base [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" :: held 0.136s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:22:13.066 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== connect_volume: return (139ms) {'type': 'block', 'scsi_wwn': '360060e8008757e000050757e000055f3', 'path': '/dev/sdd'} [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:22:13.067 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Attached iSCSI volume {'type': 'block', 'scsi_wwn': '360060e8008757e000050757e000055f3', 'path': '/dev/sdd'} [00;33m{{(pid=807113) connect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:66}}[00m
2025-10-14 17:22:13.076 807113 DEBUG nova.objects.instance [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 457ce939-5f92-4f51-b71e-041cccbfa57f [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:22:13.591 807113 DEBUG nova.virt.libvirt.guest [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] attach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-25868f8c-06ce-4319-9d90-346bddc4bf70"/>
  <source dev="/dev/sdd"/>
  <target dev="vdb" bus="virtio"/>
  <serial>25868f8c-06ce-4319-9d90-346bddc4bf70</serial>
  <shareable/>
</disk>
 [00;33m{{(pid=807113) attach_device /opt/stack/nova/nova/virt/libvirt/guest.py:336}}[00m
2025-10-14 17:22:15.498 807113 DEBUG nova.virt.libvirt.driver [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vda, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:22:15.499 807113 DEBUG nova.virt.libvirt.driver [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vdb, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:22:15.500 807113 DEBUG nova.virt.libvirt.driver [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No VIF found with MAC fa:16:3e:93:af:48, not building metadata [00;33m{{(pid=807113) _build_interface_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12794}}[00m
2025-10-14 17:22:16.637 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4998-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:16.638 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:16.639 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:22:16.639 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:16.641 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:16.642 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:17.183 807113 DEBUG oslo_concurrency.lockutils [req-d0c4a2dd-134f-48c0-a10f-9b27acaf9e50 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f" "released" by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" :: held 14.096s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:22:19.944 807113 DEBUG oslo_concurrency.lockutils [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "457ce939-5f92-4f51-b71e-041cccbfa57f" by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:22:19.946 807113 DEBUG oslo_concurrency.lockutils [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f" acquired by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:22:20.453 807113 INFO nova.compute.manager [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Detaching volume 25868f8c-06ce-4319-9d90-346bddc4bf70
2025-10-14 17:22:20.550 807113 INFO nova.virt.block_device [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Attempting to driver detach volume 25868f8c-06ce-4319-9d90-346bddc4bf70 from mountpoint /dev/vdb
2025-10-14 17:22:20.564 807113 DEBUG nova.virt.libvirt.driver [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdb by alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:22:20.569 807113 DEBUG nova.virt.libvirt.driver [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdb by alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:22:20.570 807113 DEBUG nova.virt.libvirt.driver [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Attempting to detach device vdb from instance 457ce939-5f92-4f51-b71e-041cccbfa57f from the persistent domain config. [00;33m{{(pid=807113) _detach_from_persistent /opt/stack/nova/nova/virt/libvirt/driver.py:2638}}[00m
2025-10-14 17:22:20.571 807113 DEBUG nova.virt.libvirt.guest [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] detach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-25868f8c-06ce-4319-9d90-346bddc4bf70"/>
  <source dev="/dev/sdd"/>
  <target dev="vdb" bus="virtio"/>
  <serial>25868f8c-06ce-4319-9d90-346bddc4bf70</serial>
  <shareable/>
  <address type="pci" domain="0x0000" bus="0x00" slot="0x07" function="0x0"/>
</disk>
 [00;33m{{(pid=807113) detach_device /opt/stack/nova/nova/virt/libvirt/guest.py:466}}[00m
2025-10-14 17:22:20.584 807113 DEBUG nova.virt.libvirt.driver [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdb by alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:22:20.586 807113 WARNING nova.virt.libvirt.driver [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Failed to detach device vdb from instance 457ce939-5f92-4f51-b71e-041cccbfa57f from the persistent domain config. Libvirt did not report any error but the device is still in the config.
2025-10-14 17:22:20.587 807113 DEBUG nova.virt.libvirt.driver [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] (1/8): Attempting to detach device vdb with device alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 from instance 457ce939-5f92-4f51-b71e-041cccbfa57f from the live domain config. [00;33m{{(pid=807113) _detach_from_live_with_retry /opt/stack/nova/nova/virt/libvirt/driver.py:2674}}[00m
2025-10-14 17:22:20.589 807113 DEBUG nova.virt.libvirt.guest [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] detach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-25868f8c-06ce-4319-9d90-346bddc4bf70"/>
  <source dev="/dev/sdd"/>
  <target dev="vdb" bus="virtio"/>
  <serial>25868f8c-06ce-4319-9d90-346bddc4bf70</serial>
  <shareable/>
  <address type="pci" domain="0x0000" bus="0x00" slot="0x07" function="0x0"/>
</disk>
 [00;33m{{(pid=807113) detach_device /opt/stack/nova/nova/virt/libvirt/guest.py:466}}[00m
2025-10-14 17:22:21.613 807113 DEBUG nova.virt.libvirt.driver [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Start waiting for the detach event from libvirt for device vdb with device alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 for instance 457ce939-5f92-4f51-b71e-041cccbfa57f [00;33m{{(pid=807113) _detach_from_live_and_wait_for_event /opt/stack/nova/nova/virt/libvirt/driver.py:2750}}[00m
2025-10-14 17:22:21.635 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:26.642 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:31.646 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:31.648 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:31.648 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5005 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:22:31.649 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:31.650 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:31.651 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:36.651 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:36.653 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:36.653 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5002 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:22:36.654 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:36.655 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:36.656 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:41.618 807113 WARNING nova.virt.libvirt.driver [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Waiting for libvirt event about the detach of device vdb with device alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 from instance 457ce939-5f92-4f51-b71e-041cccbfa57f is timed out.
2025-10-14 17:22:41.627 807113 INFO nova.virt.libvirt.driver [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully detached device vdb from instance 457ce939-5f92-4f51-b71e-041cccbfa57f from the live domain config.
2025-10-14 17:22:41.657 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:41.660 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:41.660 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:22:41.661 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:41.662 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:41.663 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:42.217 807113 INFO nova.virt.libvirt.driver [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Detected multiple connections on this host for volume: 25868f8c-06ce-4319-9d90-346bddc4bf70, skipping target disconnect.
2025-10-14 17:22:42.869 807113 DEBUG nova.objects.instance [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 457ce939-5f92-4f51-b71e-041cccbfa57f [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:22:43.887 807113 DEBUG oslo_concurrency.lockutils [req-5781f169-fd1c-495a-a998-ec8dfb3c1476 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f" "released" by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" :: held 23.941s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:22:44.291 807113 DEBUG oslo_concurrency.lockutils [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "457ce939-5f92-4f51-b71e-041cccbfa57f" by "nova.compute.manager.ComputeManager.terminate_instance.<locals>.do_terminate_instance" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:22:44.292 807113 DEBUG oslo_concurrency.lockutils [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f" acquired by "nova.compute.manager.ComputeManager.terminate_instance.<locals>.do_terminate_instance" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:22:44.292 807113 DEBUG oslo_concurrency.lockutils [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" by "nova.compute.manager.InstanceEvents.clear_events_for_instance.<locals>._clear_events" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:22:44.293 807113 DEBUG oslo_concurrency.lockutils [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" acquired by "nova.compute.manager.InstanceEvents.clear_events_for_instance.<locals>._clear_events" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:22:44.294 807113 DEBUG oslo_concurrency.lockutils [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" "released" by "nova.compute.manager.InstanceEvents.clear_events_for_instance.<locals>._clear_events" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:22:44.299 807113 INFO nova.compute.manager [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Terminating instance
2025-10-14 17:22:44.808 807113 DEBUG nova.compute.manager [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Start destroying the instance on the hypervisor. [00;33m{{(pid=807113) _shutdown_instance /opt/stack/nova/nova/compute/manager.py:3164}}[00m
2025-10-14 17:22:44.845 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:45.375 807113 INFO nova.virt.libvirt.driver [-] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Instance destroyed successfully.
2025-10-14 17:22:45.376 807113 DEBUG nova.objects.instance [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'resources' on Instance uuid 457ce939-5f92-4f51-b71e-041cccbfa57f [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:22:45.883 807113 DEBUG nova.virt.libvirt.vif [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] vif_type=ovs instance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone='nova',cell_name=None,cleaned=False,compute_id=1,config_drive='',created_at=2025-10-15T00:20:28Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,device_metadata=<?>,disable_terminate=False,display_description=None,display_name='tempest-VolumeMultiattachTests-server-28408194',ec2_ids=<?>,ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,flavor=Flavor(11),hidden=False,host='devstack-u2204-93-55',hostname='tempest-volumemultiattachtests-server-28408194',id=2,image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',info_cache=InstanceInfoCache,instance_type_id=11,kernel_id='',key_data='ecdsa-sha2-nistp384 AAAAE2VjZHNhLXNoYTItbmlzdHAzODQAAAAIbmlzdHAzODQAAABhBA8Aiex4gcSHOLfHUTCeqhj7EyM75uU1yg5RlGdYgLuNs2zNO5yK6ijBQYa275YCZkO6CfvUFVYQ+Ps+520EW9lVVkJ9pJ8Md24/YbKYhDFiKsViWmJOf5Nn7uVTraEcEQ==',key_name='tempest-keypair-1058132398',keypairs=<?>,launch_index=0,launched_at=2025-10-15T00:20:44Z,launched_on='devstack-u2204-93-55',locked=False,locked_by=None,memory_mb=192,metadata={},migration_context=<?>,new_flavor=None,node='devstack-u2204-93-55',numa_topology=None,old_flavor=None,os_type=None,pci_devices=<?>,pci_requests=<?>,power_state=1,progress=0,project_id='1eef17e93cf14f169df902f14b44a4e3',ramdisk_id='',reservation_id='r-vp5b6c6n',resources=None,root_device_name='/dev/vda',root_gb=1,security_groups=SecurityGroupList,services=<?>,shutdown_terminate=False,system_metadata={boot_roles='member,reader',image_base_image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',image_container_format='bare',image_disk_format='raw',image_hw_cdrom_bus='ide',image_hw_disk_bus='virtio',image_hw_input_bus=None,image_hw_machine_type='pc',image_hw_pointer_model=None,image_hw_rng_model='virtio',image_hw_video_model='virtio',image_hw_vif_model='virtio',image_min_disk='1',image_min_ram='0',image_owner_specified.openstack.md5='',image_owner_specified.openstack.object='images/cirros-0.6.1-x86_64-disk',image_owner_specified.openstack.sha256='',owner_project_name='tempest-VolumeMultiattachTests-2017337252',owner_user_name='tempest-VolumeMultiattachTests-2017337252-project-member'},tags=<?>,task_state='deleting',terminated_at=None,trusted_certs=<?>,updated_at=2025-10-15T00:20:44Z,user_data='IyEvYmluL3NoCmVjaG8gIlByaW50aW5nIGNpcnJvcyB1c2VyIGF1dGhvcml6ZWQga2V5cyIKY2F0IH5jaXJyb3MvLnNzaC9hdXRob3JpemVkX2tleXMgfHwgdHJ1ZQo=',user_id='960a08fcc4d0429e9e879816a305186f',uuid=457ce939-5f92-4f51-b71e-041cccbfa57f,vcpu_model=<?>,vcpus=1,vm_mode=None,vm_state='active') vif={"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": [{"address": "172.24.5.125", "type": "floating", "version": 4, "meta": {}}]}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": true, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) unplug /opt/stack/nova/nova/virt/libvirt/vif.py:839}}[00m
2025-10-14 17:22:45.885 807113 DEBUG nova.network.os_vif_util [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converting VIF {"id": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "address": "fa:16:3e:93:af:48", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.4", "type": "fixed", "version": 4, "meta": {}, "floating_ips": [{"address": "172.24.5.125", "type": "floating", "version": 4, "meta": {}}]}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcee44034-db", "ovs_interfaceid": "cee44034-dbe7-4086-a701-cbdee9e5a9ab", "qbh_params": null, "qbg_params": null, "active": true, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:511}}[00m
2025-10-14 17:22:45.888 807113 DEBUG nova.network.os_vif_util [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converted object VIFOpenVSwitch(active=True,address=fa:16:3e:93:af:48,bridge_name='br-int',has_traffic_filtering=True,id=cee44034-dbe7-4086-a701-cbdee9e5a9ab,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcee44034-db') [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:548}}[00m
2025-10-14 17:22:45.889 807113 DEBUG os_vif [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Unplugging vif VIFOpenVSwitch(active=True,address=fa:16:3e:93:af:48,bridge_name='br-int',has_traffic_filtering=True,id=cee44034-dbe7-4086-a701-cbdee9e5a9ab,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcee44034-db') [00;33m{{(pid=807113) unplug /opt/stack/data/venv/lib/python3.10/site-packages/os_vif/__init__.py:109}}[00m
2025-10-14 17:22:45.897 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:45.898 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): DelPortCommand(_result=None, port=tapcee44034-db, bridge=br-int, if_exists=True) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:22:45.902 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:45.910 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:45.912 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:45.913 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): DbDestroyCommand(_result=None, table=QoS, record=8a2c6ba4-61cf-46cd-8378-6e857e6b6d0c) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:22:45.915 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:45.920 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:45.924 807113 INFO os_vif [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully unplugged vif VIFOpenVSwitch(active=True,address=fa:16:3e:93:af:48,bridge_name='br-int',has_traffic_filtering=True,id=cee44034-dbe7-4086-a701-cbdee9e5a9ab,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcee44034-db')
2025-10-14 17:22:45.925 807113 INFO nova.virt.libvirt.driver [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Deleting instance files /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f_del
2025-10-14 17:22:45.927 807113 INFO nova.virt.libvirt.driver [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Deletion of /opt/stack/data/nova/instances/457ce939-5f92-4f51-b71e-041cccbfa57f_del complete
2025-10-14 17:22:46.443 807113 INFO nova.compute.manager [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Took 1.63 seconds to destroy the instance on the hypervisor.
2025-10-14 17:22:46.445 807113 DEBUG oslo.service.backend.eventlet.loopingcall [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Waiting for function nova.compute.manager.ComputeManager._try_deallocate_network.<locals>._deallocate_network_with_retries to return. [00;33m{{(pid=807113) func /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/backend/eventlet/loopingcall.py:436}}[00m
2025-10-14 17:22:46.445 807113 DEBUG nova.compute.manager [-] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Deallocating network for instance [00;33m{{(pid=807113) _deallocate_network /opt/stack/nova/nova/compute/manager.py:2296}}[00m
2025-10-14 17:22:46.446 807113 DEBUG nova.network.neutron [-] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] deallocate_for_instance() [00;33m{{(pid=807113) deallocate_for_instance /opt/stack/nova/nova/network/neutron.py:1863}}[00m
2025-10-14 17:22:47.027 807113 DEBUG nova.compute.manager [req-fe81f64f-ae2d-4b77-912d-5868b3d0199f bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Received event network-vif-unplugged-cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:22:47.028 807113 DEBUG oslo_concurrency.lockutils [req-fe81f64f-ae2d-4b77-912d-5868b3d0199f bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:22:47.029 807113 DEBUG oslo_concurrency.lockutils [req-fe81f64f-ae2d-4b77-912d-5868b3d0199f bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" acquired by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:22:47.030 807113 DEBUG oslo_concurrency.lockutils [req-fe81f64f-ae2d-4b77-912d-5868b3d0199f bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f-events" "released" by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:22:47.030 807113 DEBUG nova.compute.manager [req-fe81f64f-ae2d-4b77-912d-5868b3d0199f bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] No waiting events found dispatching network-vif-unplugged-cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) pop_instance_event /opt/stack/nova/nova/compute/manager.py:322}}[00m
2025-10-14 17:22:47.031 807113 DEBUG nova.compute.manager [req-fe81f64f-ae2d-4b77-912d-5868b3d0199f bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Received event network-vif-unplugged-cee44034-dbe7-4086-a701-cbdee9e5a9ab for instance with task_state deleting. [00;33m{{(pid=807113) _process_instance_event /opt/stack/nova/nova/compute/manager.py:11546}}[00m
2025-10-14 17:22:47.816 807113 DEBUG nova.compute.manager [req-07e65a79-5da7-4bbd-af01-b1f686049506 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Received event network-vif-deleted-cee44034-dbe7-4086-a701-cbdee9e5a9ab [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:22:47.817 807113 INFO nova.compute.manager [req-07e65a79-5da7-4bbd-af01-b1f686049506 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Neutron deleted interface cee44034-dbe7-4086-a701-cbdee9e5a9ab; detaching it from the instance and deleting it from the info cache
2025-10-14 17:22:47.818 807113 DEBUG nova.network.neutron [req-07e65a79-5da7-4bbd-af01-b1f686049506 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Updating instance_info_cache with network_info: [] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:22:48.208 807113 DEBUG nova.network.neutron [-] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Updating instance_info_cache with network_info: [] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:22:48.328 807113 DEBUG nova.compute.manager [req-07e65a79-5da7-4bbd-af01-b1f686049506 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Detach interface failed, port_id=cee44034-dbe7-4086-a701-cbdee9e5a9ab, reason: Instance 457ce939-5f92-4f51-b71e-041cccbfa57f could not be found. [00;33m{{(pid=807113) _process_instance_vif_deleted_event /opt/stack/nova/nova/compute/manager.py:11602}}[00m
2025-10-14 17:22:48.714 807113 INFO nova.compute.manager [-] [instance: 457ce939-5f92-4f51-b71e-041cccbfa57f] Took 2.27 seconds to deallocate network for instance.
2025-10-14 17:22:49.231 807113 DEBUG oslo_concurrency.lockutils [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.update_usage" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:22:49.232 807113 DEBUG oslo_concurrency.lockutils [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.update_usage" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:22:49.358 807113 DEBUG nova.compute.provider_tree [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:22:49.867 807113 DEBUG nova.scheduler.client.report [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:22:50.391 807113 DEBUG oslo_concurrency.lockutils [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.update_usage" :: held 1.159s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:22:50.507 807113 INFO nova.scheduler.client.report [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Deleted allocations for instance 457ce939-5f92-4f51-b71e-041cccbfa57f
2025-10-14 17:22:50.919 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4997-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:50.921 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:50.921 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:22:50.922 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:50.923 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:50.924 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:51.528 807113 DEBUG oslo_concurrency.lockutils [req-a39196e9-5170-4162-b509-8ca4e6bf5063 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "457ce939-5f92-4f51-b71e-041cccbfa57f" "released" by "nova.compute.manager.ComputeManager.terminate_instance.<locals>.do_terminate_instance" :: held 7.237s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:22:52.607 807113 DEBUG oslo_concurrency.lockutils [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:22:52.608 807113 DEBUG oslo_concurrency.lockutils [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:22:53.115 807113 INFO nova.compute.manager [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Detaching volume 25868f8c-06ce-4319-9d90-346bddc4bf70
2025-10-14 17:22:53.203 807113 INFO nova.virt.block_device [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Attempting to driver detach volume 25868f8c-06ce-4319-9d90-346bddc4bf70 from mountpoint /dev/vdd
2025-10-14 17:22:53.217 807113 DEBUG nova.virt.libvirt.driver [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdd by alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:22:53.222 807113 DEBUG nova.virt.libvirt.driver [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdd by alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:22:53.223 807113 DEBUG nova.virt.libvirt.driver [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Attempting to detach device vdd from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the persistent domain config. [00;33m{{(pid=807113) _detach_from_persistent /opt/stack/nova/nova/virt/libvirt/driver.py:2638}}[00m
2025-10-14 17:22:53.224 807113 DEBUG nova.virt.libvirt.guest [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] detach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-25868f8c-06ce-4319-9d90-346bddc4bf70"/>
  <source dev="/dev/sdd"/>
  <target dev="vdd" bus="virtio"/>
  <serial>25868f8c-06ce-4319-9d90-346bddc4bf70</serial>
  <shareable/>
  <address type="pci" domain="0x0000" bus="0x00" slot="0x09" function="0x0"/>
</disk>
 [00;33m{{(pid=807113) detach_device /opt/stack/nova/nova/virt/libvirt/guest.py:466}}[00m
2025-10-14 17:22:53.238 807113 DEBUG nova.virt.libvirt.driver [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdd by alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:22:53.239 807113 WARNING nova.virt.libvirt.driver [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Failed to detach device vdd from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the persistent domain config. Libvirt did not report any error but the device is still in the config.
2025-10-14 17:22:53.240 807113 DEBUG nova.virt.libvirt.driver [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] (1/8): Attempting to detach device vdd with device alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the live domain config. [00;33m{{(pid=807113) _detach_from_live_with_retry /opt/stack/nova/nova/virt/libvirt/driver.py:2674}}[00m
2025-10-14 17:22:53.241 807113 DEBUG nova.virt.libvirt.guest [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] detach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-25868f8c-06ce-4319-9d90-346bddc4bf70"/>
  <source dev="/dev/sdd"/>
  <target dev="vdd" bus="virtio"/>
  <serial>25868f8c-06ce-4319-9d90-346bddc4bf70</serial>
  <shareable/>
  <address type="pci" domain="0x0000" bus="0x00" slot="0x09" function="0x0"/>
</disk>
 [00;33m{{(pid=807113) detach_device /opt/stack/nova/nova/virt/libvirt/guest.py:466}}[00m
2025-10-14 17:22:54.289 807113 DEBUG nova.virt.libvirt.driver [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Start waiting for the detach event from libvirt for device vdd with device alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 for instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) _detach_from_live_and_wait_for_event /opt/stack/nova/nova/virt/libvirt/driver.py:2750}}[00m
2025-10-14 17:22:55.925 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:55.927 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:22:55.927 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:22:55.928 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:55.930 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:22:55.931 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:22:58.295 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:22:58.296 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:22:59.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:22:59.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:22:59.807 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:22:59.808 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:22:59.808 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:22:59.809 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:23:00.863 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:00.932 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:00.936 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:00.937 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5005 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:00.937 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:00.939 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:00.940 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:00.973 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.110s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:00.975 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:01.087 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.112s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:01.090 807113 DEBUG nova.virt.libvirt.driver [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] skipping disk /dev/sdb (vdb) as it is a volume [00;33m{{(pid=807113) _get_instance_disk_info_from_config /opt/stack/nova/nova/virt/libvirt/driver.py:11941}}[00m
2025-10-14 17:23:01.091 807113 DEBUG nova.virt.libvirt.driver [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] skipping disk /dev/sdc (vdc) as it is a volume [00;33m{{(pid=807113) _get_instance_disk_info_from_config /opt/stack/nova/nova/virt/libvirt/driver.py:11941}}[00m
2025-10-14 17:23:01.351 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:01.389 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.038s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:01.392 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=14500MB free_disk=172.31803131103516GB free_vcpus=7 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:23:01.393 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:23:01.395 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:23:02.456 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:23:02.457 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 1 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:23:02.457 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=704MB phys_disk=194GB used_disk=1GB total_vcpus=8 used_vcpus=1 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:23:01 up 1 day,  6:50,  5 users,  load average: 1.59, 2.66, 2.11\n', 'num_instances': '1', 'num_vm_active': '1', 'num_task_None': '1', 'num_os_type_None': '1', 'num_proj_1eef17e93cf14f169df902f14b44a4e3': '1', 'io_workload': '0'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:23:02.534 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:23:03.041 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:23:03.563 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:23:03.564 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.169s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:23:04.564 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:23:04.565 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:23:04.566 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:23:04.567 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:23:04.568 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:23:05.941 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:05.943 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:05.944 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:05.945 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:05.946 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:05.948 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:10.949 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:10.951 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:10.951 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:10.952 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:10.954 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:10.955 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:14.292 807113 WARNING nova.virt.libvirt.driver [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Waiting for libvirt event about the detach of device vdd with device alias ua-25868f8c-06ce-4319-9d90-346bddc4bf70 from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba is timed out.
2025-10-14 17:23:14.302 807113 INFO nova.virt.libvirt.driver [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully detached device vdd from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the live domain config.
2025-10-14 17:23:14.378 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] calling os-brick to detach iSCSI Volume [00;33m{{(pid=807113) disconnect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:73}}[00m
2025-10-14 17:23:14.380 807113 DEBUG os_brick.initiator.connectors.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> disconnect_volume: call "{'args': (<os_brick.initiator.connectors.iscsi.ISCSIConnector object at 0x7a59504d4550>, {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 2, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True, 'device_path': '/dev/sdd'}, None), 'kwargs': {'force': False}}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:23:14.381 807113 DEBUG os_brick.initiator.connectors.base [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_volume" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:23:14.383 807113 DEBUG os_brick.initiator.connectors.base [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:23:14.385 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m discoverydb -o show -P 1 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:14.406 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m discoverydb -o show -P 1" returned: 0 in 0.020s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:14.407 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[bd974bb5-4b20-4bb8-8e69-d3a9366eb6d9]: (4, ('SENDTARGETS:\nNo targets found.\niSNS:\nNo targets found.\nSTATIC:\nTarget: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\n\tPortal: 172.25.59.221:3260,-1\n\t\tIface Name: default\nFIRMWARE:\nNo targets found.\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:14.409 807113 DEBUG os_brick.initiator.connectors.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ['-m', 'discoverydb', '-o', 'show', '-P', 1]: stdout=SENDTARGETS:
No targets found.
iSNS:
No targets found.
STATIC:
Target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target
	Portal: 172.25.59.221:3260,-1
		Iface Name: default
FIRMWARE:
No targets found.
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:23:14.410 807113 DEBUG os_brick.initiator.connectors.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Regex to get portals from discoverydb: ^SENDTARGETS:
.*?^DiscoveryAddress: 172.25.59.221,3260.*?
(.*?)^(?:DiscoveryAddress|iSNS):.* [00;33m{{(pid=807113) _get_discoverydb_portals /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:392}}[00m
2025-10-14 17:23:14.412 807113 DEBUG os_brick.initiator.connectors.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Getting connected devices for (ips,iqns,luns)=[('172.25.59.221:3260', 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 2)] [00;33m{{(pid=807113) _get_connection_devices /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:853}}[00m
2025-10-14 17:23:14.414 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:14.435 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:14.436 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[daf769f0-29b8-4061-aa90-5b8075bdce1a]: (4, ('172.25.59.221:3260,4294967295 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:14.439 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:14.460 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:14.461 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[e14b20b6-855a-429a-90df-63397767a75a]: (4, ('tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:14.463 807113 DEBUG os_brick.initiator.connectors.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:23:14.464 807113 DEBUG os_brick.initiator.connectors.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:23:14.471 807113 DEBUG os_brick.initiator.connectors.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Resulting device map defaultdict(<function ISCSIConnector._get_connection_devices.<locals>.<lambda> at 0x7a5950344ca0>, {('172.25.59.221:3260', 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target'): ({'sdd'}, {'sdb', 'sdc'})}) [00;33m{{(pid=807113) _get_connection_devices /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:886}}[00m
2025-10-14 17:23:14.473 807113 DEBUG os_brick.initiator.linuxscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Removing single pathed devices sdd [00;33m{{(pid=807113) remove_connection /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:381}}[00m
2025-10-14 17:23:14.474 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): multipathd show status [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:14.488 826121 DEBUG oslo_concurrency.processutils [-] 'multipathd show status' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:23:14.489 826121 DEBUG oslo.privsep.daemon [-] privsep: Exception during request[9c46491b-b6e5-481f-96f5-188224484b9b]: [Errno 2] No such file or directory: 'multipathd' [00;33m{{(pid=826121) _process_cmd /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:481}}[00m
Traceback (most recent call last):
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py", line 478, in _process_cmd
    ret = func(*f_args, **f_kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/priv_context.py", line 266, in _wrap
    return func(*args, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 198, in execute_root
    return custom_execute(*cmd, shell=False, run_as_root=False, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 146, in custom_execute
    return putils.execute(on_execute=on_execute,
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py", line 354, in execute
    obj = subprocess.Popen(cmd,
  File "/usr/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'multipathd'
2025-10-14 17:23:14.490 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[9c46491b-b6e5-481f-96f5-188224484b9b]: (5, 'builtins.FileNotFoundError', (2, 'No such file or directory')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:14.492 807113 DEBUG os_brick.initiator.linuxscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Flushing IO for device /dev/sdd [00;33m{{(pid=807113) flush_device_io /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:441}}[00m
2025-10-14 17:23:14.494 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): blockdev --flushbufs /dev/sdd [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:14.510 826121 DEBUG oslo_concurrency.processutils [-] CMD "blockdev --flushbufs /dev/sdd" returned: 0 in 0.016s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:14.511 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[45c71237-3b8c-4ce5-976e-f4b454f2dd80]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:14.513 807113 DEBUG os_brick.initiator.linuxscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Remove SCSI device /dev/sdd with /sys/block/sdd/device/delete [00;33m{{(pid=807113) remove_scsi_device /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:151}}[00m
2025-10-14 17:23:14.515 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): tee -a /sys/block/sdd/device/delete [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:14.552 826121 DEBUG oslo_concurrency.processutils [-] CMD "tee -a /sys/block/sdd/device/delete" returned: 0 in 0.037s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:14.553 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[28175802-b01f-4431-9073-53270c9ffbc9]: (4, ('1', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:14.555 807113 DEBUG os_brick.initiator.linuxscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Checking to see if SCSI volumes sdd have been removed. [00;33m{{(pid=807113) wait_for_volumes_removal /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:159}}[00m
2025-10-14 17:23:14.556 807113 DEBUG os_brick.initiator.linuxscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] SCSI volumes sdd have been removed. [00;33m{{(pid=807113) wait_for_volumes_removal /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:169}}[00m
2025-10-14 17:23:14.557 807113 DEBUG os_brick.initiator.connectors.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Disconnecting from: [] [00;33m{{(pid=807113) _disconnect_connection /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1199}}[00m
2025-10-14 17:23:14.558 807113 DEBUG os_brick.initiator.connectors.base [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" :: held 0.175s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:23:14.559 807113 DEBUG os_brick.initiator.connectors.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== disconnect_volume: return (177ms) None [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:23:14.560 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Disconnected iSCSI Volume [00;33m{{(pid=807113) disconnect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:80}}[00m
2025-10-14 17:23:15.956 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:15.957 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:15.958 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5002 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:15.958 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:15.960 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:15.961 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:16.669 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:21.676 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4998-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:21.678 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:21.678 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:21.679 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:21.680 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:21.680 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:23.221 807113 DEBUG nova.objects.instance [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:23:24.240 807113 DEBUG oslo_concurrency.lockutils [req-84b11422-a0f9-4381-b1b2-dd10fa8c4c25 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" :: held 31.632s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:23:24.645 807113 DEBUG oslo_concurrency.lockutils [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:23:24.647 807113 DEBUG oslo_concurrency.lockutils [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:23:25.154 807113 INFO nova.compute.manager [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Detaching volume 73706d59-5ba8-4c8e-8953-1fad2944615a
2025-10-14 17:23:25.240 807113 INFO nova.virt.block_device [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Attempting to driver detach volume 73706d59-5ba8-4c8e-8953-1fad2944615a from mountpoint /dev/vdc
2025-10-14 17:23:25.254 807113 DEBUG nova.virt.libvirt.driver [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdc by alias ua-73706d59-5ba8-4c8e-8953-1fad2944615a [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:23:25.258 807113 DEBUG nova.virt.libvirt.driver [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdc by alias ua-73706d59-5ba8-4c8e-8953-1fad2944615a [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:23:25.259 807113 DEBUG nova.virt.libvirt.driver [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Attempting to detach device vdc from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the persistent domain config. [00;33m{{(pid=807113) _detach_from_persistent /opt/stack/nova/nova/virt/libvirt/driver.py:2638}}[00m
2025-10-14 17:23:25.260 807113 DEBUG nova.virt.libvirt.guest [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] detach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-73706d59-5ba8-4c8e-8953-1fad2944615a"/>
  <source dev="/dev/sdc"/>
  <target dev="vdc" bus="virtio"/>
  <serial>73706d59-5ba8-4c8e-8953-1fad2944615a</serial>
  <address type="pci" domain="0x0000" bus="0x00" slot="0x08" function="0x0"/>
</disk>
 [00;33m{{(pid=807113) detach_device /opt/stack/nova/nova/virt/libvirt/guest.py:466}}[00m
2025-10-14 17:23:25.274 807113 DEBUG nova.virt.libvirt.driver [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdc by alias ua-73706d59-5ba8-4c8e-8953-1fad2944615a [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:23:25.275 807113 WARNING nova.virt.libvirt.driver [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Failed to detach device vdc from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the persistent domain config. Libvirt did not report any error but the device is still in the config.
2025-10-14 17:23:25.276 807113 DEBUG nova.virt.libvirt.driver [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] (1/8): Attempting to detach device vdc with device alias ua-73706d59-5ba8-4c8e-8953-1fad2944615a from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the live domain config. [00;33m{{(pid=807113) _detach_from_live_with_retry /opt/stack/nova/nova/virt/libvirt/driver.py:2674}}[00m
2025-10-14 17:23:25.277 807113 DEBUG nova.virt.libvirt.guest [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] detach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-73706d59-5ba8-4c8e-8953-1fad2944615a"/>
  <source dev="/dev/sdc"/>
  <target dev="vdc" bus="virtio"/>
  <serial>73706d59-5ba8-4c8e-8953-1fad2944615a</serial>
  <address type="pci" domain="0x0000" bus="0x00" slot="0x08" function="0x0"/>
</disk>
 [00;33m{{(pid=807113) detach_device /opt/stack/nova/nova/virt/libvirt/guest.py:466}}[00m
2025-10-14 17:23:26.313 807113 DEBUG nova.virt.libvirt.driver [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Start waiting for the detach event from libvirt for device vdc with device alias ua-73706d59-5ba8-4c8e-8953-1fad2944615a for instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) _detach_from_live_and_wait_for_event /opt/stack/nova/nova/virt/libvirt/driver.py:2750}}[00m
2025-10-14 17:23:26.682 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:26.683 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:26.684 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:26.684 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:26.686 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:26.687 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:31.687 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:31.689 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:31.689 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5002 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:31.690 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:31.691 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:31.692 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:36.694 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:36.696 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:36.696 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:36.697 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:36.699 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:36.700 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:41.701 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:41.703 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:41.704 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:41.704 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:41.705 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:41.706 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:46.316 807113 WARNING nova.virt.libvirt.driver [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Waiting for libvirt event about the detach of device vdc with device alias ua-73706d59-5ba8-4c8e-8953-1fad2944615a from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba is timed out.
2025-10-14 17:23:46.325 807113 INFO nova.virt.libvirt.driver [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully detached device vdc from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the live domain config.
2025-10-14 17:23:46.331 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] calling os-brick to detach iSCSI Volume [00;33m{{(pid=807113) disconnect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:73}}[00m
2025-10-14 17:23:46.332 807113 DEBUG os_brick.initiator.connectors.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> disconnect_volume: call "{'args': (<os_brick.initiator.connectors.iscsi.ISCSIConnector object at 0x7a59504d4550>, {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 0, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True, 'device_path': '/dev/sdc'}, None), 'kwargs': {'force': False}}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:23:46.333 807113 DEBUG os_brick.initiator.connectors.base [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_volume" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:23:46.334 807113 DEBUG os_brick.initiator.connectors.base [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:23:46.336 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m discoverydb -o show -P 1 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:46.358 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m discoverydb -o show -P 1" returned: 0 in 0.022s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:46.359 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[d3add99c-5296-4d59-9018-ce94e3a3c897]: (4, ('SENDTARGETS:\nNo targets found.\niSNS:\nNo targets found.\nSTATIC:\nTarget: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\n\tPortal: 172.25.59.221:3260,-1\n\t\tIface Name: default\nFIRMWARE:\nNo targets found.\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:46.361 807113 DEBUG os_brick.initiator.connectors.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ['-m', 'discoverydb', '-o', 'show', '-P', 1]: stdout=SENDTARGETS:
No targets found.
iSNS:
No targets found.
STATIC:
Target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target
	Portal: 172.25.59.221:3260,-1
		Iface Name: default
FIRMWARE:
No targets found.
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:23:46.362 807113 DEBUG os_brick.initiator.connectors.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Regex to get portals from discoverydb: ^SENDTARGETS:
.*?^DiscoveryAddress: 172.25.59.221,3260.*?
(.*?)^(?:DiscoveryAddress|iSNS):.* [00;33m{{(pid=807113) _get_discoverydb_portals /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:392}}[00m
2025-10-14 17:23:46.363 807113 DEBUG os_brick.initiator.connectors.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Getting connected devices for (ips,iqns,luns)=[('172.25.59.221:3260', 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 0)] [00;33m{{(pid=807113) _get_connection_devices /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:853}}[00m
2025-10-14 17:23:46.365 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:46.390 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node" returned: 0 in 0.025s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:46.391 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[d53a52b5-2799-4d37-bd79-1dc186ed04f5]: (4, ('172.25.59.221:3260,4294967295 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:46.394 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:46.415 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:46.417 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[0f6bc26a-1b5b-42a6-8537-1f5e63add67c]: (4, ('tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:46.418 807113 DEBUG os_brick.initiator.connectors.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:23:46.419 807113 DEBUG os_brick.initiator.connectors.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:23:46.424 807113 DEBUG os_brick.initiator.connectors.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Resulting device map defaultdict(<function ISCSIConnector._get_connection_devices.<locals>.<lambda> at 0x7a59503e7370>, {('172.25.59.221:3260', 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target'): ({'sdc'}, {'sdb'})}) [00;33m{{(pid=807113) _get_connection_devices /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:886}}[00m
2025-10-14 17:23:46.425 807113 DEBUG os_brick.initiator.linuxscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Removing single pathed devices sdc [00;33m{{(pid=807113) remove_connection /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:381}}[00m
2025-10-14 17:23:46.427 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): multipathd show status [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:46.441 826121 DEBUG oslo_concurrency.processutils [-] 'multipathd show status' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:23:46.442 826121 DEBUG oslo.privsep.daemon [-] privsep: Exception during request[e4c2afc8-6b65-4944-a22d-97aaa74bfac8]: [Errno 2] No such file or directory: 'multipathd' [00;33m{{(pid=826121) _process_cmd /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:481}}[00m
Traceback (most recent call last):
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py", line 478, in _process_cmd
    ret = func(*f_args, **f_kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/priv_context.py", line 266, in _wrap
    return func(*args, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 198, in execute_root
    return custom_execute(*cmd, shell=False, run_as_root=False, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 146, in custom_execute
    return putils.execute(on_execute=on_execute,
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py", line 354, in execute
    obj = subprocess.Popen(cmd,
  File "/usr/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'multipathd'
2025-10-14 17:23:46.444 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[e4c2afc8-6b65-4944-a22d-97aaa74bfac8]: (5, 'builtins.FileNotFoundError', (2, 'No such file or directory')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:46.446 807113 DEBUG os_brick.initiator.linuxscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Flushing IO for device /dev/sdc [00;33m{{(pid=807113) flush_device_io /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:441}}[00m
2025-10-14 17:23:46.448 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): blockdev --flushbufs /dev/sdc [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:46.463 826121 DEBUG oslo_concurrency.processutils [-] CMD "blockdev --flushbufs /dev/sdc" returned: 0 in 0.015s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:46.464 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[8f68bd82-d3ec-4d3d-976d-5bd028ebd478]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:46.466 807113 DEBUG os_brick.initiator.linuxscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Remove SCSI device /dev/sdc with /sys/block/sdc/device/delete [00;33m{{(pid=807113) remove_scsi_device /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:151}}[00m
2025-10-14 17:23:46.468 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): tee -a /sys/block/sdc/device/delete [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:23:46.512 826121 DEBUG oslo_concurrency.processutils [-] CMD "tee -a /sys/block/sdc/device/delete" returned: 0 in 0.044s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:23:46.514 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[fdcfef73-8940-4b6a-b00a-6a570a6601d3]: (4, ('1', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:23:46.516 807113 DEBUG os_brick.initiator.linuxscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Checking to see if SCSI volumes sdc have been removed. [00;33m{{(pid=807113) wait_for_volumes_removal /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:159}}[00m
2025-10-14 17:23:46.517 807113 DEBUG os_brick.initiator.linuxscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] SCSI volumes sdc have been removed. [00;33m{{(pid=807113) wait_for_volumes_removal /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:169}}[00m
2025-10-14 17:23:46.519 807113 DEBUG os_brick.initiator.connectors.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Disconnecting from: [] [00;33m{{(pid=807113) _disconnect_connection /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1199}}[00m
2025-10-14 17:23:46.520 807113 DEBUG os_brick.initiator.connectors.base [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" :: held 0.185s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:23:46.520 807113 DEBUG os_brick.initiator.connectors.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== disconnect_volume: return (187ms) None [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:23:46.521 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Disconnected iSCSI Volume [00;33m{{(pid=807113) disconnect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:80}}[00m
2025-10-14 17:23:46.707 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:46.709 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:46.710 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:46.710 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:46.711 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:46.712 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:51.691 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:54.651 807113 DEBUG nova.objects.instance [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:23:55.669 807113 DEBUG oslo_concurrency.lockutils [req-3eeb2f28-d421-4ae8-8510-f1fb24f6b40c 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" :: held 31.023s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:23:56.603 807113 DEBUG oslo_concurrency.lockutils [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:23:56.605 807113 DEBUG oslo_concurrency.lockutils [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:23:56.700 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4998-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:56.702 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:23:56.703 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5005 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:23:56.704 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:56.705 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:23:56.707 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:23:57.114 807113 INFO nova.compute.manager [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Detaching volume 6143228d-e127-4fba-8b40-e8d79c7b0c72
2025-10-14 17:23:57.226 807113 INFO nova.virt.block_device [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Attempting to driver detach volume 6143228d-e127-4fba-8b40-e8d79c7b0c72 from mountpoint /dev/vdb
2025-10-14 17:23:57.242 807113 DEBUG nova.virt.libvirt.driver [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdb by alias ua-6143228d-e127-4fba-8b40-e8d79c7b0c72 [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:23:57.247 807113 DEBUG nova.virt.libvirt.driver [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdb by alias ua-6143228d-e127-4fba-8b40-e8d79c7b0c72 [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:23:57.249 807113 DEBUG nova.virt.libvirt.driver [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Attempting to detach device vdb from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the persistent domain config. [00;33m{{(pid=807113) _detach_from_persistent /opt/stack/nova/nova/virt/libvirt/driver.py:2638}}[00m
2025-10-14 17:23:57.250 807113 DEBUG nova.virt.libvirt.guest [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] detach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-6143228d-e127-4fba-8b40-e8d79c7b0c72"/>
  <source dev="/dev/sdb"/>
  <target dev="vdb" bus="virtio"/>
  <serial>6143228d-e127-4fba-8b40-e8d79c7b0c72</serial>
  <address type="pci" domain="0x0000" bus="0x00" slot="0x07" function="0x0"/>
</disk>
 [00;33m{{(pid=807113) detach_device /opt/stack/nova/nova/virt/libvirt/guest.py:466}}[00m
2025-10-14 17:23:57.264 807113 DEBUG nova.virt.libvirt.driver [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdb by alias ua-6143228d-e127-4fba-8b40-e8d79c7b0c72 [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:23:57.265 807113 WARNING nova.virt.libvirt.driver [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Failed to detach device vdb from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the persistent domain config. Libvirt did not report any error but the device is still in the config.
2025-10-14 17:23:57.266 807113 DEBUG nova.virt.libvirt.driver [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] (1/8): Attempting to detach device vdb with device alias ua-6143228d-e127-4fba-8b40-e8d79c7b0c72 from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the live domain config. [00;33m{{(pid=807113) _detach_from_live_with_retry /opt/stack/nova/nova/virt/libvirt/driver.py:2674}}[00m
2025-10-14 17:23:57.267 807113 DEBUG nova.virt.libvirt.guest [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] detach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-6143228d-e127-4fba-8b40-e8d79c7b0c72"/>
  <source dev="/dev/sdb"/>
  <target dev="vdb" bus="virtio"/>
  <serial>6143228d-e127-4fba-8b40-e8d79c7b0c72</serial>
  <address type="pci" domain="0x0000" bus="0x00" slot="0x07" function="0x0"/>
</disk>
 [00;33m{{(pid=807113) detach_device /opt/stack/nova/nova/virt/libvirt/guest.py:466}}[00m
2025-10-14 17:23:58.428 807113 DEBUG nova.virt.libvirt.driver [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Start waiting for the detach event from libvirt for device vdb with device alias ua-6143228d-e127-4fba-8b40-e8d79c7b0c72 for instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) _detach_from_live_and_wait_for_event /opt/stack/nova/nova/virt/libvirt/driver.py:2750}}[00m
2025-10-14 17:23:59.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:23:59.807 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:23:59.808 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:23:59.809 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:23:59.809 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:24:00.875 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:00.989 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.114s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:01.038 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:01.150 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba/disk --force-share --output=json" returned: 0 in 0.112s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:01.422 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:01.472 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.050s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:01.476 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=14498MB free_disk=172.31719970703125GB free_vcpus=7 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:24:01.478 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:24:01.480 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:24:01.709 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:01.712 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:01.712 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5005 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:01.713 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:01.714 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:01.716 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:02.602 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:24:02.604 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 1 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:24:02.605 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=704MB phys_disk=194GB used_disk=1GB total_vcpus=8 used_vcpus=1 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:24:01 up 1 day,  6:51,  5 users,  load average: 0.90, 2.26, 2.01\n', 'num_instances': '1', 'num_vm_active': '1', 'num_task_None': '1', 'num_os_type_None': '1', 'num_proj_1eef17e93cf14f169df902f14b44a4e3': '1', 'io_workload': '0'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:24:02.697 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:24:03.207 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:24:03.735 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:24:03.737 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.257s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:24:04.738 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:04.739 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_scheduler_instance_info [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:04.740 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:04.741 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:04.741 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:04.742 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:04.743 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:04.744 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:24:05.293 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:06.717 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:06.719 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:06.720 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:06.720 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:06.721 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:06.722 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:07.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._run_pending_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:07.293 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Cleaning up deleted instances [00;33m{{(pid=807113) _run_pending_deletes /opt/stack/nova/nova/compute/manager.py:11865}}[00m
2025-10-14 17:24:07.801 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] There are 0 instances to clean [00;33m{{(pid=807113) _run_pending_deletes /opt/stack/nova/nova/compute/manager.py:11874}}[00m
2025-10-14 17:24:10.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._cleanup_expired_console_auth_tokens [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:11.723 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:11.725 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:11.725 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:11.726 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:11.727 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:11.728 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:16.729 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:16.732 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:16.733 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5004 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:16.733 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:16.734 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:16.735 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:18.432 807113 WARNING nova.virt.libvirt.driver [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Waiting for libvirt event about the detach of device vdb with device alias ua-6143228d-e127-4fba-8b40-e8d79c7b0c72 from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba is timed out.
2025-10-14 17:24:18.442 807113 INFO nova.virt.libvirt.driver [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully detached device vdb from instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba from the live domain config.
2025-10-14 17:24:18.447 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] calling os-brick to detach iSCSI Volume [00;33m{{(pid=807113) disconnect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:73}}[00m
2025-10-14 17:24:18.450 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> disconnect_volume: call "{'args': (<os_brick.initiator.connectors.iscsi.ISCSIConnector object at 0x7a59504d4550>, {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 1, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True, 'device_path': '/dev/sdb'}, None), 'kwargs': {'force': False}}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:24:18.451 807113 DEBUG os_brick.initiator.connectors.base [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_volume" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:24:18.453 807113 DEBUG os_brick.initiator.connectors.base [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" :: waited 0.003s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:24:18.457 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m discoverydb -o show -P 1 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:18.482 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m discoverydb -o show -P 1" returned: 0 in 0.025s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:18.484 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[dd0dcd03-2d8e-4a31-aac0-f1af7758d9e9]: (4, ('SENDTARGETS:\nNo targets found.\niSNS:\nNo targets found.\nSTATIC:\nTarget: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\n\tPortal: 172.25.59.221:3260,-1\n\t\tIface Name: default\nFIRMWARE:\nNo targets found.\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:24:18.485 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ['-m', 'discoverydb', '-o', 'show', '-P', 1]: stdout=SENDTARGETS:
No targets found.
iSNS:
No targets found.
STATIC:
Target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target
	Portal: 172.25.59.221:3260,-1
		Iface Name: default
FIRMWARE:
No targets found.
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:24:18.486 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Regex to get portals from discoverydb: ^SENDTARGETS:
.*?^DiscoveryAddress: 172.25.59.221,3260.*?
(.*?)^(?:DiscoveryAddress|iSNS):.* [00;33m{{(pid=807113) _get_discoverydb_portals /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:392}}[00m
2025-10-14 17:24:18.487 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Getting connected devices for (ips,iqns,luns)=[('172.25.59.221:3260', 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 1)] [00;33m{{(pid=807113) _get_connection_devices /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:853}}[00m
2025-10-14 17:24:18.490 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:18.512 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node" returned: 0 in 0.022s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:18.513 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[148e8165-d1a7-4b45-aa73-b56663706204]: (4, ('172.25.59.221:3260,4294967295 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:24:18.516 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:18.540 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 0 in 0.024s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:18.541 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[fd537d59-6382-491b-a363-526577aa0a6e]: (4, ('tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:24:18.543 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:24:18.545 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout=tcp: [17] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:24:18.551 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Resulting device map defaultdict(<function ISCSIConnector._get_connection_devices.<locals>.<lambda> at 0x7a59503895a0>, {('172.25.59.221:3260', 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target'): ({'sdb'}, set())}) [00;33m{{(pid=807113) _get_connection_devices /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:886}}[00m
2025-10-14 17:24:18.552 807113 DEBUG os_brick.initiator.linuxscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Removing single pathed devices sdb [00;33m{{(pid=807113) remove_connection /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:381}}[00m
2025-10-14 17:24:18.554 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): multipathd show status [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:18.568 826121 DEBUG oslo_concurrency.processutils [-] 'multipathd show status' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:24:18.569 826121 DEBUG oslo.privsep.daemon [-] privsep: Exception during request[e368d8da-efe0-458b-9356-01bcf98e7ca6]: [Errno 2] No such file or directory: 'multipathd' [00;33m{{(pid=826121) _process_cmd /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:481}}[00m
Traceback (most recent call last):
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py", line 478, in _process_cmd
    ret = func(*f_args, **f_kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/priv_context.py", line 266, in _wrap
    return func(*args, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 198, in execute_root
    return custom_execute(*cmd, shell=False, run_as_root=False, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 146, in custom_execute
    return putils.execute(on_execute=on_execute,
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py", line 354, in execute
    obj = subprocess.Popen(cmd,
  File "/usr/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'multipathd'
2025-10-14 17:24:18.571 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[e368d8da-efe0-458b-9356-01bcf98e7ca6]: (5, 'builtins.FileNotFoundError', (2, 'No such file or directory')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:24:18.573 807113 DEBUG os_brick.initiator.linuxscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Flushing IO for device /dev/sdb [00;33m{{(pid=807113) flush_device_io /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:441}}[00m
2025-10-14 17:24:18.575 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): blockdev --flushbufs /dev/sdb [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:18.590 826121 DEBUG oslo_concurrency.processutils [-] CMD "blockdev --flushbufs /dev/sdb" returned: 0 in 0.015s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:18.592 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[a6017692-4801-4fec-814b-1f8d58eee24d]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:24:18.594 807113 DEBUG os_brick.initiator.linuxscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Remove SCSI device /dev/sdb with /sys/block/sdb/device/delete [00;33m{{(pid=807113) remove_scsi_device /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:151}}[00m
2025-10-14 17:24:18.596 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): tee -a /sys/block/sdb/device/delete [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:18.635 826121 DEBUG oslo_concurrency.processutils [-] CMD "tee -a /sys/block/sdb/device/delete" returned: 0 in 0.038s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:18.636 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[5cc48a89-ab89-4817-a4a9-73b356ac5c4a]: (4, ('1', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:24:18.639 807113 DEBUG os_brick.initiator.linuxscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Checking to see if SCSI volumes sdb have been removed. [00;33m{{(pid=807113) wait_for_volumes_removal /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:159}}[00m
2025-10-14 17:24:18.640 807113 DEBUG os_brick.initiator.linuxscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] SCSI volumes sdb have been removed. [00;33m{{(pid=807113) wait_for_volumes_removal /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:169}}[00m
2025-10-14 17:24:18.641 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Disconnecting from: [('172.25.59.221:3260', 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target')] [00;33m{{(pid=807113) _disconnect_connection /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1199}}[00m
2025-10-14 17:24:18.643 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.startup -v manual [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:18.662 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.startup -v manual" returned: 0 in 0.019s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:18.664 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[1fd0b4f8-8695-4039-bdd8-b42d10a9a11a]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:24:18.666 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'update', '-n', 'node.startup', '-v', 'manual'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:24:18.669 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --logout [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:18.721 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --logout" returned: 0 in 0.052s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:18.722 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[ed6cfcd5-c9f7-4ab1-a06a-18b9d143f724]: (4, ('Logging out of session [sid: 17, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260]\nLogout of [sid: 17, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260] successful.\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:24:18.724 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--logout',): stdout=Logging out of session [sid: 17, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260]
Logout of [sid: 17, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260] successful.
 stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:24:18.725 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op delete [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:24:18.744 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op delete" returned: 0 in 0.019s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:24:18.746 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[d575f59c-467b-47e8-8c92-f3ee4258e2a9]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:24:18.748 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'delete'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:24:18.749 807113 DEBUG os_brick.initiator.connectors.base [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" :: held 0.296s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:24:18.750 807113 DEBUG os_brick.initiator.connectors.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== disconnect_volume: return (299ms) None [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:24:18.751 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Disconnected iSCSI Volume [00;33m{{(pid=807113) disconnect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:80}}[00m
2025-10-14 17:24:21.709 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:21.799 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._cleanup_incomplete_migrations [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:21.800 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Cleaning up deleted instances with incomplete migration  [00;33m{{(pid=807113) _cleanup_incomplete_migrations /opt/stack/nova/nova/compute/manager.py:11903}}[00m
2025-10-14 17:24:26.461 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_power_states [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:26.715 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4998-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:26.717 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:26.718 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:26.718 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:26.720 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:26.721 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:26.912 807113 DEBUG nova.objects.instance [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:24:26.975 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Triggering sync for uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) _sync_power_states /opt/stack/nova/nova/compute/manager.py:10975}}[00m
2025-10-14 17:24:26.976 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager._sync_power_states.<locals>._sync.<locals>.query_driver_power_state_and_sync" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:24:27.931 807113 DEBUG oslo_concurrency.lockutils [req-d48ec197-998c-4eca-90cb-74402d41b94f 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" :: held 31.326s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:24:27.933 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager._sync_power_states.<locals>._sync.<locals>.query_driver_power_state_and_sync" :: waited 0.958s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:24:28.446 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager._sync_power_states.<locals>._sync.<locals>.query_driver_power_state_and_sync" :: held 0.512s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:24:31.722 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:31.723 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:31.724 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5002 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:31.724 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:31.725 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:31.727 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:36.728 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:36.729 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:36.730 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:36.730 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:36.732 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:36.732 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:41.667 807113 DEBUG oslo_concurrency.lockutils [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" by "nova.compute.manager.ComputeManager.terminate_instance.<locals>.do_terminate_instance" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:24:41.668 807113 DEBUG oslo_concurrency.lockutils [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" acquired by "nova.compute.manager.ComputeManager.terminate_instance.<locals>.do_terminate_instance" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:24:41.669 807113 DEBUG oslo_concurrency.lockutils [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba-events" by "nova.compute.manager.InstanceEvents.clear_events_for_instance.<locals>._clear_events" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:24:41.670 807113 DEBUG oslo_concurrency.lockutils [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba-events" acquired by "nova.compute.manager.InstanceEvents.clear_events_for_instance.<locals>._clear_events" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:24:41.671 807113 DEBUG oslo_concurrency.lockutils [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba-events" "released" by "nova.compute.manager.InstanceEvents.clear_events_for_instance.<locals>._clear_events" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:24:41.677 807113 INFO nova.compute.manager [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Terminating instance
2025-10-14 17:24:41.734 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:41.737 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:41.737 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5004 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:41.738 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:41.739 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:41.740 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:42.189 807113 DEBUG nova.compute.manager [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Start destroying the instance on the hypervisor. [00;33m{{(pid=807113) _shutdown_instance /opt/stack/nova/nova/compute/manager.py:3164}}[00m
2025-10-14 17:24:42.228 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:42.717 807113 INFO nova.virt.libvirt.driver [-] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Instance destroyed successfully.
2025-10-14 17:24:42.718 807113 DEBUG nova.objects.instance [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'resources' on Instance uuid 1c5196e6-48bf-42c2-95c5-4db2adce84ba [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:24:43.227 807113 DEBUG nova.virt.libvirt.vif [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] vif_type=ovs instance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone='nova',cell_name=None,cleaned=False,compute_id=1,config_drive='',created_at=2025-10-15T00:17:11Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,device_metadata=<?>,disable_terminate=False,display_description=None,display_name='tempest-VolumeMultiattachTests-server-17603601',ec2_ids=<?>,ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,flavor=Flavor(11),hidden=False,host='devstack-u2204-93-55',hostname='tempest-volumemultiattachtests-server-17603601',id=1,image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',info_cache=InstanceInfoCache,instance_type_id=11,kernel_id='',key_data='ecdsa-sha2-nistp384 AAAAE2VjZHNhLXNoYTItbmlzdHAzODQAAAAIbmlzdHAzODQAAABhBA8Aiex4gcSHOLfHUTCeqhj7EyM75uU1yg5RlGdYgLuNs2zNO5yK6ijBQYa275YCZkO6CfvUFVYQ+Ps+520EW9lVVkJ9pJ8Md24/YbKYhDFiKsViWmJOf5Nn7uVTraEcEQ==',key_name='tempest-keypair-1058132398',keypairs=<?>,launch_index=0,launched_at=2025-10-15T00:17:31Z,launched_on='devstack-u2204-93-55',locked=False,locked_by=None,memory_mb=192,metadata={},migration_context=<?>,new_flavor=None,node='devstack-u2204-93-55',numa_topology=None,old_flavor=None,os_type=None,pci_devices=<?>,pci_requests=<?>,power_state=1,progress=0,project_id='1eef17e93cf14f169df902f14b44a4e3',ramdisk_id='',reservation_id='r-wrv46qma',resources=None,root_device_name='/dev/vda',root_gb=1,security_groups=SecurityGroupList,services=<?>,shutdown_terminate=False,system_metadata={boot_roles='member,reader',image_base_image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',image_container_format='bare',image_disk_format='raw',image_hw_cdrom_bus='ide',image_hw_disk_bus='virtio',image_hw_input_bus=None,image_hw_machine_type='pc',image_hw_pointer_model=None,image_hw_rng_model='virtio',image_hw_video_model='virtio',image_hw_vif_model='virtio',image_min_disk='1',image_min_ram='0',image_owner_specified.openstack.md5='',image_owner_specified.openstack.object='images/cirros-0.6.1-x86_64-disk',image_owner_specified.openstack.sha256='',owner_project_name='tempest-VolumeMultiattachTests-2017337252',owner_user_name='tempest-VolumeMultiattachTests-2017337252-project-member'},tags=<?>,task_state='deleting',terminated_at=None,trusted_certs=<?>,updated_at=2025-10-15T00:17:32Z,user_data='IyEvYmluL3NoCmVjaG8gIlByaW50aW5nIGNpcnJvcyB1c2VyIGF1dGhvcml6ZWQga2V5cyIKY2F0IH5jaXJyb3MvLnNzaC9hdXRob3JpemVkX2tleXMgfHwgdHJ1ZQo=',user_id='960a08fcc4d0429e9e879816a305186f',uuid=1c5196e6-48bf-42c2-95c5-4db2adce84ba,vcpu_model=<?>,vcpus=1,vm_mode=None,vm_state='active') vif={"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": true, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) unplug /opt/stack/nova/nova/virt/libvirt/vif.py:839}}[00m
2025-10-14 17:24:43.229 807113 DEBUG nova.network.os_vif_util [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converting VIF {"id": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "address": "fa:16:3e:55:eb:ee", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.9", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapcb17c207-b6", "ovs_interfaceid": "cb17c207-b6b1-4528-8c86-6ec60ca00990", "qbh_params": null, "qbg_params": null, "active": true, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:511}}[00m
2025-10-14 17:24:43.231 807113 DEBUG nova.network.os_vif_util [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converted object VIFOpenVSwitch(active=True,address=fa:16:3e:55:eb:ee,bridge_name='br-int',has_traffic_filtering=True,id=cb17c207-b6b1-4528-8c86-6ec60ca00990,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcb17c207-b6') [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:548}}[00m
2025-10-14 17:24:43.233 807113 DEBUG os_vif [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Unplugging vif VIFOpenVSwitch(active=True,address=fa:16:3e:55:eb:ee,bridge_name='br-int',has_traffic_filtering=True,id=cb17c207-b6b1-4528-8c86-6ec60ca00990,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcb17c207-b6') [00;33m{{(pid=807113) unplug /opt/stack/data/venv/lib/python3.10/site-packages/os_vif/__init__.py:109}}[00m
2025-10-14 17:24:43.238 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:43.239 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): DelPortCommand(_result=None, port=tapcb17c207-b6, bridge=br-int, if_exists=True) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:24:43.243 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:43.248 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:43.249 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:43.250 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): DbDestroyCommand(_result=None, table=QoS, record=2ea2153e-3fba-49d4-8769-e8394d3fe92b) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:24:43.252 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:43.255 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:43.260 807113 INFO os_vif [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully unplugged vif VIFOpenVSwitch(active=True,address=fa:16:3e:55:eb:ee,bridge_name='br-int',has_traffic_filtering=True,id=cb17c207-b6b1-4528-8c86-6ec60ca00990,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapcb17c207-b6')
2025-10-14 17:24:43.261 807113 INFO nova.virt.libvirt.driver [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Deleting instance files /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba_del
2025-10-14 17:24:43.262 807113 INFO nova.virt.libvirt.driver [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Deletion of /opt/stack/data/nova/instances/1c5196e6-48bf-42c2-95c5-4db2adce84ba_del complete
2025-10-14 17:24:43.778 807113 INFO nova.compute.manager [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Took 1.59 seconds to destroy the instance on the hypervisor.
2025-10-14 17:24:43.779 807113 DEBUG oslo.service.backend.eventlet.loopingcall [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Waiting for function nova.compute.manager.ComputeManager._try_deallocate_network.<locals>._deallocate_network_with_retries to return. [00;33m{{(pid=807113) func /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/backend/eventlet/loopingcall.py:436}}[00m
2025-10-14 17:24:43.780 807113 DEBUG nova.compute.manager [-] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Deallocating network for instance [00;33m{{(pid=807113) _deallocate_network /opt/stack/nova/nova/compute/manager.py:2296}}[00m
2025-10-14 17:24:43.781 807113 DEBUG nova.network.neutron [-] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] deallocate_for_instance() [00;33m{{(pid=807113) deallocate_for_instance /opt/stack/nova/nova/network/neutron.py:1863}}[00m
2025-10-14 17:24:44.337 807113 DEBUG nova.compute.manager [req-a8a7f34f-8bd8-415c-b928-8deb53644acd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Received event network-vif-deleted-cb17c207-b6b1-4528-8c86-6ec60ca00990 [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:24:44.338 807113 INFO nova.compute.manager [req-a8a7f34f-8bd8-415c-b928-8deb53644acd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Neutron deleted interface cb17c207-b6b1-4528-8c86-6ec60ca00990; detaching it from the instance and deleting it from the info cache
2025-10-14 17:24:44.339 807113 DEBUG nova.network.neutron [req-a8a7f34f-8bd8-415c-b928-8deb53644acd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updating instance_info_cache with network_info: [] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:24:44.795 807113 DEBUG nova.network.neutron [-] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Updating instance_info_cache with network_info: [] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:24:44.848 807113 DEBUG nova.compute.manager [req-a8a7f34f-8bd8-415c-b928-8deb53644acd bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Detach interface failed, port_id=cb17c207-b6b1-4528-8c86-6ec60ca00990, reason: Instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba could not be found. [00;33m{{(pid=807113) _process_instance_vif_deleted_event /opt/stack/nova/nova/compute/manager.py:11602}}[00m
2025-10-14 17:24:45.301 807113 INFO nova.compute.manager [-] [instance: 1c5196e6-48bf-42c2-95c5-4db2adce84ba] Took 1.52 seconds to deallocate network for instance.
2025-10-14 17:24:45.817 807113 DEBUG oslo_concurrency.lockutils [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.update_usage" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:24:45.819 807113 DEBUG oslo_concurrency.lockutils [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.update_usage" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:24:45.917 807113 DEBUG nova.compute.provider_tree [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:24:46.426 807113 DEBUG nova.scheduler.client.report [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:24:46.951 807113 DEBUG oslo_concurrency.lockutils [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.update_usage" :: held 1.133s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:24:47.015 807113 INFO nova.scheduler.client.report [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Deleted allocations for instance 1c5196e6-48bf-42c2-95c5-4db2adce84ba
2025-10-14 17:24:48.034 807113 DEBUG oslo_concurrency.lockutils [req-ae525a3c-6542-4dd6-a245-afa02c275d03 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "1c5196e6-48bf-42c2-95c5-4db2adce84ba" "released" by "nova.compute.manager.ComputeManager.terminate_instance.<locals>.do_terminate_instance" :: held 6.366s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:24:48.258 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:48.259 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:48.260 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:48.260 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:48.261 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:48.263 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:53.264 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:53.266 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:53.267 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5004 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:53.267 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:53.269 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:53.269 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:54.647 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "6d42f8db-d75e-46be-9a7a-aae117646c61" by "nova.compute.manager.ComputeManager.build_and_run_instance.<locals>._locked_do_build_and_run_instance" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:24:54.648 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61" acquired by "nova.compute.manager.ComputeManager.build_and_run_instance.<locals>._locked_do_build_and_run_instance" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:24:55.154 807113 DEBUG nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Starting instance... [00;33m{{(pid=807113) _do_build_and_run_instance /opt/stack/nova/nova/compute/manager.py:2439}}[00m
2025-10-14 17:24:55.710 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.instance_claim" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:24:55.711 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.instance_claim" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:24:55.717 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Require both a host and instance NUMA topology to fit instance on host. [00;33m{{(pid=807113) numa_fit_instance_to_host /opt/stack/nova/nova/virt/hardware.py:2468}}[00m
2025-10-14 17:24:55.718 807113 INFO nova.compute.claims [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Claim successful on node devstack-u2204-93-55
2025-10-14 17:24:56.823 807113 DEBUG nova.compute.provider_tree [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:24:57.331 807113 DEBUG nova.scheduler.client.report [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:24:57.852 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.instance_claim" :: held 2.142s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:24:57.854 807113 DEBUG nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Start building networks asynchronously for instance. [00;33m{{(pid=807113) _build_resources /opt/stack/nova/nova/compute/manager.py:2836}}[00m
2025-10-14 17:24:58.271 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:58.272 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:24:58.273 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:24:58.273 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:58.275 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:24:58.276 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:24:58.374 807113 DEBUG nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Allocating IP information in the background. [00;33m{{(pid=807113) _allocate_network_async /opt/stack/nova/nova/compute/manager.py:1988}}[00m
2025-10-14 17:24:58.375 807113 DEBUG nova.network.neutron [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] allocate_for_instance() [00;33m{{(pid=807113) allocate_for_instance /opt/stack/nova/nova/network/neutron.py:1208}}[00m
2025-10-14 17:24:58.469 807113 DEBUG nova.policy [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Policy check for network:attach_external_network failed with credentials {'is_admin': False, 'user_id': '960a08fcc4d0429e9e879816a305186f', 'user_domain_id': 'default', 'system_scope': None, 'domain_id': None, 'project_id': '1eef17e93cf14f169df902f14b44a4e3', 'project_domain_id': 'default', 'roles': ['member', 'reader'], 'is_admin_project': True, 'service_user_id': None, 'service_user_domain_id': None, 'service_project_id': None, 'service_project_domain_id': None, 'service_roles': []} [00;33m{{(pid=807113) authorize /opt/stack/nova/nova/policy.py:192}}[00m
2025-10-14 17:24:58.881 807113 INFO nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2025-10-14 17:24:59.212 807113 DEBUG nova.network.neutron [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Successfully created port: b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) _create_port_minimal /opt/stack/nova/nova/network/neutron.py:550}}[00m
2025-10-14 17:24:59.290 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:24:59.389 807113 DEBUG nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Start building block device mappings for instance. [00;33m{{(pid=807113) _build_resources /opt/stack/nova/nova/compute/manager.py:2871}}[00m
2025-10-14 17:24:59.802 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:24:59.803 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:24:59.804 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:24:59.804 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:24:59.961 807113 DEBUG nova.network.neutron [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Successfully updated port: b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) _update_port /opt/stack/nova/nova/network/neutron.py:588}}[00m
2025-10-14 17:25:00.015 807113 DEBUG nova.compute.manager [req-5058c7b4-4a4f-49ed-a3a7-2ccd6fe48d28 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Received event network-changed-b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:25:00.016 807113 DEBUG nova.compute.manager [req-5058c7b4-4a4f-49ed-a3a7-2ccd6fe48d28 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Refreshing instance network info cache due to event network-changed-b9d92f2f-7da6-44cb-b0f9-bed2bb601653. [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11773}}[00m
2025-10-14 17:25:00.017 807113 DEBUG oslo_concurrency.lockutils [req-5058c7b4-4a4f-49ed-a3a7-2ccd6fe48d28 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "refresh_cache-6d42f8db-d75e-46be-9a7a-aae117646c61" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:313}}[00m
2025-10-14 17:25:00.017 807113 DEBUG oslo_concurrency.lockutils [req-5058c7b4-4a4f-49ed-a3a7-2ccd6fe48d28 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquired lock "refresh_cache-6d42f8db-d75e-46be-9a7a-aae117646c61" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:316}}[00m
2025-10-14 17:25:00.018 807113 DEBUG nova.network.neutron [req-5058c7b4-4a4f-49ed-a3a7-2ccd6fe48d28 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Refreshing network info cache for port b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) _get_instance_nw_info /opt/stack/nova/nova/network/neutron.py:2067}}[00m
2025-10-14 17:25:00.112 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:25:00.149 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.037s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:25:00.152 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=15171MB free_disk=172.343017578125GB free_vcpus=8 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:25:00.153 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:25:00.154 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:25:00.409 807113 DEBUG nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Start spawning the instance on the hypervisor. [00;33m{{(pid=807113) _build_and_run_instance /opt/stack/nova/nova/compute/manager.py:2645}}[00m
2025-10-14 17:25:00.413 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Creating instance directory [00;33m{{(pid=807113) _create_image /opt/stack/nova/nova/virt/libvirt/driver.py:5186}}[00m
2025-10-14 17:25:00.414 807113 INFO nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Creating image(s)
2025-10-14 17:25:00.415 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "/opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk.info" by "nova.virt.libvirt.imagebackend.Image.resolve_driver_format.<locals>.write_to_disk_info_file" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:25:00.415 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "/opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk.info" acquired by "nova.virt.libvirt.imagebackend.Image.resolve_driver_format.<locals>.write_to_disk_info_file" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:25:00.417 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "/opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk.info" "released" by "nova.virt.libvirt.imagebackend.Image.resolve_driver_format.<locals>.write_to_disk_info_file" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:25:00.418 807113 DEBUG oslo_utils.imageutils.format_inspector [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vmdk does not match, excluding from consideration (Signature KDMV not found: b'\xebH\x90\x00') [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:25:00.426 807113 DEBUG oslo_utils.imageutils.format_inspector [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vhdx does not match, excluding from consideration (Region signature not found at 30000) [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:25:00.430 807113 DEBUG oslo_concurrency.processutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:25:00.471 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "refresh_cache-6d42f8db-d75e-46be-9a7a-aae117646c61" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:313}}[00m
2025-10-14 17:25:00.533 807113 DEBUG oslo_concurrency.processutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json" returned: 0 in 0.104s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:25:00.535 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" by "nova.virt.libvirt.imagebackend.Qcow2.create_image.<locals>.create_qcow2_image" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:25:00.535 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" acquired by "nova.virt.libvirt.imagebackend.Qcow2.create_image.<locals>.create_qcow2_image" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:25:00.536 807113 DEBUG oslo_utils.imageutils.format_inspector [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vmdk does not match, excluding from consideration (Signature KDMV not found: b'\xebH\x90\x00') [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:25:00.541 807113 DEBUG oslo_utils.imageutils.format_inspector [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Format inspector for vhdx does not match, excluding from consideration (Region signature not found at 30000) [00;33m{{(pid=807113) _process_chunk /opt/stack/data/venv/lib/python3.10/site-packages/oslo_utils/imageutils/format_inspector.py:1365}}[00m
2025-10-14 17:25:00.542 807113 DEBUG oslo_concurrency.processutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:25:00.596 807113 DEBUG nova.network.neutron [req-5058c7b4-4a4f-49ed-a3a7-2ccd6fe48d28 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Instance cache missing network info. [00;33m{{(pid=807113) _get_preexisting_port_ids /opt/stack/nova/nova/network/neutron.py:3383}}[00m
2025-10-14 17:25:00.637 807113 DEBUG oslo_concurrency.processutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json" returned: 0 in 0.095s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:25:00.639 807113 DEBUG oslo_concurrency.processutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): env LC_ALL=C LANG=C qemu-img create -f qcow2 -o backing_file=/opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1,backing_fmt=raw /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk 1073741824 [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:25:00.699 807113 DEBUG oslo_concurrency.processutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "env LC_ALL=C LANG=C qemu-img create -f qcow2 -o backing_file=/opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1,backing_fmt=raw /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk 1073741824" returned: 0 in 0.060s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:25:00.701 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "b57f8ab45ab11e9eadc8e5e0467461f381eb37f1" "released" by "nova.virt.libvirt.imagebackend.Qcow2.create_image.<locals>.create_qcow2_image" :: held 0.166s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:25:00.702 807113 DEBUG oslo_concurrency.processutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:25:00.791 807113 DEBUG nova.network.neutron [req-5058c7b4-4a4f-49ed-a3a7-2ccd6fe48d28 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Updating instance_info_cache with network_info: [] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:25:00.807 807113 DEBUG oslo_concurrency.processutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/_base/b57f8ab45ab11e9eadc8e5e0467461f381eb37f1 --force-share --output=json" returned: 0 in 0.105s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:25:00.809 807113 DEBUG nova.virt.disk.api [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Checking if we can resize image /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk. size=1073741824 [00;33m{{(pid=807113) can_resize_image /opt/stack/nova/nova/virt/disk/api.py:164}}[00m
2025-10-14 17:25:00.810 807113 DEBUG oslo_concurrency.processutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:25:00.915 807113 DEBUG oslo_concurrency.processutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk --force-share --output=json" returned: 0 in 0.105s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:25:00.917 807113 DEBUG nova.virt.disk.api [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Cannot resize image /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk to a smaller size. [00;33m{{(pid=807113) can_resize_image /opt/stack/nova/nova/virt/disk/api.py:170}}[00m
2025-10-14 17:25:00.918 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Created local disks [00;33m{{(pid=807113) _create_image /opt/stack/nova/nova/virt/libvirt/driver.py:5318}}[00m
2025-10-14 17:25:00.919 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Ensure instance console log exists: /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/console.log [00;33m{{(pid=807113) _ensure_console_log_for_instance /opt/stack/nova/nova/virt/libvirt/driver.py:5072}}[00m
2025-10-14 17:25:00.920 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "vgpu_resources" by "nova.virt.libvirt.driver.LibvirtDriver._allocate_mdevs" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:25:00.921 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "vgpu_resources" acquired by "nova.virt.libvirt.driver.LibvirtDriver._allocate_mdevs" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:25:00.922 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "vgpu_resources" "released" by "nova.virt.libvirt.driver.LibvirtDriver._allocate_mdevs" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:25:01.292 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 6d42f8db-d75e-46be-9a7a-aae117646c61 actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:25:01.293 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 1 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:25:01.294 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=704MB phys_disk=194GB used_disk=1GB total_vcpus=8 used_vcpus=1 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:25:00 up 1 day,  6:52,  5 users,  load average: 1.19, 2.08, 1.96\n', 'num_instances': '1', 'num_vm_building': '1', 'num_task_spawning': '1', 'num_os_type_None': '1', 'num_proj_1eef17e93cf14f169df902f14b44a4e3': '1', 'io_workload': '1'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:25:01.301 807113 DEBUG oslo_concurrency.lockutils [req-5058c7b4-4a4f-49ed-a3a7-2ccd6fe48d28 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Releasing lock "refresh_cache-6d42f8db-d75e-46be-9a7a-aae117646c61" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:334}}[00m
2025-10-14 17:25:01.304 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquired lock "refresh_cache-6d42f8db-d75e-46be-9a7a-aae117646c61" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:316}}[00m
2025-10-14 17:25:01.305 807113 DEBUG nova.network.neutron [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Building network info cache for instance [00;33m{{(pid=807113) _get_instance_nw_info /opt/stack/nova/nova/network/neutron.py:2070}}[00m
2025-10-14 17:25:01.350 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Refreshing inventories for resource provider 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) _refresh_associations /opt/stack/nova/nova/scheduler/client/report.py:822}}[00m
2025-10-14 17:25:01.390 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Updating ProviderTree inventory for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 from _refresh_and_get_inventory using data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) _refresh_and_get_inventory /opt/stack/nova/nova/scheduler/client/report.py:786}}[00m
2025-10-14 17:25:01.391 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Updating inventory in ProviderTree for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 with inventory: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:176}}[00m
2025-10-14 17:25:01.420 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Refreshing aggregate associations for resource provider 074ba663-40c5-4090-8b4a-a216c63d8a77, aggregates: None [00;33m{{(pid=807113) _refresh_associations /opt/stack/nova/nova/scheduler/client/report.py:831}}[00m
2025-10-14 17:25:01.469 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Refreshing trait associations for resource provider 074ba663-40c5-4090-8b4a-a216c63d8a77, traits: HW_CPU_X86_SSE42,COMPUTE_STORAGE_BUS_SCSI,HW_CPU_X86_SSE,COMPUTE_NET_VIF_MODEL_VIRTIO,COMPUTE_NET_VIF_MODEL_LAN9118,COMPUTE_GRAPHICS_MODEL_VIRTIO,COMPUTE_TRUSTED_CERTS,COMPUTE_NET_VIF_MODEL_E1000,COMPUTE_IMAGE_TYPE_ISO,COMPUTE_NET_VIF_MODEL_SPAPR_VLAN,COMPUTE_IMAGE_TYPE_AMI,COMPUTE_STORAGE_BUS_SATA,HW_CPU_X86_SSSE3,COMPUTE_SOCKET_PCI_NUMA_AFFINITY,COMPUTE_VOLUME_MULTI_ATTACH,COMPUTE_ARCH_AARCH64,COMPUTE_VIOMMU_MODEL_AUTO,COMPUTE_ACCELERATORS,COMPUTE_GRAPHICS_MODEL_NONE,COMPUTE_STORAGE_BUS_IDE,HW_CPU_X86_SSE41,COMPUTE_GRAPHICS_MODEL_VGA,COMPUTE_IMAGE_TYPE_AKI,COMPUTE_NET_VIRTIO_PACKED,COMPUTE_SECURITY_UEFI_SECURE_BOOT,COMPUTE_ARCH_MIPSEL,COMPUTE_NET_VIF_MODEL_E1000E,COMPUTE_NET_ATTACH_INTERFACE_WITH_TAG,COMPUTE_GRAPHICS_MODEL_VMVGA,COMPUTE_ARCH_X86_64,COMPUTE_IMAGE_TYPE_ARI,COMPUTE_NET_VIF_MODEL_VMXNET3,COMPUTE_GRAPHICS_MODEL_QXL,COMPUTE_VIOMMU_MODEL_INTEL,COMPUTE_NET_ATTACH_INTERFACE,COMPUTE_RESCUE_BFV,COMPUTE_STORAGE_BUS_VIRTIO,COMPUTE_VOLUME_EXTEND,COMPUTE_NET_VIF_MODEL_NE2K_PCI,COMPUTE_IMAGE_TYPE_RAW,COMPUTE_STORAGE_BUS_FDC,COMPUTE_ARCH_PPC64LE,COMPUTE_VOLUME_ATTACH_WITH_TAG,COMPUTE_NODE,COMPUTE_ARCH_RISCV64,HW_CPU_X86_MMX,COMPUTE_IMAGE_TYPE_QCOW2,COMPUTE_NET_VIF_MODEL_RTL8139,COMPUTE_GRAPHICS_MODEL_CIRRUS,COMPUTE_NET_VIF_MODEL_PCNET,COMPUTE_GRAPHICS_MODEL_BOCHS,COMPUTE_DEVICE_TAGGING,HW_CPU_X86_SSE2,HW_ARCH_X86_64,COMPUTE_ARCH_S390X,COMPUTE_STORAGE_VIRTIO_FS,COMPUTE_STORAGE_BUS_USB,COMPUTE_VIOMMU_MODEL_SMMUV3 [00;33m{{(pid=807113) _refresh_associations /opt/stack/nova/nova/scheduler/client/report.py:843}}[00m
2025-10-14 17:25:01.557 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:25:01.885 807113 DEBUG nova.network.neutron [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Instance cache missing network info. [00;33m{{(pid=807113) _get_preexisting_port_ids /opt/stack/nova/nova/network/neutron.py:3383}}[00m
2025-10-14 17:25:02.067 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:25:02.181 807113 DEBUG nova.network.neutron [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Updating instance_info_cache with network_info: [{"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:25:02.592 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:25:02.593 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.438s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:25:02.689 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Releasing lock "refresh_cache-6d42f8db-d75e-46be-9a7a-aae117646c61" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:334}}[00m
2025-10-14 17:25:02.690 807113 DEBUG nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Instance network_info: |[{"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}]| [00;33m{{(pid=807113) _allocate_network_async /opt/stack/nova/nova/compute/manager.py:2003}}[00m
2025-10-14 17:25:02.696 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Start _get_guest_xml network_info=[{"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}] disk_info={'disk_bus': 'virtio', 'cdrom_bus': 'ide', 'mapping': {'root': {'bus': 'virtio', 'dev': 'vda', 'type': 'disk', 'boot_index': '1'}, 'disk': {'bus': 'virtio', 'dev': 'vda', 'type': 'disk', 'boot_index': '1'}}} image_meta=ImageMeta(checksum='1352196d1db841ad1931906db5e76ff6',container_format='bare',created_at=2025-10-15T00:04:23Z,direct_url=<?>,disk_format='raw',id=fccdc018-118e-4071-9d16-6a4d7f6e5493,min_disk=0,min_ram=0,name='cirros-0.6.1-x86_64-disk',owner='89c832aae7f04895a3e7cf9ee7f7bb2d',properties=ImageMetaProps,protected=<?>,size=117440512,status='active',tags=<?>,updated_at=2025-10-15T00:04:30Z,virtual_size=<?>,visibility=<?>) rescue=None block_device_info={'root_device_name': '/dev/vda', 'image': [{'encrypted': False, 'boot_index': 0, 'guest_format': None, 'encryption_secret_uuid': None, 'device_type': 'disk', 'disk_bus': 'virtio', 'encryption_format': None, 'device_name': '/dev/vda', 'size': 0, 'encryption_options': None, 'image_id': 'fccdc018-118e-4071-9d16-6a4d7f6e5493'}], 'ephemerals': [], 'block_device_mapping': [], 'swap': None}share_info=None [00;33m{{(pid=807113) _get_guest_xml /opt/stack/nova/nova/virt/libvirt/driver.py:8047}}[00m
2025-10-14 17:25:02.708 807113 DEBUG nova.virt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] InstanceDriverMetadata: InstanceDriverMetadata(root_type='image', root_id='fccdc018-118e-4071-9d16-6a4d7f6e5493', instance_meta=NovaInstanceMeta(name='tempest-VolumeMultiattachTests-server-810971940', uuid='6d42f8db-d75e-46be-9a7a-aae117646c61'), owner=OwnerMeta(userid='960a08fcc4d0429e9e879816a305186f', username='tempest-VolumeMultiattachTests-2017337252-project-member', projectid='1eef17e93cf14f169df902f14b44a4e3', projectname='tempest-VolumeMultiattachTests-2017337252'), image=ImageMeta(id='fccdc018-118e-4071-9d16-6a4d7f6e5493', name=None, properties=ImageMetaProps(hw_architecture=<?>,hw_auto_disk_config=<?>,hw_boot_menu=<?>,hw_cdrom_bus=<?>,hw_cpu_cores=<?>,hw_cpu_max_cores=<?>,hw_cpu_max_sockets=<?>,hw_cpu_max_threads=<?>,hw_cpu_policy=<?>,hw_cpu_realtime_mask=<?>,hw_cpu_sockets=<?>,hw_cpu_thread_policy=<?>,hw_cpu_threads=<?>,hw_device_id=<?>,hw_disk_bus=<?>,hw_disk_type=<?>,hw_emulation_architecture=<?>,hw_ephemeral_encryption=<?>,hw_ephemeral_encryption_format=<?>,hw_ephemeral_encryption_secret_uuid=<?>,hw_firmware_stateless=<?>,hw_firmware_type=<?>,hw_floppy_bus=<?>,hw_input_bus=<?>,hw_ipxe_boot=<?>,hw_locked_memory=<?>,hw_machine_type=<?>,hw_maxphysaddr_bits=<?>,hw_maxphysaddr_mode=<?>,hw_mem_encryption=<?>,hw_mem_page_size=<?>,hw_numa_cpus=<?>,hw_numa_mem=<?>,hw_numa_nodes=<?>,hw_pci_numa_affinity_policy=<?>,hw_pmu=<?>,hw_pointer_model=<?>,hw_qemu_guest_agent=<?>,hw_rescue_bus=<?>,hw_rescue_device=<?>,hw_rng_model='virtio',hw_scsi_model=<?>,hw_serial_port_count=<?>,hw_time_hpet=<?>,hw_tpm_model=<?>,hw_tpm_version=<?>,hw_video_model=<?>,hw_video_ram=<?>,hw_vif_model=<?>,hw_vif_multiqueue_enabled=<?>,hw_viommu_model=<?>,hw_virtio_packed_ring=<?>,hw_vm_mode=<?>,hw_watchdog_action=<?>,img_bdm_v2=<?>,img_bittorrent=<?>,img_block_device_mapping=<?>,img_cache_in_nova=<?>,img_compression_level=<?>,img_config_drive=<?>,img_hide_hypervisor_id=<?>,img_hv_requested_version=<?>,img_hv_type=<?>,img_linked_clone=<?>,img_mappings=<?>,img_owner_id=<?>,img_root_device_name=<?>,img_signature=<?>,img_signature_certificate_uuid=<?>,img_signature_hash_method=<?>,img_signature_key_type=<?>,img_use_agent=<?>,img_version=<?>,os_admin_user=<?>,os_command_line=<?>,os_distro=<?>,os_require_quiesce=<?>,os_secure_boot=<?>,os_skip_agent_inject_files_at_boot=<?>,os_skip_agent_inject_ssh=<?>,os_type=<?>,traits_required=<?>)), flavor=FlavorMeta(name='m1.nano', memory_mb=192, vcpus=1, root_gb=1, ephemeral_gb=0, extra_specs={'hw_rng:allowed': 'True'}, swap=0), network_info=[{"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}], nova_package='31.1.1', creation_time=1760487902.7078662) [00;33m{{(pid=807113) get_instance_driver_metadata /opt/stack/nova/nova/virt/driver.py:401}}[00m
2025-10-14 17:25:02.714 807113 DEBUG nova.virt.libvirt.host [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching host: 'devstack-u2204-93-55' for CPU controller through CGroups V1... [00;33m{{(pid=807113) _has_cgroupsv1_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1695}}[00m
2025-10-14 17:25:02.715 807113 DEBUG nova.virt.libvirt.host [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CPU controller missing on host. [00;33m{{(pid=807113) _has_cgroupsv1_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1705}}[00m
2025-10-14 17:25:02.720 807113 DEBUG nova.virt.libvirt.host [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching host: 'devstack-u2204-93-55' for CPU controller through CGroups V2... [00;33m{{(pid=807113) _has_cgroupsv2_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1714}}[00m
2025-10-14 17:25:02.721 807113 DEBUG nova.virt.libvirt.host [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CPU controller found on host. [00;33m{{(pid=807113) _has_cgroupsv2_cpu_controller /opt/stack/nova/nova/virt/libvirt/host.py:1721}}[00m
2025-10-14 17:25:02.724 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] CPU mode 'custom' models 'Nehalem' was chosen, with extra flags: '' [00;33m{{(pid=807113) _get_guest_cpu_model_config /opt/stack/nova/nova/virt/libvirt/driver.py:5857}}[00m
2025-10-14 17:25:02.725 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Getting desirable topologies for flavor Flavor(created_at=2025-10-15T00:05:26Z,deleted=False,deleted_at=None,description=None,disabled=False,ephemeral_gb=0,extra_specs={hw_rng:allowed='True'},flavorid='42',id=11,is_public=True,memory_mb=192,name='m1.nano',projects=<?>,root_gb=1,rxtx_factor=1.0,swap=0,updated_at=None,vcpu_weight=0,vcpus=1) and image_meta ImageMeta(checksum='1352196d1db841ad1931906db5e76ff6',container_format='bare',created_at=2025-10-15T00:04:23Z,direct_url=<?>,disk_format='raw',id=fccdc018-118e-4071-9d16-6a4d7f6e5493,min_disk=0,min_ram=0,name='cirros-0.6.1-x86_64-disk',owner='89c832aae7f04895a3e7cf9ee7f7bb2d',properties=ImageMetaProps,protected=<?>,size=117440512,status='active',tags=<?>,updated_at=2025-10-15T00:04:30Z,virtual_size=<?>,visibility=<?>), allow threads: True [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:567}}[00m
2025-10-14 17:25:02.727 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Flavor limits 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:352}}[00m
2025-10-14 17:25:02.727 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Image limits 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:356}}[00m
2025-10-14 17:25:02.728 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Flavor pref 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:392}}[00m
2025-10-14 17:25:02.729 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Image pref 0:0:0 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:396}}[00m
2025-10-14 17:25:02.729 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Chose sockets=0, cores=0, threads=0; limits were sockets=65536, cores=65536, threads=65536 [00;33m{{(pid=807113) get_cpu_topology_constraints /opt/stack/nova/nova/virt/hardware.py:434}}[00m
2025-10-14 17:25:02.730 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Topology preferred VirtCPUTopology(cores=0,sockets=0,threads=0), maximum VirtCPUTopology(cores=65536,sockets=65536,threads=65536) [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:573}}[00m
2025-10-14 17:25:02.731 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Build topologies for 1 vcpu(s) 1:1:1 [00;33m{{(pid=807113) _get_possible_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:475}}[00m
2025-10-14 17:25:02.731 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Got 1 possible topologies [00;33m{{(pid=807113) _get_possible_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:505}}[00m
2025-10-14 17:25:02.732 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Possible topologies [VirtCPUTopology(cores=1,sockets=1,threads=1)] [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:579}}[00m
2025-10-14 17:25:02.732 807113 DEBUG nova.virt.hardware [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Sorted desired topologies [VirtCPUTopology(cores=1,sockets=1,threads=1)] [00;33m{{(pid=807113) _get_desirable_cpu_topologies /opt/stack/nova/nova/virt/hardware.py:581}}[00m
2025-10-14 17:25:02.752 807113 DEBUG nova.virt.libvirt.vif [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] vif_type=ovs instance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone='nova',cell_name=None,cleaned=False,compute_id=1,config_drive='',created_at=2025-10-15T00:24:53Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,device_metadata=None,disable_terminate=False,display_description=None,display_name='tempest-VolumeMultiattachTests-server-810971940',ec2_ids=EC2Ids,ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,flavor=Flavor(11),hidden=False,host='devstack-u2204-93-55',hostname='tempest-volumemultiattachtests-server-810971940',id=3,image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',info_cache=InstanceInfoCache,instance_type_id=11,kernel_id='',key_data='ecdsa-sha2-nistp384 AAAAE2VjZHNhLXNoYTItbmlzdHAzODQAAAAIbmlzdHAzODQAAABhBFskQtn5mWzTXnj8PSln/bCfCz+13NawIE/UvT0jD0a2RK//R53958RfCSAuLKwmMeEHcU1qIA636nQP7frAEB4NGLtz6TO5t8uMk6/i6y6Z4n3o7Coo+hoPByNszZ2eZQ==',key_name='tempest-keypair-256554728',keypairs=KeyPairList,launch_index=0,launched_at=None,launched_on='devstack-u2204-93-55',locked=False,locked_by=None,memory_mb=192,metadata={},migration_context=None,new_flavor=None,node='devstack-u2204-93-55',numa_topology=None,old_flavor=None,os_type=None,pci_devices=<?>,pci_requests=InstancePCIRequests,power_state=0,progress=0,project_id='1eef17e93cf14f169df902f14b44a4e3',ramdisk_id='',reservation_id='r-7wvpuh3u',resources=None,root_device_name='/dev/vda',root_gb=1,security_groups=SecurityGroupList,services=<?>,shutdown_terminate=False,system_metadata={boot_roles='member,reader',image_base_image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',image_container_format='bare',image_disk_format='raw',image_hw_machine_type='pc',image_hw_rng_model='virtio',image_min_disk='1',image_min_ram='0',image_owner_specified.openstack.md5='',image_owner_specified.openstack.object='images/cirros-0.6.1-x86_64-disk',image_owner_specified.openstack.sha256='',network_allocated='True',owner_project_name='tempest-VolumeMultiattachTests-2017337252',owner_user_name='tempest-VolumeMultiattachTests-2017337252-project-member'},tags=TagList,task_state='spawning',terminated_at=None,trusted_certs=None,updated_at=2025-10-15T00:24:59Z,user_data='IyEvYmluL3NoCmVjaG8gIlByaW50aW5nIGNpcnJvcyB1c2VyIGF1dGhvcml6ZWQga2V5cyIKY2F0IH5jaXJyb3MvLnNzaC9hdXRob3JpemVkX2tleXMgfHwgdHJ1ZQo=',user_id='960a08fcc4d0429e9e879816a305186f',uuid=6d42f8db-d75e-46be-9a7a-aae117646c61,vcpu_model=VirtCPUModel,vcpus=1,vm_mode=None,vm_state='building') vif={"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} virt_type=qemu [00;33m{{(pid=807113) get_config /opt/stack/nova/nova/virt/libvirt/vif.py:574}}[00m
2025-10-14 17:25:02.752 807113 DEBUG nova.network.os_vif_util [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converting VIF {"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:511}}[00m
2025-10-14 17:25:02.753 807113 DEBUG nova.network.os_vif_util [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converted object VIFOpenVSwitch(active=False,address=fa:16:3e:ae:dd:42,bridge_name='br-int',has_traffic_filtering=True,id=b9d92f2f-7da6-44cb-b0f9-bed2bb601653,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapb9d92f2f-7d') [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:548}}[00m
2025-10-14 17:25:02.755 807113 DEBUG nova.objects.instance [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'pci_devices' on Instance uuid 6d42f8db-d75e-46be-9a7a-aae117646c61 [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:25:03.262 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] End _get_guest_xml xml=<domain type="qemu">
  <uuid>6d42f8db-d75e-46be-9a7a-aae117646c61</uuid>
  <name>instance-00000003</name>
  <memory>196608</memory>
  <vcpu>1</vcpu>
  <metadata>
    <nova:instance xmlns:nova="http://openstack.org/xmlns/libvirt/nova/1.1">
      <nova:package version="31.1.1"/>
      <nova:name>tempest-VolumeMultiattachTests-server-810971940</nova:name>
      <nova:creationTime>2025-10-15 00:25:02</nova:creationTime>
      <nova:flavor name="m1.nano">
        <nova:memory>192</nova:memory>
        <nova:disk>1</nova:disk>
        <nova:swap>0</nova:swap>
        <nova:ephemeral>0</nova:ephemeral>
        <nova:vcpus>1</nova:vcpus>
      </nova:flavor>
      <nova:owner>
        <nova:user uuid="960a08fcc4d0429e9e879816a305186f">tempest-VolumeMultiattachTests-2017337252-project-member</nova:user>
        <nova:project uuid="1eef17e93cf14f169df902f14b44a4e3">tempest-VolumeMultiattachTests-2017337252</nova:project>
      </nova:owner>
      <nova:root type="image" uuid="fccdc018-118e-4071-9d16-6a4d7f6e5493"/>
      <nova:ports>
        <nova:port uuid="b9d92f2f-7da6-44cb-b0f9-bed2bb601653">
          <nova:ip type="fixed" address="10.1.0.5" ipVersion="4"/>
        </nova:port>
      </nova:ports>
    </nova:instance>
  </metadata>
  <sysinfo type="smbios">
    <system>
      <entry name="manufacturer">OpenStack Foundation</entry>
      <entry name="product">OpenStack Nova</entry>
      <entry name="version">31.1.1</entry>
      <entry name="serial">6d42f8db-d75e-46be-9a7a-aae117646c61</entry>
      <entry name="uuid">6d42f8db-d75e-46be-9a7a-aae117646c61</entry>
      <entry name="family">Virtual Machine</entry>
    </system>
  </sysinfo>
  <os>
    <type arch="x86_64" machine="pc">hvm</type>
    <boot dev="hd"/>
    <smbios mode="sysinfo"/>
  </os>
  <features>
    <acpi/>
    <vmcoreinfo/>
  </features>
  <clock offset="utc"/>
  <cpu mode="custom" match="exact">
    <model>Nehalem</model>
    <topology sockets="1" cores="1" threads="1"/>
  </cpu>
  <devices>
    <disk type="file" device="disk">
      <driver name="qemu" type="qcow2" cache="none"/>
      <source file="/opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk"/>
      <target dev="vda" bus="virtio"/>
    </disk>
    <interface type="ethernet">
      <mac address="fa:16:3e:ae:dd:42"/>
      <model type="virtio"/>
      <driver name="qemu"/>
      <mtu size="1450"/>
      <target dev="tapb9d92f2f-7d"/>
    </interface>
    <serial type="pty">
      <log file="/opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/console.log" append="off"/>
    </serial>
    <graphics type="vnc" autoport="yes" listen="0.0.0.0"/>
    <video>
      <model type="virtio"/>
    </video>
    <rng model="virtio">
      <backend model="random">/dev/urandom</backend>
    </rng>
    <controller type="usb" index="0" model="none"/>
    <memballoon model="virtio">
      <stats period="10"/>
    </memballoon>
  </devices>
</domain>
 [00;33m{{(pid=807113) _get_guest_xml /opt/stack/nova/nova/virt/libvirt/driver.py:8053}}[00m
2025-10-14 17:25:03.264 807113 DEBUG nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Preparing to wait for external event network-vif-plugged-b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) prepare_for_instance_event /opt/stack/nova/nova/compute/manager.py:285}}[00m
2025-10-14 17:25:03.265 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" by "nova.compute.manager.InstanceEvents.prepare_for_instance_event.<locals>._create_or_get_event" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:25:03.266 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" acquired by "nova.compute.manager.InstanceEvents.prepare_for_instance_event.<locals>._create_or_get_event" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:25:03.267 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" "released" by "nova.compute.manager.InstanceEvents.prepare_for_instance_event.<locals>._create_or_get_event" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:25:03.269 807113 DEBUG nova.virt.libvirt.vif [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] vif_type=ovs instance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone='nova',cell_name=None,cleaned=False,compute_id=1,config_drive='',created_at=2025-10-15T00:24:53Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,device_metadata=None,disable_terminate=False,display_description=None,display_name='tempest-VolumeMultiattachTests-server-810971940',ec2_ids=EC2Ids,ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,flavor=Flavor(11),hidden=False,host='devstack-u2204-93-55',hostname='tempest-volumemultiattachtests-server-810971940',id=3,image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',info_cache=InstanceInfoCache,instance_type_id=11,kernel_id='',key_data='ecdsa-sha2-nistp384 AAAAE2VjZHNhLXNoYTItbmlzdHAzODQAAAAIbmlzdHAzODQAAABhBFskQtn5mWzTXnj8PSln/bCfCz+13NawIE/UvT0jD0a2RK//R53958RfCSAuLKwmMeEHcU1qIA636nQP7frAEB4NGLtz6TO5t8uMk6/i6y6Z4n3o7Coo+hoPByNszZ2eZQ==',key_name='tempest-keypair-256554728',keypairs=KeyPairList,launch_index=0,launched_at=None,launched_on='devstack-u2204-93-55',locked=False,locked_by=None,memory_mb=192,metadata={},migration_context=None,new_flavor=None,node='devstack-u2204-93-55',numa_topology=None,old_flavor=None,os_type=None,pci_devices=PciDeviceList,pci_requests=InstancePCIRequests,power_state=0,progress=0,project_id='1eef17e93cf14f169df902f14b44a4e3',ramdisk_id='',reservation_id='r-7wvpuh3u',resources=None,root_device_name='/dev/vda',root_gb=1,security_groups=SecurityGroupList,services=<?>,shutdown_terminate=False,system_metadata={boot_roles='member,reader',image_base_image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',image_container_format='bare',image_disk_format='raw',image_hw_machine_type='pc',image_hw_rng_model='virtio',image_min_disk='1',image_min_ram='0',image_owner_specified.openstack.md5='',image_owner_specified.openstack.object='images/cirros-0.6.1-x86_64-disk',image_owner_specified.openstack.sha256='',network_allocated='True',owner_project_name='tempest-VolumeMultiattachTests-2017337252',owner_user_name='tempest-VolumeMultiattachTests-2017337252-project-member'},tags=TagList,task_state='spawning',terminated_at=None,trusted_certs=None,updated_at=2025-10-15T00:24:59Z,user_data='IyEvYmluL3NoCmVjaG8gIlByaW50aW5nIGNpcnJvcyB1c2VyIGF1dGhvcml6ZWQga2V5cyIKY2F0IH5jaXJyb3MvLnNzaC9hdXRob3JpemVkX2tleXMgfHwgdHJ1ZQo=',user_id='960a08fcc4d0429e9e879816a305186f',uuid=6d42f8db-d75e-46be-9a7a-aae117646c61,vcpu_model=VirtCPUModel,vcpus=1,vm_mode=None,vm_state='building') vif={"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) plug /opt/stack/nova/nova/virt/libvirt/vif.py:721}}[00m
2025-10-14 17:25:03.270 807113 DEBUG nova.network.os_vif_util [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converting VIF {"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": []}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": false, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:511}}[00m
2025-10-14 17:25:03.272 807113 DEBUG nova.network.os_vif_util [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converted object VIFOpenVSwitch(active=False,address=fa:16:3e:ae:dd:42,bridge_name='br-int',has_traffic_filtering=True,id=b9d92f2f-7da6-44cb-b0f9-bed2bb601653,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapb9d92f2f-7d') [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:548}}[00m
2025-10-14 17:25:03.273 807113 DEBUG os_vif [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Plugging vif VIFOpenVSwitch(active=False,address=fa:16:3e:ae:dd:42,bridge_name='br-int',has_traffic_filtering=True,id=b9d92f2f-7da6-44cb-b0f9-bed2bb601653,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapb9d92f2f-7d') [00;33m{{(pid=807113) plug /opt/stack/data/venv/lib/python3.10/site-packages/os_vif/__init__.py:76}}[00m
2025-10-14 17:25:03.275 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:03.277 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): AddBridgeCommand(_result=None, name=br-int, may_exist=True, datapath_type=system) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:25:03.278 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Transaction caused no change [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:129}}[00m
2025-10-14 17:25:03.280 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:03.281 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5005 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:25:03.281 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:25:03.282 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): DbCreateCommand(_result=None, table=QoS, columns={'type': 'linux-noop', 'external_ids': {'id': '7b24da8f-7ecf-545b-a501-d05f7333818e', '_type': 'linux-noop'}}, row=False) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:25:03.284 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:25:03.284 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:03.290 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:25:03.295 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:03.295 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): AddPortCommand(_result=None, bridge=br-int, port=tapb9d92f2f-7d, may_exist=True, interface_attrs={}) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:25:03.297 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=1): DbSetCommand(_result=None, table=Port, record=tapb9d92f2f-7d, col_values=(('qos', UUID('aa9613c9-c3c1-4ac1-90b3-282d788cc90d')),), if_exists=True) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:25:03.298 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=2): DbSetCommand(_result=None, table=Interface, record=tapb9d92f2f-7d, col_values=(('external_ids', {'iface-id': 'b9d92f2f-7da6-44cb-b0f9-bed2bb601653', 'iface-status': 'active', 'attached-mac': 'fa:16:3e:ae:dd:42', 'vm-uuid': '6d42f8db-d75e-46be-9a7a-aae117646c61'}),), if_exists=True) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:25:03.301 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:03.306 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:25:03.317 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:03.321 807113 INFO os_vif [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully plugged vif VIFOpenVSwitch(active=False,address=fa:16:3e:ae:dd:42,bridge_name='br-int',has_traffic_filtering=True,id=b9d92f2f-7da6-44cb-b0f9-bed2bb601653,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapb9d92f2f-7d')
2025-10-14 17:25:03.593 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:25:03.594 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:25:03.595 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:25:03.596 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:25:03.597 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:25:03.597 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:25:04.288 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:25:04.793 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:04.803 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:04.809 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:04.824 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:04.864 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vda, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:25:04.865 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No VIF found with MAC fa:16:3e:ae:dd:42, not building metadata [00;33m{{(pid=807113) _build_interface_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12794}}[00m
2025-10-14 17:25:05.082 807113 DEBUG nova.compute.manager [req-adabf140-3697-4811-af71-d5aa2b5a7183 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Received event network-vif-plugged-b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:25:05.083 807113 DEBUG oslo_concurrency.lockutils [req-adabf140-3697-4811-af71-d5aa2b5a7183 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:25:05.084 807113 DEBUG oslo_concurrency.lockutils [req-adabf140-3697-4811-af71-d5aa2b5a7183 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" acquired by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:25:05.084 807113 DEBUG oslo_concurrency.lockutils [req-adabf140-3697-4811-af71-d5aa2b5a7183 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" "released" by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:25:05.085 807113 DEBUG nova.compute.manager [req-adabf140-3697-4811-af71-d5aa2b5a7183 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Processing event network-vif-plugged-b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) _process_instance_event /opt/stack/nova/nova/compute/manager.py:11528}}[00m
2025-10-14 17:25:06.049 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:06.061 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:06.734 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:07.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:25:08.044 807113 DEBUG nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Instance event wait completed in 0 seconds for network-vif-plugged [00;33m{{(pid=807113) wait_for_instance_event /opt/stack/nova/nova/compute/manager.py:579}}[00m
2025-10-14 17:25:08.052 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Guest created on hypervisor [00;33m{{(pid=807113) spawn /opt/stack/nova/nova/virt/libvirt/driver.py:4871}}[00m
2025-10-14 17:25:08.059 807113 INFO nova.virt.libvirt.driver [-] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Instance spawned successfully.
2025-10-14 17:25:08.061 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Attempting to register defaults for the following image properties: ['hw_cdrom_bus', 'hw_disk_bus', 'hw_input_bus', 'hw_pointer_model', 'hw_video_model', 'hw_vif_model'] [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1006}}[00m
2025-10-14 17:25:08.580 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Found default for hw_cdrom_bus of ide [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:25:08.581 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Found default for hw_disk_bus of virtio [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:25:08.583 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Found default for hw_input_bus of None [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:25:08.584 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Found default for hw_pointer_model of None [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:25:08.585 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Found default for hw_video_model of virtio [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:25:08.586 807113 DEBUG nova.virt.libvirt.driver [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Found default for hw_vif_model of virtio [00;33m{{(pid=807113) _register_undefined_instance_details /opt/stack/nova/nova/virt/libvirt/driver.py:1035}}[00m
2025-10-14 17:25:09.098 807113 INFO nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Took 8.69 seconds to spawn the instance on the hypervisor.
2025-10-14 17:25:09.099 807113 DEBUG nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Checking state [00;33m{{(pid=807113) _get_power_state /opt/stack/nova/nova/compute/manager.py:1798}}[00m
2025-10-14 17:25:09.628 807113 INFO nova.compute.manager [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Took 13.96 seconds to build instance.
2025-10-14 17:25:10.134 807113 DEBUG oslo_concurrency.lockutils [req-31057824-be04-4c2c-87f8-1dca004b3bf0 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61" "released" by "nova.compute.manager.ComputeManager.build_and_run_instance.<locals>._locked_do_build_and_run_instance" :: held 15.486s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:25:11.161 807113 DEBUG nova.compute.manager [req-2cad7ec6-6e81-4056-8151-2f0def429d14 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Received event network-changed-b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:25:11.162 807113 DEBUG nova.compute.manager [req-2cad7ec6-6e81-4056-8151-2f0def429d14 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Refreshing instance network info cache due to event network-changed-b9d92f2f-7da6-44cb-b0f9-bed2bb601653. [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11773}}[00m
2025-10-14 17:25:11.163 807113 DEBUG oslo_concurrency.lockutils [req-2cad7ec6-6e81-4056-8151-2f0def429d14 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "refresh_cache-6d42f8db-d75e-46be-9a7a-aae117646c61" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:313}}[00m
2025-10-14 17:25:11.164 807113 DEBUG oslo_concurrency.lockutils [req-2cad7ec6-6e81-4056-8151-2f0def429d14 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquired lock "refresh_cache-6d42f8db-d75e-46be-9a7a-aae117646c61" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:316}}[00m
2025-10-14 17:25:11.165 807113 DEBUG nova.network.neutron [req-2cad7ec6-6e81-4056-8151-2f0def429d14 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Refreshing network info cache for port b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) _get_instance_nw_info /opt/stack/nova/nova/network/neutron.py:2067}}[00m
2025-10-14 17:25:11.737 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:25:11.739 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:25:11.740 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:25:11.741 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:25:11.747 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:25:12.208 807113 DEBUG nova.network.neutron [req-2cad7ec6-6e81-4056-8151-2f0def429d14 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Updated VIF entry in instance network info cache for port b9d92f2f-7da6-44cb-b0f9-bed2bb601653. [00;33m{{(pid=807113) _build_network_info_model /opt/stack/nova/nova/network/neutron.py:3542}}[00m
2025-10-14 17:25:12.209 807113 DEBUG nova.network.neutron [req-2cad7ec6-6e81-4056-8151-2f0def429d14 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Updating instance_info_cache with network_info: [{"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": [{"address": "172.24.5.89", "type": "floating", "version": 4, "meta": {}}]}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": true, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}}] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:25:12.717 807113 DEBUG oslo_concurrency.lockutils [req-2cad7ec6-6e81-4056-8151-2f0def429d14 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Releasing lock "refresh_cache-6d42f8db-d75e-46be-9a7a-aae117646c61" [00;33m{{(pid=807113) lock /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:334}}[00m
2025-10-14 17:25:16.745 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:21.743 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:21.749 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:26.753 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:31.745 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:31.757 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:36.761 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:41.747 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:41.765 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:46.769 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:51.750 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:51.773 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:25:56.777 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:00.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:26:00.804 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:26:00.805 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:26:00.806 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:26:00.806 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:26:01.752 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:01.781 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:01.862 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:01.968 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk --force-share --output=json" returned: 0 in 0.106s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:01.972 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:02.074 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk --force-share --output=json" returned: 0 in 0.102s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:02.323 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:02.363 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.039s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:02.365 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=14680MB free_disk=172.31503677368164GB free_vcpus=7 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:26:02.366 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:26:02.368 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:26:03.441 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 6d42f8db-d75e-46be-9a7a-aae117646c61 actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:26:03.442 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 1 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:26:03.443 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=704MB phys_disk=194GB used_disk=1GB total_vcpus=8 used_vcpus=1 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:26:02 up 1 day,  6:53,  5 users,  load average: 1.46, 2.01, 1.95\n', 'num_instances': '1', 'num_vm_active': '1', 'num_task_None': '1', 'num_os_type_None': '1', 'num_proj_1eef17e93cf14f169df902f14b44a4e3': '1', 'io_workload': '0'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:26:03.532 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:26:04.040 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:26:04.557 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:26:04.558 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.191s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:26:05.560 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_scheduler_instance_info [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:26:05.560 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:26:05.561 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:26:05.562 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:26:05.562 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:26:05.563 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:26:05.563 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:26:06.288 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:26:06.786 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:07.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:26:11.754 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:11.789 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:16.794 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:21.757 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:21.798 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:26.801 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:28.191 807113 DEBUG oslo_concurrency.lockutils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "6d42f8db-d75e-46be-9a7a-aae117646c61" by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:26:28.192 807113 DEBUG oslo_concurrency.lockutils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61" acquired by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:26:28.703 807113 DEBUG nova.objects.instance [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 6d42f8db-d75e-46be-9a7a-aae117646c61 [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:26:29.719 807113 DEBUG oslo_concurrency.lockutils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61" "released" by "nova.compute.manager.ComputeManager.reserve_block_device_name.<locals>.do_reserve" :: held 1.526s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:26:30.887 807113 DEBUG oslo_concurrency.lockutils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "6d42f8db-d75e-46be-9a7a-aae117646c61" by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:26:30.888 807113 DEBUG oslo_concurrency.lockutils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61" acquired by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:26:30.889 807113 INFO nova.compute.manager [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Attaching volume 581eedfe-5388-4155-890a-ee7847220e3c to /dev/vdb
2025-10-14 17:26:30.989 807113 DEBUG os_brick.utils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> get_connector_properties: call "{'root_helper': 'sudo nova-rootwrap /etc/nova/rootwrap.conf', 'my_ip': '172.25.93.55', 'multipath': False, 'enforce_multipath': True, 'host': 'devstack-u2204-93-55', 'execute': None}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:26:30.993 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): cat /etc/iscsi/initiatorname.iscsi [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:31.009 826121 DEBUG oslo_concurrency.processutils [-] CMD "cat /etc/iscsi/initiatorname.iscsi" returned: 0 in 0.016s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:31.010 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[d4db7f9d-4033-4171-8299-19a00b7b4067]: (4, ('InitiatorName=iqn.2016-04.com.open-iscsi:851997e07f81\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:31.014 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): findmnt -v / -n -o SOURCE [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:31.033 826121 DEBUG oslo_concurrency.processutils [-] CMD "findmnt -v / -n -o SOURCE" returned: 0 in 0.018s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:31.034 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[ccfa99ef-0a2d-4d71-839b-cbc4528117e4]: (4, ('/dev/sda2\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:31.037 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): blkid /dev/sda2 -s UUID -o value [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:31.058 826121 DEBUG oslo_concurrency.processutils [-] CMD "blkid /dev/sda2 -s UUID -o value" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:31.059 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[b1dbddd3-1b45-4bdb-9557-7c696be185c8]: (4, ('849a1340-77d5-4de3-852c-cf0210ca78af\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:31.063 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[62491f9c-6586-4cff-be41-d991a535ac09]: (4, '89b11b42-6ca2-76fb-88b9-4b0fae22b322') [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:31.064 807113 DEBUG oslo_concurrency.processutils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Running cmd (subprocess): nvme version [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:31.097 807113 DEBUG oslo_concurrency.processutils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] 'nvme version' failed. Not Retrying. [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:26:31.101 807113 DEBUG os_brick.initiator.connectors.nvmeof [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] nvme not present on system [00;33m{{(pid=807113) nvme_present /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/nvmeof.py:784}}[00m
2025-10-14 17:26:31.104 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): nvme show-hostnqn [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:31.117 826121 DEBUG oslo_concurrency.processutils [-] 'nvme show-hostnqn' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:26:31.118 826121 WARNING os_brick.privileged.nvmeof [-] Could not generate host nqn: [Errno 2] No such file or directory: 'nvme'
2025-10-14 17:26:31.118 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[52880da8-af0b-4bcc-be16-0619d31e0bf7]: (4, '') [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:31.126 807113 DEBUG os_brick.initiator.connectors.lightos [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: [Errno 111] ECONNREFUSED [00;33m{{(pid=807113) find_dsc /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:135}}[00m
2025-10-14 17:26:31.130 807113 INFO os_brick.initiator.connectors.lightos [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Current host hostNQN  and IP(s) are ['172.25.93.55', 'fe80::387c:9d0a:2c22:5c64', '192.168.122.1', '172.24.5.1', 'fe80::7c4c:53ff:fed4:fe47', 'fe80::fc16:3eff:feae:dd42'] 
2025-10-14 17:26:31.131 807113 DEBUG os_brick.initiator.connectors.lightos [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: did not find dsc, continuing anyway. [00;33m{{(pid=807113) get_connector_properties /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:112}}[00m
2025-10-14 17:26:31.132 807113 DEBUG os_brick.initiator.connectors.lightos [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] LIGHTOS: no hostnqn found. [00;33m{{(pid=807113) get_connector_properties /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/lightos.py:121}}[00m
2025-10-14 17:26:31.133 807113 DEBUG os_brick.utils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== get_connector_properties: return (142ms) {'platform': 'x86_64', 'os_type': 'linux', 'ip': '172.25.93.55', 'host': 'devstack-u2204-93-55', 'multipath': False, 'enforce_multipath': True, 'initiator': 'iqn.2016-04.com.open-iscsi:851997e07f81', 'do_local_attach': False, 'uuid': '849a1340-77d5-4de3-852c-cf0210ca78af', 'system uuid': '89b11b42-6ca2-76fb-88b9-4b0fae22b322', 'nvme_native_multipath': False} [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:26:31.134 807113 DEBUG nova.virt.block_device [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Updating existing volume attachment record: c582e222-f633-4978-8e56-e4ba3656041c [00;33m{{(pid=807113) _volume_attach /opt/stack/nova/nova/virt/block_device.py:666}}[00m
2025-10-14 17:26:31.760 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:31.805 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:36.812 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4997-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:26:36.814 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:26:36.814 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:26:36.815 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:26:36.817 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:36.818 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:26:39.257 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Calling os-brick to attach iSCSI Volume [00;33m{{(pid=807113) connect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:64}}[00m
2025-10-14 17:26:39.258 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> connect_volume: call "{'self': <os_brick.initiator.connectors.iscsi.ISCSIConnector object at 0x7a59504d4550>, 'connection_properties': {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 0, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True}}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:26:39.259 807113 DEBUG os_brick.initiator.connectors.base [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_volume" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:26:39.261 807113 DEBUG os_brick.initiator.connectors.base [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:26:39.261 807113 DEBUG os_brick.initiator.connectors.base [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connection properties {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 0, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True} [00;33m{{(pid=807113) check_multipath /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:133}}[00m
2025-10-14 17:26:39.263 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): multipathd show status [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:39.280 826121 DEBUG oslo_concurrency.processutils [-] 'multipathd show status' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:26:39.281 826121 DEBUG oslo.privsep.daemon [-] privsep: Exception during request[7fd97e6e-ab8b-41aa-b225-e2bc200a0ed6]: [Errno 2] No such file or directory: 'multipathd' [00;33m{{(pid=826121) _process_cmd /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:481}}[00m
Traceback (most recent call last):
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py", line 478, in _process_cmd
    ret = func(*f_args, **f_kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/priv_context.py", line 266, in _wrap
    return func(*args, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 198, in execute_root
    return custom_execute(*cmd, shell=False, run_as_root=False, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 146, in custom_execute
    return putils.execute(on_execute=on_execute,
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py", line 354, in execute
    obj = subprocess.Popen(cmd,
  File "/usr/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'multipathd'
2025-10-14 17:26:39.284 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[7fd97e6e-ab8b-41aa-b225-e2bc200a0ed6]: (5, 'builtins.FileNotFoundError', (2, 'No such file or directory')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:39.287 807113 DEBUG os_brick.initiator.connectors.base [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:26:39.289 807113 DEBUG os_brick.initiator.connectors.base [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:26:39.290 807113 INFO os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Trying to connect to iSCSI portal 172.25.59.221:3260
2025-10-14 17:26:39.292 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:39.312 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260" returned: 21 in 0.020s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:39.313 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[9119e97a-8bb2-40d4-af7a-e81c08a2ff6b]: (4, ('', 'iscsiadm: No records found\n')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:39.315 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm (): stdout= stderr=iscsiadm: No records found
 [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:26:39.317 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --interface default --op new [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:39.338 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --interface default --op new" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:39.340 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[60409982-8d93-4a33-9099-9af1b933f956]: (4, ('New iSCSI node [tcp:[hw=,ip=,net_if=,iscsi_if=default] 172.25.59.221,3260,-1 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target] added\n', 'iscsiadm: config file line 337 do not has value\niscsiadm: config file line 337 do not has value\niscsiadm: config file line 337 do not has value\niscsiadm: config file line 337 do not has value\n')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:39.341 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--interface', 'default', '--op', 'new'): stdout=New iSCSI node [tcp:[hw=,ip=,net_if=,iscsi_if=default] 172.25.59.221,3260,-1 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target] added
 stderr=iscsiadm: config file line 337 do not has value
iscsiadm: config file line 337 do not has value
iscsiadm: config file line 337 do not has value
iscsiadm: config file line 337 do not has value
 [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:26:39.342 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Retrying to connect to iSCSI portal 172.25.59.221:3260 [00;33m{{(pid=807113) _connect_to_iscsi_portal_unsafe /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1131}}[00m
2025-10-14 17:26:39.344 807113 DEBUG os_brick.utils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Finished call to 'os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe' after 0.054(s), this was the 1st time calling it. [00;33m{{(pid=807113) log_it /opt/stack/data/venv/lib/python3.10/site-packages/tenacity/after.py:44}}[00m
2025-10-14 17:26:39.345 807113 DEBUG os_brick.utils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Retrying os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe in 1.0 seconds as it raised BrickException: An unknown exception occurred.. [00;33m{{(pid=807113) log_it /opt/stack/data/venv/lib/python3.10/site-packages/tenacity/before_sleep.py:65}}[00m
2025-10-14 17:26:40.346 807113 INFO os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Trying to connect to iSCSI portal 172.25.59.221:3260
2025-10-14 17:26:40.349 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:40.370 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:40.372 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[5365e56c-3126-4da2-aea8-339a1d196fe0]: (4, ('# BEGIN RECORD 2.1.5\nnode.name = iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\nnode.tpgt = -1\nnode.startup = manual\nnode.leading_login = No\niface.iscsi_ifacename = default\niface.net_ifacename = <empty>\niface.ipaddress = <empty>\niface.prefix_len = 0\niface.hwaddress = <empty>\niface.transport_name = tcp\niface.initiatorname = <empty>\niface.state = <empty>\niface.vlan_id = 0\niface.vlan_priority = 0\niface.vlan_state = <empty>\niface.iface_num = 0\niface.mtu = 0\niface.port = 0\niface.bootproto = <empty>\niface.subnet_mask = <empty>\niface.gateway = <empty>\niface.dhcp_alt_client_id_state = <empty>\niface.dhcp_alt_client_id = <empty>\niface.dhcp_dns = <empty>\niface.dhcp_learn_iqn = <empty>\niface.dhcp_req_vendor_id_state = <empty>\niface.dhcp_vendor_id_state = <empty>\niface.dhcp_vendor_id = <empty>\niface.dhcp_slp_da = <empty>\niface.fragmentation = <empty>\niface.gratuitous_arp = <empty>\niface.incoming_forwarding = <empty>\niface.tos_state = <empty>\niface.tos = 0\niface.ttl = 0\niface.delayed_ack = <empty>\niface.tcp_nagle = <empty>\niface.tcp_wsf_state = <empty>\niface.tcp_wsf = 0\niface.tcp_timer_scale = 0\niface.tcp_timestamp = <empty>\niface.redirect = <empty>\niface.def_task_mgmt_timeout = 0\niface.header_digest = <empty>\niface.data_digest = <empty>\niface.immediate_data = <empty>\niface.initial_r2t = <empty>\niface.data_seq_inorder = <empty>\niface.data_pdu_inorder = <empty>\niface.erl = 0\niface.max_receive_data_len = 0\niface.first_burst_len = 0\niface.max_outstanding_r2t = 0\niface.max_burst_len = 0\niface.chap_auth = <empty>\niface.bidi_chap = <empty>\niface.strict_login_compliance = <empty>\niface.discovery_auth = <empty>\niface.discovery_logout = <empty>\nnode.discovery_address = <empty>\nnode.discovery_port = 0\nnode.discovery_type = static\nnode.session.initial_cmdsn = 0\nnode.session.initial_login_retry_max = 8\nnode.session.xmit_thread_priority = -20\nnode.session.cmds_max = 128\nnode.session.queue_depth = 32\nnode.session.nr_sessions = 1\nnode.session.auth.authmethod = None\nnode.session.auth.username = <empty>\nnode.session.auth.password = <empty>\nnode.session.auth.username_in = <empty>\nnode.session.auth.password_in = <empty>\nnode.session.auth.chap_algs = SHA3-256,SHA256\nnode.session.timeo.replacement_timeout = 120\nnode.session.err_timeo.abort_timeout = 15\nnode.session.err_timeo.lu_reset_timeout = 30\nnode.session.err_timeo.tgt_reset_timeout = 30\nnode.session.err_timeo.host_reset_timeout = 60\nnode.session.iscsi.FastAbort = Yes\nnode.session.iscsi.InitialR2T = No\nnode.session.iscsi.ImmediateData = Yes\nnode.session.iscsi.FirstBurstLength = 262144\nnode.session.iscsi.MaxBurstLength = 16776192\nnode.session.iscsi.DefaultTime2Retain = 0\nnode.session.iscsi.DefaultTime2Wait = 2\nnode.session.iscsi.MaxConnections = 1\nnode.session.iscsi.MaxOutstandingR2T = 1\nnode.session.iscsi.ERL = 0\nnode.session.scan = auto\nnode.session.reopen_max = 0\nnode.conn[0].address = 172.25.59.221\nnode.conn[0].port = 3260\nnode.conn[0].startup = manual\nnode.conn[0].tcp.window_size = 524288\nnode.conn[0].tcp.type_of_service = 0\nnode.conn[0].timeo.logout_timeout = 15\nnode.conn[0].timeo.login_timeout = 15\nnode.conn[0].timeo.auth_timeout = 45\nnode.conn[0].timeo.noop_out_interval = 5\nnode.conn[0].timeo.noop_out_timeout = 5\nnode.conn[0].iscsi.MaxXmitDataSegmentLength = 0\nnode.conn[0].iscsi.MaxRecvDataSegmentLength = 262144\nnode.conn[0].iscsi.HeaderDigest = None\nnode.conn[0].iscsi.DataDigest = None\nnode.conn[0].iscsi.IFMarker = No\nnode.conn[0].iscsi.OFMarker = No\n# END RECORD\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:40.376 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm (): stdout=# BEGIN RECORD 2.1.5
node.name = iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target
node.tpgt = -1
node.startup = manual
node.leading_login = No
iface.iscsi_ifacename = default
iface.net_ifacename = <empty>
iface.ipaddress = <empty>
iface.prefix_len = 0
iface.hwaddress = <empty>
iface.transport_name = tcp
iface.initiatorname = <empty>
iface.state = <empty>
iface.vlan_id = 0
iface.vlan_priority = 0
iface.vlan_state = <empty>
iface.iface_num = 0
iface.mtu = 0
iface.port = 0
iface.bootproto = <empty>
iface.subnet_mask = <empty>
iface.gateway = <empty>
iface.dhcp_alt_client_id_state = <empty>
iface.dhcp_alt_client_id = <empty>
iface.dhcp_dns = <empty>
iface.dhcp_learn_iqn = <empty>
iface.dhcp_req_vendor_id_state = <empty>
iface.dhcp_vendor_id_state = <empty>
iface.dhcp_vendor_id = <empty>
iface.dhcp_slp_da = <empty>
iface.fragmentation = <empty>
iface.gratuitous_arp = <empty>
iface.incoming_forwarding = <empty>
iface.tos_state = <empty>
iface.tos = 0
iface.ttl = 0
iface.delayed_ack = <empty>
iface.tcp_nagle = <empty>
iface.tcp_wsf_state = <empty>
iface.tcp_wsf = 0
iface.tcp_timer_scale = 0
iface.tcp_timestamp = <empty>
iface.redirect = <empty>
iface.def_task_mgmt_timeout = 0
iface.header_digest = <empty>
iface.data_digest = <empty>
iface.immediate_data = <empty>
iface.initial_r2t = <empty>
iface.data_seq_inorder = <empty>
iface.data_pdu_inorder = <empty>
iface.erl = 0
iface.max_receive_data_len = 0
iface.first_burst_len = 0
iface.max_outstanding_r2t = 0
iface.max_burst_len = 0
iface.chap_auth = <empty>
iface.bidi_chap = <empty>
iface.strict_login_compliance = <empty>
iface.discovery_auth = <empty>
iface.discovery_logout = <empty>
node.discovery_address = <empty>
node.discovery_port = 0
node.discovery_type = static
node.session.initial_cmdsn = 0
node.session.initial_login_retry_max = 8
node.session.xmit_thread_priority = -20
node.session.cmds_max = 128
node.session.queue_depth = 32
node.session.nr_sessions = 1
node.session.auth.authmethod = None
node.session.auth.username = <empty>
node.session.auth.password = ***
node.session.auth.username_in = <empty>
node.session.auth.password_in = <empty>
node.session.auth.chap_algs = SHA3-256,SHA256
node.session.timeo.replacement_timeout = 120
node.session.err_timeo.abort_timeout = 15
node.session.err_timeo.lu_reset_timeout = 30
node.session.err_timeo.tgt_reset_timeout = 30
node.session.err_timeo.host_reset_timeout = 60
node.session.iscsi.FastAbort = Yes
node.session.iscsi.InitialR2T = No
node.session.iscsi.ImmediateData = Yes
node.session.iscsi.FirstBurstLength = 262144
node.session.iscsi.MaxBurstLength = 16776192
node.session.iscsi.DefaultTime2Retain = 0
node.session.iscsi.DefaultTime2Wait = 2
node.session.iscsi.MaxConnections = 1
node.session.iscsi.MaxOutstandingR2T = 1
node.session.iscsi.ERL = 0
node.session.scan = auto
node.session.reopen_max = 0
node.conn[0].address = 172.25.59.221
node.conn[0].port = 3260
node.conn[0].startup = manual
node.conn[0].tcp.window_size = 524288
node.conn[0].tcp.type_of_service = 0
node.conn[0].timeo.logout_timeout = 15
node.conn[0].timeo.login_timeout = 15
node.conn[0].timeo.auth_timeout = 45
node.conn[0].timeo.noop_out_interval = 5
node.conn[0].timeo.noop_out_timeout = 5
node.conn[0].iscsi.MaxXmitDataSegmentLength = 0
node.conn[0].iscsi.MaxRecvDataSegmentLength = 262144
node.conn[0].iscsi.HeaderDigest = None
node.conn[0].iscsi.DataDigest = None
node.conn[0].iscsi.IFMarker = No
node.conn[0].iscsi.OFMarker = No
# END RECORD
 stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:26:40.378 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.session.scan -v manual [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:40.398 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.session.scan -v manual" returned: 0 in 0.020s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:40.399 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[0b3659e2-1a20-4393-adda-399828d1cb24]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:40.401 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'update', '-n', 'node.session.scan', '-v', 'manual'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:26:40.403 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:40.425 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 21 in 0.022s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:40.426 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[c37e99fb-5b58-47ec-9f50-281844d936f0]: (4, ('', 'iscsiadm: No active sessions.\n')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:40.428 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout= stderr=iscsiadm: No active sessions.
 [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:26:40.429 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout= stderr=iscsiadm: No active sessions.
 [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:26:40.430 807113 WARNING os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm stderr output when getting sessions: iscsiadm: No active sessions.

2025-10-14 17:26:40.432 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --login [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:41.484 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --login" returned: 0 in 1.052s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:41.485 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[89c2ac37-ece4-48ef-a7b7-91cc160d24ac]: (4, ('Logging in to [iface: default, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260]\nLogin to [iface: default, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260] successful.\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:41.487 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--login',): stdout=Logging in to [iface: default, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260]
Login to [iface: default, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260] successful.
 stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:26:41.489 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.startup -v automatic [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:41.509 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.startup -v automatic" returned: 0 in 0.020s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:41.510 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[c1d680d6-9bdd-42c2-8ca6-6fd1c459565f]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:41.512 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'update', '-n', 'node.startup', '-v', 'automatic'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:26:41.514 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:41.534 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 0 in 0.020s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:41.535 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[03236f5d-2f9e-4ec4-807f-5e939c8dd3d3]: (4, ('tcp: [18] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:41.537 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout=tcp: [18] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:26:41.538 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout=tcp: [18] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:26:41.539 807113 DEBUG os_brick.initiator.connectors.base [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_to_iscsi_portal-172.25.59.221:3260-iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector._connect_to_iscsi_portal_unsafe" :: held 2.250s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:26:41.540 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connected to 172.25.59.221:3260 [00;33m{{(pid=807113) _connect_vol /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:659}}[00m
2025-10-14 17:26:41.542 807113 DEBUG os_brick.initiator.linuxscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] HCTL ('33', '-', '-', 0) found on session 18 with lun 0 [00;33m{{(pid=807113) get_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:788}}[00m
2025-10-14 17:26:41.543 807113 DEBUG os_brick.initiator.linuxscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Scanning host 33 c: -, t: -, l: 0) [00;33m{{(pid=807113) scan_iscsi /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:814}}[00m
2025-10-14 17:26:41.546 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): tee -a /sys/class/scsi_host/host33/scan [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:26:41.590 826121 DEBUG oslo_concurrency.processutils [-] CMD "tee -a /sys/class/scsi_host/host33/scan" returned: 0 in 0.044s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:26:41.591 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[434e16bd-28da-4d98-bee8-12808d0455d1]: (4, ('- - 0', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:26:41.595 807113 DEBUG os_brick.initiator.linuxscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching for a device in session 18 and hctl ['33', '*', '*', 0] yield: None [00;33m{{(pid=807113) device_name_by_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:808}}[00m
2025-10-14 17:26:41.813 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:42.598 807113 DEBUG os_brick.initiator.linuxscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Searching for a device in session 18 and hctl ['33', '*', '*', 0] yield: sdb [00;33m{{(pid=807113) device_name_by_hctl /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:808}}[00m
2025-10-14 17:26:42.599 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Connected to sdb using {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 0, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True} [00;33m{{(pid=807113) _connect_vol /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:687}}[00m
2025-10-14 17:26:42.601 807113 DEBUG os_brick.initiator.connectors.base [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.connect_volume" :: held 3.340s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:26:42.602 807113 DEBUG os_brick.initiator.connectors.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== connect_volume: return (3342ms) {'type': 'block', 'scsi_wwn': '360060e8008757e000050757e000055f2', 'path': '/dev/sdb'} [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:26:42.603 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Attached iSCSI volume {'type': 'block', 'scsi_wwn': '360060e8008757e000050757e000055f2', 'path': '/dev/sdb'} [00;33m{{(pid=807113) connect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:66}}[00m
2025-10-14 17:26:42.614 807113 DEBUG nova.objects.instance [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 6d42f8db-d75e-46be-9a7a-aae117646c61 [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:26:43.129 807113 DEBUG nova.virt.libvirt.guest [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] attach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-581eedfe-5388-4155-890a-ee7847220e3c"/>
  <source dev="/dev/sdb"/>
  <target dev="vdb" bus="virtio"/>
  <serial>581eedfe-5388-4155-890a-ee7847220e3c</serial>
  <shareable/>
</disk>
 [00;33m{{(pid=807113) attach_device /opt/stack/nova/nova/virt/libvirt/guest.py:336}}[00m
2025-10-14 17:26:45.037 807113 DEBUG nova.virt.libvirt.driver [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vda, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:26:45.038 807113 DEBUG nova.virt.libvirt.driver [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No BDM found with device name vdb, not building metadata. [00;33m{{(pid=807113) _build_disk_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12818}}[00m
2025-10-14 17:26:45.039 807113 DEBUG nova.virt.libvirt.driver [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] No VIF found with MAC fa:16:3e:ae:dd:42, not building metadata [00;33m{{(pid=807113) _build_interface_metadata /opt/stack/nova/nova/virt/libvirt/driver.py:12794}}[00m
2025-10-14 17:26:46.654 807113 DEBUG oslo_concurrency.lockutils [req-c1574333-1306-401c-bc1c-a27569708a5d 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61" "released" by "nova.compute.manager.ComputeManager.attach_volume.<locals>.do_attach_volume" :: held 15.766s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:26:46.817 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:47.673 807113 DEBUG oslo_concurrency.lockutils [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "6d42f8db-d75e-46be-9a7a-aae117646c61" by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:26:47.674 807113 DEBUG oslo_concurrency.lockutils [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61" acquired by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:26:48.180 807113 INFO nova.compute.manager [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Detaching volume 581eedfe-5388-4155-890a-ee7847220e3c
2025-10-14 17:26:48.273 807113 INFO nova.virt.block_device [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Attempting to driver detach volume 581eedfe-5388-4155-890a-ee7847220e3c from mountpoint /dev/vdb
2025-10-14 17:26:48.287 807113 DEBUG nova.virt.libvirt.driver [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdb by alias ua-581eedfe-5388-4155-890a-ee7847220e3c [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:26:48.290 807113 DEBUG nova.virt.libvirt.driver [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdb by alias ua-581eedfe-5388-4155-890a-ee7847220e3c [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:26:48.292 807113 DEBUG nova.virt.libvirt.driver [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Attempting to detach device vdb from instance 6d42f8db-d75e-46be-9a7a-aae117646c61 from the persistent domain config. [00;33m{{(pid=807113) _detach_from_persistent /opt/stack/nova/nova/virt/libvirt/driver.py:2638}}[00m
2025-10-14 17:26:48.293 807113 DEBUG nova.virt.libvirt.guest [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] detach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-581eedfe-5388-4155-890a-ee7847220e3c"/>
  <source dev="/dev/sdb"/>
  <target dev="vdb" bus="virtio"/>
  <serial>581eedfe-5388-4155-890a-ee7847220e3c</serial>
  <shareable/>
  <address type="pci" domain="0x0000" bus="0x00" slot="0x07" function="0x0"/>
</disk>
 [00;33m{{(pid=807113) detach_device /opt/stack/nova/nova/virt/libvirt/guest.py:466}}[00m
2025-10-14 17:26:48.306 807113 DEBUG nova.virt.libvirt.driver [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Found disk vdb by alias ua-581eedfe-5388-4155-890a-ee7847220e3c [00;33m{{(pid=807113) _get_guest_disk_device /opt/stack/nova/nova/virt/libvirt/driver.py:2887}}[00m
2025-10-14 17:26:48.307 807113 WARNING nova.virt.libvirt.driver [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Failed to detach device vdb from instance 6d42f8db-d75e-46be-9a7a-aae117646c61 from the persistent domain config. Libvirt did not report any error but the device is still in the config.
2025-10-14 17:26:48.308 807113 DEBUG nova.virt.libvirt.driver [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] (1/8): Attempting to detach device vdb with device alias ua-581eedfe-5388-4155-890a-ee7847220e3c from instance 6d42f8db-d75e-46be-9a7a-aae117646c61 from the live domain config. [00;33m{{(pid=807113) _detach_from_live_with_retry /opt/stack/nova/nova/virt/libvirt/driver.py:2674}}[00m
2025-10-14 17:26:48.309 807113 DEBUG nova.virt.libvirt.guest [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] detach device xml: <disk type="block" device="disk">
  <driver name="qemu" type="raw" cache="none" io="native"/>
  <alias name="ua-581eedfe-5388-4155-890a-ee7847220e3c"/>
  <source dev="/dev/sdb"/>
  <target dev="vdb" bus="virtio"/>
  <serial>581eedfe-5388-4155-890a-ee7847220e3c</serial>
  <shareable/>
  <address type="pci" domain="0x0000" bus="0x00" slot="0x07" function="0x0"/>
</disk>
 [00;33m{{(pid=807113) detach_device /opt/stack/nova/nova/virt/libvirt/guest.py:466}}[00m
2025-10-14 17:26:49.399 807113 DEBUG nova.virt.libvirt.driver [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Start waiting for the detach event from libvirt for device vdb with device alias ua-581eedfe-5388-4155-890a-ee7847220e3c for instance 6d42f8db-d75e-46be-9a7a-aae117646c61 [00;33m{{(pid=807113) _detach_from_live_and_wait_for_event /opt/stack/nova/nova/virt/libvirt/driver.py:2750}}[00m
2025-10-14 17:26:51.821 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:26:56.825 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:01.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:27:01.293 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:27:01.294 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:27:01.810 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:27:01.811 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:27:01.812 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:27:01.813 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:27:01.828 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:01.831 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:01.832 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5005 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:27:01.833 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:01.834 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:01.835 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:02.878 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:03.003 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk --force-share --output=json" returned: 0 in 0.125s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:03.007 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): /opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk --force-share --output=json [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:03.103 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "/opt/stack/data/venv/bin/python3.10 -m oslo_concurrency.prlimit --as=1073741824 --cpu=30 -- env LC_ALL=C LANG=C qemu-img info /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61/disk --force-share --output=json" returned: 0 in 0.096s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:03.359 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:03.398 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.039s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:03.401 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=14532MB free_disk=172.3127670288086GB free_vcpus=7 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:27:03.402 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:27:03.404 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:27:04.475 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Instance 6d42f8db-d75e-46be-9a7a-aae117646c61 actively managed on this compute host and has allocations in placement: {'resources': {'DISK_GB': 1, 'MEMORY_MB': 192, 'VCPU': 1}}. [00;33m{{(pid=807113) _remove_deleted_instances_allocations /opt/stack/nova/nova/compute/resource_tracker.py:1710}}[00m
2025-10-14 17:27:04.476 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 1 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:27:04.476 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=704MB phys_disk=194GB used_disk=1GB total_vcpus=8 used_vcpus=1 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:27:03 up 1 day,  6:54,  5 users,  load average: 1.20, 1.85, 1.89\n', 'num_instances': '1', 'num_vm_active': '1', 'num_task_None': '1', 'num_os_type_None': '1', 'num_proj_1eef17e93cf14f169df902f14b44a4e3': '1', 'io_workload': '0'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:27:04.546 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:27:05.056 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:27:05.578 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:27:05.579 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.175s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:27:06.837 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:06.839 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:06.840 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5004 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:27:06.841 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:06.842 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:06.843 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:07.578 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:27:07.580 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:27:07.581 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:27:07.582 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:27:07.582 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:27:09.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_volume_usage [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:27:09.402 807113 WARNING nova.virt.libvirt.driver [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Waiting for libvirt event about the detach of device vdb with device alias ua-581eedfe-5388-4155-890a-ee7847220e3c from instance 6d42f8db-d75e-46be-9a7a-aae117646c61 is timed out.
2025-10-14 17:27:09.410 807113 INFO nova.virt.libvirt.driver [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully detached device vdb from instance 6d42f8db-d75e-46be-9a7a-aae117646c61 from the live domain config.
2025-10-14 17:27:09.477 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] calling os-brick to detach iSCSI Volume [00;33m{{(pid=807113) disconnect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:73}}[00m
2025-10-14 17:27:09.478 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] ==> disconnect_volume: call "{'args': (<os_brick.initiator.connectors.iscsi.ISCSIConnector object at 0x7a59504d4550>, {'target_portal': '172.25.59.221:3260', 'target_iqn': 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 'target_discovered': False, 'target_lun': 0, 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'enforce_multipath': True, 'device_path': '/dev/sdb'}, None), 'kwargs': {'force': False}}" [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:177}}[00m
2025-10-14 17:27:09.479 807113 DEBUG os_brick.initiator.connectors.base [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "connect_volume" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:68}}[00m
2025-10-14 17:27:09.480 807113 DEBUG os_brick.initiator.connectors.base [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" acquired by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:73}}[00m
2025-10-14 17:27:09.482 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m discoverydb -o show -P 1 [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:09.502 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m discoverydb -o show -P 1" returned: 0 in 0.020s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:09.503 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[8abdc4b7-5d43-4fb3-9431-a13d19777246]: (4, ('SENDTARGETS:\nNo targets found.\niSNS:\nNo targets found.\nSTATIC:\nTarget: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\n\tPortal: 172.25.59.221:3260,-1\n\t\tIface Name: default\nFIRMWARE:\nNo targets found.\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:27:09.505 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ['-m', 'discoverydb', '-o', 'show', '-P', 1]: stdout=SENDTARGETS:
No targets found.
iSNS:
No targets found.
STATIC:
Target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target
	Portal: 172.25.59.221:3260,-1
		Iface Name: default
FIRMWARE:
No targets found.
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:27:09.505 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Regex to get portals from discoverydb: ^SENDTARGETS:
.*?^DiscoveryAddress: 172.25.59.221,3260.*?
(.*?)^(?:DiscoveryAddress|iSNS):.* [00;33m{{(pid=807113) _get_discoverydb_portals /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:392}}[00m
2025-10-14 17:27:09.506 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Getting connected devices for (ips,iqns,luns)=[('172.25.59.221:3260', 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target', 0)] [00;33m{{(pid=807113) _get_connection_devices /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:853}}[00m
2025-10-14 17:27:09.508 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:09.528 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node" returned: 0 in 0.020s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:09.529 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[72ac2612-7396-47c8-a41a-eb8f90f62414]: (4, ('172.25.59.221:3260,4294967295 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:27:09.532 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m session [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:09.553 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m session" returned: 0 in 0.022s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:09.555 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[92c63682-acfb-4067-a5bb-77718eb344eb]: (4, ('tcp: [18] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:27:09.556 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('-m', 'session'): stdout=tcp: [18] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsiadm_bare /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1221}}[00m
2025-10-14 17:27:09.557 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsi session list stdout=tcp: [18] 172.25.59.221:3260,257 iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target (non-flash)
 stderr= [00;33m{{(pid=807113) _run_iscsi_session /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1210}}[00m
2025-10-14 17:27:09.563 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Resulting device map defaultdict(<function ISCSIConnector._get_connection_devices.<locals>.<lambda> at 0x7a59504e2710>, {('172.25.59.221:3260', 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target'): ({'sdb'}, set())}) [00;33m{{(pid=807113) _get_connection_devices /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:886}}[00m
2025-10-14 17:27:09.564 807113 DEBUG os_brick.initiator.linuxscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Removing single pathed devices sdb [00;33m{{(pid=807113) remove_connection /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:381}}[00m
2025-10-14 17:27:09.566 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): multipathd show status [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:09.581 826121 DEBUG oslo_concurrency.processutils [-] 'multipathd show status' failed. Not Retrying. [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:423}}[00m
2025-10-14 17:27:09.582 826121 DEBUG oslo.privsep.daemon [-] privsep: Exception during request[4e9b2d39-751d-490e-9676-01e831673208]: [Errno 2] No such file or directory: 'multipathd' [00;33m{{(pid=826121) _process_cmd /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:481}}[00m
Traceback (most recent call last):
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py", line 478, in _process_cmd
    ret = func(*f_args, **f_kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/priv_context.py", line 266, in _wrap
    return func(*args, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 198, in execute_root
    return custom_execute(*cmd, shell=False, run_as_root=False, **kwargs)
  File "/opt/stack/data/venv/lib/python3.10/site-packages/os_brick/privileged/rootwrap.py", line 146, in custom_execute
    return putils.execute(on_execute=on_execute,
  File "/opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py", line 354, in execute
    obj = subprocess.Popen(cmd,
  File "/usr/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'multipathd'
2025-10-14 17:27:09.584 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[4e9b2d39-751d-490e-9676-01e831673208]: (5, 'builtins.FileNotFoundError', (2, 'No such file or directory')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:27:09.586 807113 DEBUG os_brick.initiator.linuxscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Flushing IO for device /dev/sdb [00;33m{{(pid=807113) flush_device_io /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:441}}[00m
2025-10-14 17:27:09.588 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): blockdev --flushbufs /dev/sdb [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:09.602 826121 DEBUG oslo_concurrency.processutils [-] CMD "blockdev --flushbufs /dev/sdb" returned: 0 in 0.015s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:09.604 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[94a17cac-f266-4adc-9a33-5e84ca65f049]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:27:09.605 807113 DEBUG os_brick.initiator.linuxscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Remove SCSI device /dev/sdb with /sys/block/sdb/device/delete [00;33m{{(pid=807113) remove_scsi_device /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:151}}[00m
2025-10-14 17:27:09.608 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): tee -a /sys/block/sdb/device/delete [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:09.642 826121 DEBUG oslo_concurrency.processutils [-] CMD "tee -a /sys/block/sdb/device/delete" returned: 0 in 0.034s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:09.643 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[6695a528-19b3-4899-8953-3737216ea4cc]: (4, ('1', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:27:09.645 807113 DEBUG os_brick.initiator.linuxscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Checking to see if SCSI volumes sdb have been removed. [00;33m{{(pid=807113) wait_for_volumes_removal /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:159}}[00m
2025-10-14 17:27:09.646 807113 DEBUG os_brick.initiator.linuxscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] SCSI volumes sdb have been removed. [00;33m{{(pid=807113) wait_for_volumes_removal /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/linuxscsi.py:169}}[00m
2025-10-14 17:27:09.647 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Disconnecting from: [('172.25.59.221:3260', 'iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target')] [00;33m{{(pid=807113) _disconnect_connection /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1199}}[00m
2025-10-14 17:27:09.650 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.startup -v manual [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:09.671 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op update -n node.startup -v manual" returned: 0 in 0.021s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:09.672 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[76aef525-b85b-493f-8942-199dfc3a7582]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:27:09.674 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'update', '-n', 'node.startup', '-v', 'manual'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:27:09.677 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --logout [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:09.721 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --logout" returned: 0 in 0.044s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:09.722 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[8d87c0f2-d5db-4b75-a828-bc0fa9d5ff28]: (4, ('Logging out of session [sid: 18, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260]\nLogout of [sid: 18, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260] successful.\n', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:27:09.724 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--logout',): stdout=Logging out of session [sid: 18, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260]
Logout of [sid: 18, target: iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target, portal: 172.25.59.221,3260] successful.
 stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:27:09.727 826121 DEBUG oslo_concurrency.processutils [-] Running cmd (subprocess): iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op delete [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:27:09.747 826121 DEBUG oslo_concurrency.processutils [-] CMD "iscsiadm -m node -T iqn.2016-04.com.open-iscsi:d78edfece0b6.hbsd-target -p 172.25.59.221:3260 --op delete" returned: 0 in 0.020s [00;33m{{(pid=826121) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:27:09.748 826121 DEBUG oslo.privsep.daemon [-] privsep: reply[a4e14184-6dc9-4266-bd9d-fd3891082b36]: (4, ('', '')) [00;33m{{(pid=826121) _call_back /opt/stack/data/venv/lib/python3.10/site-packages/oslo_privsep/daemon.py:503}}[00m
2025-10-14 17:27:09.750 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] iscsiadm ('--op', 'delete'): stdout= stderr= [00;33m{{(pid=807113) _run_iscsiadm /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/iscsi.py:1065}}[00m
2025-10-14 17:27:09.751 807113 DEBUG os_brick.initiator.connectors.base [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "connect_volume" "released" by "os_brick.initiator.connectors.iscsi.ISCSIConnector.disconnect_volume" :: held 0.271s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/initiator/connectors/base.py:87}}[00m
2025-10-14 17:27:09.752 807113 DEBUG os_brick.initiator.connectors.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] <== disconnect_volume: return (272ms) None [00;33m{{(pid=807113) trace_logging_wrapper /opt/stack/data/venv/lib/python3.10/site-packages/os_brick/utils.py:204}}[00m
2025-10-14 17:27:09.753 807113 DEBUG nova.virt.libvirt.volume.iscsi [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Disconnected iSCSI Volume [00;33m{{(pid=807113) disconnect_volume /opt/stack/nova/nova/virt/libvirt/volume/iscsi.py:80}}[00m
2025-10-14 17:27:11.833 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:16.837 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:16.843 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:20.390 807113 DEBUG nova.objects.instance [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'flavor' on Instance uuid 6d42f8db-d75e-46be-9a7a-aae117646c61 [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:27:21.408 807113 DEBUG oslo_concurrency.lockutils [req-569d5517-bb98-4a9f-8529-e49c7d4677e6 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61" "released" by "nova.compute.manager.ComputeManager.detach_volume.<locals>.do_detach_volume" :: held 33.734s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:27:21.845 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:21.846 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:21.847 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:27:21.847 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:21.848 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:21.849 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:26.842 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:31.846 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:31.848 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:31.849 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5004 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:27:31.849 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:31.850 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:31.851 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:35.006 807113 DEBUG oslo_concurrency.lockutils [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "6d42f8db-d75e-46be-9a7a-aae117646c61" by "nova.compute.manager.ComputeManager.terminate_instance.<locals>.do_terminate_instance" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:27:35.008 807113 DEBUG oslo_concurrency.lockutils [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61" acquired by "nova.compute.manager.ComputeManager.terminate_instance.<locals>.do_terminate_instance" :: waited 0.002s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:27:35.009 807113 DEBUG oslo_concurrency.lockutils [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" by "nova.compute.manager.InstanceEvents.clear_events_for_instance.<locals>._clear_events" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:27:35.010 807113 DEBUG oslo_concurrency.lockutils [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" acquired by "nova.compute.manager.InstanceEvents.clear_events_for_instance.<locals>._clear_events" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:27:35.011 807113 DEBUG oslo_concurrency.lockutils [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" "released" by "nova.compute.manager.InstanceEvents.clear_events_for_instance.<locals>._clear_events" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:27:35.017 807113 INFO nova.compute.manager [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Terminating instance
2025-10-14 17:27:35.526 807113 DEBUG nova.compute.manager [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Start destroying the instance on the hypervisor. [00;33m{{(pid=807113) _shutdown_instance /opt/stack/nova/nova/compute/manager.py:3164}}[00m
2025-10-14 17:27:35.567 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:36.053 807113 INFO nova.virt.libvirt.driver [-] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Instance destroyed successfully.
2025-10-14 17:27:36.054 807113 DEBUG nova.objects.instance [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lazy-loading 'resources' on Instance uuid 6d42f8db-d75e-46be-9a7a-aae117646c61 [00;33m{{(pid=807113) obj_load_attr /opt/stack/nova/nova/objects/instance.py:1141}}[00m
2025-10-14 17:27:36.562 807113 DEBUG nova.virt.libvirt.vif [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] vif_type=ovs instance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone='nova',cell_name=None,cleaned=False,compute_id=1,config_drive='',created_at=2025-10-15T00:24:53Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,device_metadata=<?>,disable_terminate=False,display_description=None,display_name='tempest-VolumeMultiattachTests-server-810971940',ec2_ids=<?>,ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,flavor=Flavor(11),hidden=False,host='devstack-u2204-93-55',hostname='tempest-volumemultiattachtests-server-810971940',id=3,image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',info_cache=InstanceInfoCache,instance_type_id=11,kernel_id='',key_data='ecdsa-sha2-nistp384 AAAAE2VjZHNhLXNoYTItbmlzdHAzODQAAAAIbmlzdHAzODQAAABhBFskQtn5mWzTXnj8PSln/bCfCz+13NawIE/UvT0jD0a2RK//R53958RfCSAuLKwmMeEHcU1qIA636nQP7frAEB4NGLtz6TO5t8uMk6/i6y6Z4n3o7Coo+hoPByNszZ2eZQ==',key_name='tempest-keypair-256554728',keypairs=<?>,launch_index=0,launched_at=2025-10-15T00:25:09Z,launched_on='devstack-u2204-93-55',locked=False,locked_by=None,memory_mb=192,metadata={},migration_context=<?>,new_flavor=None,node='devstack-u2204-93-55',numa_topology=None,old_flavor=None,os_type=None,pci_devices=<?>,pci_requests=<?>,power_state=1,progress=0,project_id='1eef17e93cf14f169df902f14b44a4e3',ramdisk_id='',reservation_id='r-7wvpuh3u',resources=None,root_device_name='/dev/vda',root_gb=1,security_groups=SecurityGroupList,services=<?>,shutdown_terminate=False,system_metadata={boot_roles='member,reader',image_base_image_ref='fccdc018-118e-4071-9d16-6a4d7f6e5493',image_container_format='bare',image_disk_format='raw',image_hw_cdrom_bus='ide',image_hw_disk_bus='virtio',image_hw_input_bus=None,image_hw_machine_type='pc',image_hw_pointer_model=None,image_hw_rng_model='virtio',image_hw_video_model='virtio',image_hw_vif_model='virtio',image_min_disk='1',image_min_ram='0',image_owner_specified.openstack.md5='',image_owner_specified.openstack.object='images/cirros-0.6.1-x86_64-disk',image_owner_specified.openstack.sha256='',owner_project_name='tempest-VolumeMultiattachTests-2017337252',owner_user_name='tempest-VolumeMultiattachTests-2017337252-project-member'},tags=<?>,task_state='deleting',terminated_at=None,trusted_certs=<?>,updated_at=2025-10-15T00:25:09Z,user_data='IyEvYmluL3NoCmVjaG8gIlByaW50aW5nIGNpcnJvcyB1c2VyIGF1dGhvcml6ZWQga2V5cyIKY2F0IH5jaXJyb3MvLnNzaC9hdXRob3JpemVkX2tleXMgfHwgdHJ1ZQo=',user_id='960a08fcc4d0429e9e879816a305186f',uuid=6d42f8db-d75e-46be-9a7a-aae117646c61,vcpu_model=<?>,vcpus=1,vm_mode=None,vm_state='active') vif={"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": [{"address": "172.24.5.89", "type": "floating", "version": 4, "meta": {}}]}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": true, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) unplug /opt/stack/nova/nova/virt/libvirt/vif.py:839}}[00m
2025-10-14 17:27:36.563 807113 DEBUG nova.network.os_vif_util [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converting VIF {"id": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "address": "fa:16:3e:ae:dd:42", "network": {"id": "7244fcbc-3a2b-4d1d-9c70-409ab3e3a140", "bridge": "br-int", "label": "tempest-VolumeMultiattachTests-1284868915-network", "subnets": [{"cidr": "10.1.0.0/28", "dns": [], "gateway": {"address": "10.1.0.1", "type": "gateway", "version": 4, "meta": {}}, "ips": [{"address": "10.1.0.5", "type": "fixed", "version": 4, "meta": {}, "floating_ips": [{"address": "172.24.5.89", "type": "floating", "version": 4, "meta": {}}]}], "routes": [], "version": 4, "meta": {"enable_dhcp": true, "dhcp_server": "10.1.0.2"}}], "meta": {"injected": false, "tenant_id": "1eef17e93cf14f169df902f14b44a4e3", "mtu": 1450, "physical_network": null, "tunneled": true}}, "type": "ovs", "details": {"connectivity": "l2", "port_filter": true, "ovs_hybrid_plug": false, "datapath_type": "system", "bridge_name": "br-int", "bound_drivers": {"0": "openvswitch"}}, "devname": "tapb9d92f2f-7d", "ovs_interfaceid": "b9d92f2f-7da6-44cb-b0f9-bed2bb601653", "qbh_params": null, "qbg_params": null, "active": true, "vnic_type": "normal", "profile": {}, "preserve_on_delete": false, "delegate_create": true, "meta": {}} [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:511}}[00m
2025-10-14 17:27:36.566 807113 DEBUG nova.network.os_vif_util [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Converted object VIFOpenVSwitch(active=True,address=fa:16:3e:ae:dd:42,bridge_name='br-int',has_traffic_filtering=True,id=b9d92f2f-7da6-44cb-b0f9-bed2bb601653,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapb9d92f2f-7d') [00;33m{{(pid=807113) nova_to_osvif_vif /opt/stack/nova/nova/network/os_vif_util.py:548}}[00m
2025-10-14 17:27:36.568 807113 DEBUG os_vif [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Unplugging vif VIFOpenVSwitch(active=True,address=fa:16:3e:ae:dd:42,bridge_name='br-int',has_traffic_filtering=True,id=b9d92f2f-7da6-44cb-b0f9-bed2bb601653,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapb9d92f2f-7d') [00;33m{{(pid=807113) unplug /opt/stack/data/venv/lib/python3.10/site-packages/os_vif/__init__.py:109}}[00m
2025-10-14 17:27:36.575 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:36.577 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): DelPortCommand(_result=None, port=tapb9d92f2f-7d, bridge=br-int, if_exists=True) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:27:36.581 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:36.587 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:36.590 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 20 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:36.590 807113 DEBUG ovsdbapp.backend.ovs_idl.transaction [-] Running txn n=1 command(idx=0): DbDestroyCommand(_result=None, table=QoS, record=aa9613c9-c3c1-4ac1-90b3-282d788cc90d) [00;33m{{(pid=807113) do_commit /opt/stack/data/venv/lib/python3.10/site-packages/ovsdbapp/backend/ovs_idl/transaction.py:89}}[00m
2025-10-14 17:27:36.592 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:36.595 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:36.601 807113 INFO os_vif [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Successfully unplugged vif VIFOpenVSwitch(active=True,address=fa:16:3e:ae:dd:42,bridge_name='br-int',has_traffic_filtering=True,id=b9d92f2f-7da6-44cb-b0f9-bed2bb601653,network=Network(7244fcbc-3a2b-4d1d-9c70-409ab3e3a140),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tapb9d92f2f-7d')
2025-10-14 17:27:36.602 807113 INFO nova.virt.libvirt.driver [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Deleting instance files /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61_del
2025-10-14 17:27:36.603 807113 INFO nova.virt.libvirt.driver [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Deletion of /opt/stack/data/nova/instances/6d42f8db-d75e-46be-9a7a-aae117646c61_del complete
2025-10-14 17:27:37.119 807113 INFO nova.compute.manager [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Took 1.59 seconds to destroy the instance on the hypervisor.
2025-10-14 17:27:37.121 807113 DEBUG oslo.service.backend.eventlet.loopingcall [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Waiting for function nova.compute.manager.ComputeManager._try_deallocate_network.<locals>._deallocate_network_with_retries to return. [00;33m{{(pid=807113) func /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/backend/eventlet/loopingcall.py:436}}[00m
2025-10-14 17:27:37.122 807113 DEBUG nova.compute.manager [-] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Deallocating network for instance [00;33m{{(pid=807113) _deallocate_network /opt/stack/nova/nova/compute/manager.py:2296}}[00m
2025-10-14 17:27:37.122 807113 DEBUG nova.network.neutron [-] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] deallocate_for_instance() [00;33m{{(pid=807113) deallocate_for_instance /opt/stack/nova/nova/network/neutron.py:1863}}[00m
2025-10-14 17:27:37.132 807113 DEBUG nova.compute.manager [req-b1d119c2-ef04-4788-a10a-09bf3a9a04bc bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Received event network-vif-unplugged-b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:27:37.133 807113 DEBUG oslo_concurrency.lockutils [req-b1d119c2-ef04-4788-a10a-09bf3a9a04bc bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Acquiring lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:27:37.134 807113 DEBUG oslo_concurrency.lockutils [req-b1d119c2-ef04-4788-a10a-09bf3a9a04bc bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" acquired by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:27:37.134 807113 DEBUG oslo_concurrency.lockutils [req-b1d119c2-ef04-4788-a10a-09bf3a9a04bc bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61-events" "released" by "nova.compute.manager.InstanceEvents.pop_instance_event.<locals>._pop_event" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:27:37.135 807113 DEBUG nova.compute.manager [req-b1d119c2-ef04-4788-a10a-09bf3a9a04bc bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] No waiting events found dispatching network-vif-unplugged-b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) pop_instance_event /opt/stack/nova/nova/compute/manager.py:322}}[00m
2025-10-14 17:27:37.135 807113 DEBUG nova.compute.manager [req-b1d119c2-ef04-4788-a10a-09bf3a9a04bc bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Received event network-vif-unplugged-b9d92f2f-7da6-44cb-b0f9-bed2bb601653 for instance with task_state deleting. [00;33m{{(pid=807113) _process_instance_event /opt/stack/nova/nova/compute/manager.py:11546}}[00m
2025-10-14 17:27:38.172 807113 DEBUG nova.compute.manager [req-5bd7a481-2fa4-4b8d-977a-12198495eaf8 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Received event network-vif-deleted-b9d92f2f-7da6-44cb-b0f9-bed2bb601653 [00;33m{{(pid=807113) external_instance_event /opt/stack/nova/nova/compute/manager.py:11768}}[00m
2025-10-14 17:27:38.173 807113 INFO nova.compute.manager [req-5bd7a481-2fa4-4b8d-977a-12198495eaf8 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Neutron deleted interface b9d92f2f-7da6-44cb-b0f9-bed2bb601653; detaching it from the instance and deleting it from the info cache
2025-10-14 17:27:38.174 807113 DEBUG nova.network.neutron [req-5bd7a481-2fa4-4b8d-977a-12198495eaf8 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Updating instance_info_cache with network_info: [] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:27:38.626 807113 DEBUG nova.network.neutron [-] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Updating instance_info_cache with network_info: [] [00;33m{{(pid=807113) update_instance_cache_with_nw_info /opt/stack/nova/nova/network/neutron.py:116}}[00m
2025-10-14 17:27:38.684 807113 DEBUG nova.compute.manager [req-5bd7a481-2fa4-4b8d-977a-12198495eaf8 bf160809a42a4c81b3287c50a0227eb7 29748517467f4f75a353752eae0d730e - - default default] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Detach interface failed, port_id=b9d92f2f-7da6-44cb-b0f9-bed2bb601653, reason: Instance 6d42f8db-d75e-46be-9a7a-aae117646c61 could not be found. [00;33m{{(pid=807113) _process_instance_vif_deleted_event /opt/stack/nova/nova/compute/manager.py:11602}}[00m
2025-10-14 17:27:39.133 807113 INFO nova.compute.manager [-] [instance: 6d42f8db-d75e-46be-9a7a-aae117646c61] Took 2.01 seconds to deallocate network for instance.
2025-10-14 17:27:39.654 807113 DEBUG oslo_concurrency.lockutils [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.update_usage" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:27:39.655 807113 DEBUG oslo_concurrency.lockutils [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.update_usage" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:27:39.751 807113 DEBUG nova.compute.provider_tree [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:27:40.259 807113 DEBUG nova.scheduler.client.report [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:27:40.781 807113 DEBUG oslo_concurrency.lockutils [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.update_usage" :: held 1.125s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:27:40.838 807113 INFO nova.scheduler.client.report [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Deleted allocations for instance 6d42f8db-d75e-46be-9a7a-aae117646c61
2025-10-14 17:27:41.597 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:41.599 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:41.599 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:27:41.599 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:41.600 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:41.601 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:41.862 807113 DEBUG oslo_concurrency.lockutils [req-df7db3cb-58bf-4d1d-8be7-c7994e2dde07 960a08fcc4d0429e9e879816a305186f 1eef17e93cf14f169df902f14b44a4e3 - - default default] Lock "6d42f8db-d75e-46be-9a7a-aae117646c61" "released" by "nova.compute.manager.ComputeManager.terminate_instance.<locals>.do_terminate_instance" :: held 6.853s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:27:44.882 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:44.886 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:45.057 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:45.086 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:45.299 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:45.331 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:46.065 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:46.088 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:48.164 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:48.184 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:48.402 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:48.421 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:49.129 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:49.138 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:51.602 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:56.604 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:56.606 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:27:56.607 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:27:56.607 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:27:56.609 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:27:56.610 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:28:01.611 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:28:01.612 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:28:01.613 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:28:01.614 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:28:01.615 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:28:01.615 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:28:02.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rescued_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:28:03.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._instance_usage_audit [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:28:03.292 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager.update_available_resource [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:28:03.803 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:28:03.804 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:28:03.805 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker.clean_compute_node_cache" :: held 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:28:03.806 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Auditing locally available compute resources for devstack-u2204-93-55 (node: devstack-u2204-93-55) [00;33m{{(pid=807113) update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:907}}[00m
2025-10-14 17:28:04.084 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running cmd (subprocess): env LANG=C uptime [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:349}}[00m
2025-10-14 17:28:04.127 807113 DEBUG oslo_concurrency.processutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CMD "env LANG=C uptime" returned: 0 in 0.043s [00;33m{{(pid=807113) execute /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/processutils.py:372}}[00m
2025-10-14 17:28:04.130 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Hypervisor/Node resource view: name=devstack-u2204-93-55 free_ram=15281MB free_disk=172.33554077148438GB free_vcpus=8 pci_devices=[{"dev_id": "pci_0000_02_00_0", "address": "0000:02:00.0", "product_id": "07c0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07c0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_0", "address": "0000:00:07.0", "product_id": "7110", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7110", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_1", "address": "0000:00:07.1", "product_id": "7111", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7111", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_02_0", "address": "0000:02:02.0", "product_id": "07e0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07e0", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_7", "address": "0000:00:07.7", "product_id": "0740", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0740", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_07_3", "address": "0000:00:07.3", "product_id": "7113", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7113", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_0f_0", "address": "0000:00:0f.0", "product_id": "0405", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_0405", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_01_0", "address": "0000:00:01.0", "product_id": "7191", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7191", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_00_00_0", "address": "0000:00:00.0", "product_id": "7190", "vendor_id": "8086", "numa_node": null, "label": "label_8086_7190", "dev_type": "type-PCI"}, {"dev_id": "pci_0000_02_01_0", "address": "0000:02:01.0", "product_id": "07b0", "vendor_id": "15ad", "numa_node": null, "label": "label_15ad_07b0", "dev_type": "type-PCI"}] [00;33m{{(pid=807113) _report_hypervisor_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1106}}[00m
2025-10-14 17:28:04.131 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Acquiring lock "compute_resources" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:405}}[00m
2025-10-14 17:28:04.132 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" acquired by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: waited 0.001s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:410}}[00m
2025-10-14 17:28:05.196 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Total usable vcpus: 8, total allocated vcpus: 0 [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1129}}[00m
2025-10-14 17:28:05.197 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Final resource view: name=devstack-u2204-93-55 phys_ram=24031MB used_ram=512MB phys_disk=194GB used_disk=0GB total_vcpus=8 used_vcpus=0 pci_stats=[] stats={'failed_builds': '0', 'uptime': ' 17:28:04 up 1 day,  6:55,  6 users,  load average: 1.57, 1.81, 1.88\n'} [00;33m{{(pid=807113) _report_final_resource_view /opt/stack/nova/nova/compute/resource_tracker.py:1138}}[00m
2025-10-14 17:28:05.244 807113 DEBUG nova.compute.provider_tree [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed in ProviderTree for provider: 074ba663-40c5-4090-8b4a-a216c63d8a77 [00;33m{{(pid=807113) update_inventory /opt/stack/nova/nova/compute/provider_tree.py:180}}[00m
2025-10-14 17:28:05.753 807113 DEBUG nova.scheduler.client.report [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Inventory has not changed for provider 074ba663-40c5-4090-8b4a-a216c63d8a77 based on inventory data: {'VCPU': {'total': 8, 'reserved': 0, 'min_unit': 1, 'max_unit': 8, 'step_size': 1, 'allocation_ratio': 100.0}, 'MEMORY_MB': {'total': 24031, 'reserved': 512, 'min_unit': 1, 'max_unit': 24031, 'step_size': 1, 'allocation_ratio': 100.0}, 'DISK_GB': {'total': 194, 'reserved': 0, 'min_unit': 1, 'max_unit': 194, 'step_size': 1, 'allocation_ratio': 100.0}} [00;33m{{(pid=807113) set_inventory_for_provider /opt/stack/nova/nova/scheduler/client/report.py:958}}[00m
2025-10-14 17:28:06.278 807113 DEBUG nova.compute.resource_tracker [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Compute_service record updated for devstack-u2204-93-55:devstack-u2204-93-55 [00;33m{{(pid=807113) _update_available_resource /opt/stack/nova/nova/compute/resource_tracker.py:1067}}[00m
2025-10-14 17:28:06.278 807113 DEBUG oslo_concurrency.lockutils [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Lock "compute_resources" "released" by "nova.compute.resource_tracker.ResourceTracker._update_available_resource" :: held 2.146s [00;33m{{(pid=807113) inner /opt/stack/data/venv/lib/python3.10/site-packages/oslo_concurrency/lockutils.py:424}}[00m
2025-10-14 17:28:06.616 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 4999-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:28:06.619 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] 0-ms timeout [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:248}}[00m
2025-10-14 17:28:06.619 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: idle 5003 ms, sending inactivity probe [00;33m{{(pid=807113) run /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:117}}[00m
2025-10-14 17:28:06.620 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering IDLE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:28:06.621 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] [POLLIN] on fd 24 [00;33m{{(pid=807113) __log_wakeup /opt/stack/data/venv/lib/python3.10/site-packages/ovs/poller.py:263}}[00m
2025-10-14 17:28:06.623 807113 DEBUG ovsdbapp.backend.ovs_idl.vlog [-] tcp:127.0.0.1:6640: entering ACTIVE [00;33m{{(pid=807113) _transition /opt/stack/data/venv/lib/python3.10/site-packages/ovs/reconnect.py:519}}[00m
2025-10-14 17:28:08.273 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._sync_scheduler_instance_info [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:28:08.274 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_rebooting_instances [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:28:08.275 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._poll_unconfirmed_resizes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:28:08.291 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._reclaim_queued_deletes [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
2025-10-14 17:28:08.292 807113 DEBUG nova.compute.manager [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] CONF.reclaim_instance_interval <= 0, skipping... [00;33m{{(pid=807113) _reclaim_queued_deletes /opt/stack/nova/nova/compute/manager.py:11184}}[00m
2025-10-14 17:28:09.286 807113 DEBUG oslo_service.periodic_task [req-382ac0a2-5dc7-4a36-9e61-b914f062bcb8 - - - - - -] Running periodic task ComputeManager._check_instance_build_time [00;33m{{(pid=807113) run_periodic_tasks /opt/stack/data/venv/lib/python3.10/site-packages/oslo_service/periodic_task.py:210}}[00m
